{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/human_data.npz')\n",
    "NUM_DIMS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "relations = data['relations'].tolist()\n",
    "relation_embeddings = data['relation_embeddings']\n",
    "entities = data['entities'].tolist()\n",
    "entity_embeddings = data['entity_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_idx = entities.index('Mark')\n",
    "tail_idx = entities.index('14')\n",
    "scores = []\n",
    "for idx, rel in enumerate(relations):\n",
    "    \n",
    "    rel_embed = relation_embeddings[idx]\n",
    "    #score = -np.linalg.norm(entity_embeddings[head_idx] +rel_embed -entity_embeddings[tail_idx])\n",
    "    score = np.sum(entity_embeddings[head_idx] * rel_embed * entity_embeddings[tail_idx])\n",
    "    scores.append((rel, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 0.18151794),\n",
       " ('hasFriend', 0.08699002),\n",
       " ('hasFather', 0.040083323),\n",
       " ('name', 0.029876247),\n",
       " ('type', 0.026286818),\n",
       " ('hasSpouse', 0.0060162283),\n",
       " ('hasChild', 0.003967628),\n",
       " ('trouserssize', 0.0022677071),\n",
       " ('shoesize', -0.052538656),\n",
       " ('shirtsize', -0.06385116),\n",
       " ('phoneNumber', -0.068703905)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark name Mark\n",
      "Mark hasFather John\n",
      "Mark age 14\n",
      "Mark shoesize 8\n",
      "Mark trouserssize 36\n",
      "Mark shirtsize 9\n",
      "Mark type Person\n"
     ]
    }
   ],
   "source": [
    "for h,r,t in X:\n",
    "    if h=='Mark' or t=='Mark':\n",
    "        print(h,r,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_data = []\n",
    "\n",
    "for h,r,t in X:\n",
    "    \n",
    "    head_idx = entities.index(h)\n",
    "    rel_idx = relations.index(r)\n",
    "    tail_idx = entities.index(t)\n",
    "    \n",
    "    head_entity = entity_embeddings[head_idx]\n",
    "    relation = relation_embeddings[rel_idx]\n",
    "    tail_entity = entity_embeddings[tail_idx]\n",
    "    \n",
    "    idx_data.append((head_entity,relation,tail_entity))\n",
    "    \n",
    "idx_data = np.array(idx_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#denoising autoencoder vs baseline autoencoder\n",
    "#use gradients??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "\n",
    "head_input = tf.keras.layers.Input(shape=(1,),name='head_input')\n",
    "relation_input = tf.keras.layers.Input(shape=(1,), name='relation_input')\n",
    "tail_input = tf.keras.layers.Input(shape=(1,),name='tail_input')\n",
    "\n",
    "entity_embed = tf.keras.layers.Embedding(\n",
    "    input_dim=NUM_ENTITIES, \n",
    "    output_dim=NUM_DIMS, \n",
    "    weights=[entity_embeddings],\n",
    "    trainable=False,\n",
    "    name='entity_embed')\n",
    "\n",
    "relation_embed = tf.keras.layers.Embedding(\n",
    "    input_dim=NUM_RELATIONS, \n",
    "    output_dim=NUM_DIMS, \n",
    "    weights=[relation_embeddings],\n",
    "    trainable=False,\n",
    "    name='relation_embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_entity = entity_embed(head_input)\n",
    "tail_entity = entity_embed(tail_input)\n",
    "relation_entity = relation_embed(relation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = tf.keras.layers.Multiply()([head_entity, relation_entity, tail_entity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(NUM_DIMS, activation='relu', name='dense_1')(vector)\n",
    "flatten = tf.keras.layers.Flatten()(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_output = tf.keras.layers.Dense(NUM_ENTITIES, name='entity_output')\n",
    "relation_output = tf.keras.layers.Dense(NUM_RELATIONS, name='relation_output')\n",
    "\n",
    "head_output = entity_output(flatten)\n",
    "tail_output = entity_output(flatten)\n",
    "rel_output = relation_output(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#('Eve', 'type', 'Person') [('Eve', 'type', 'Lecturer'), ('Lecturer', 'subClassOf', 'Person')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in X:\n",
    "#     if tuple(i) in traces:\n",
    "#         print(tuple(i),traces[tuple(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.GradientTape(persistent=True) as g:\n",
    "    \n",
    "#     x = tf.Variable([1.0, 2.0])\n",
    "#     y = tf.Variable([1.0, 2.0])\n",
    "#     z = tf.Variable([1.0, 2.0])\n",
    "    \n",
    "#     output = loss(x,y,z)\n",
    "\n",
    "#     grads = g.gradient(output, x)\n",
    "\n",
    "# print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h,r,t, neg_h, neg_r, neg_t,margin):\n",
    "    return tf.math.maximum(\n",
    "        tf.norm(h + r - t) + tf.norm(neg_h + neg_r - neg_t) + margin,0)\n",
    "\n",
    "def score(h,r,t):\n",
    "    return tf.norm(h + r - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(h,r,t, loss_fun):\n",
    "\n",
    "    with tf.GradientTape() as tape_:\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            tape.watch(h)\n",
    "            tape.watch(r)\n",
    "            tape.watch(t)\n",
    "            \n",
    "            output = loss_fun(h,r,t)\n",
    "\n",
    "        jacobian = tape.jacobian(output, h)\n",
    "\n",
    "    return tape_.jacobian(jacobian, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.linalg.matmul(hessian(tf.Variable([1.0, 2.0]),tf.Variable([1.0, 2.0]),tf.Variable([1.0, 2.0]),loss_fun=score), \n",
    "#             tf.convert_to_tensor([[1],[2]],dtype=tf.float32))\n",
    "# tf.linalg.inv(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_gradient(h,r,t,score_fun):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        tape.watch(h)\n",
    "        tape.watch(r)\n",
    "        tape.watch(t)\n",
    "        \n",
    "        output = score_fun(x,y,z)\n",
    "        \n",
    "    return tf.reshape(tape.gradient(output,h),shape=(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj_gradient\n",
    "\n",
    "mat = np.zeros((5,3,5))\n",
    "mat[1,0,2] = 1\n",
    "\n",
    "A = tf.convert_to_tensor(mat,dtype=tf.float32)\n",
    "embeddings = tf.convert_to_tensor(np.array([[1.0,2.0],[1.0,3.0],[1.0,4.0]]))\n",
    "i=1\n",
    "j=0\n",
    "k=2\n",
    "indices = tf.convert_to_tensor([1,0,2])\n",
    "# with tf.GradientTape(persistent=True) as tape:\n",
    "    \n",
    "#     tape.watch(A)\n",
    "    \n",
    "#     h = tf.Variable([1.0, 2.0])\n",
    "#     r = tf.Variable([1.0, 2.0])\n",
    "#     t = tf.Variable([1.0, 2.0])\n",
    "    \n",
    "#     a = A[i,j,k]\n",
    "    \n",
    "#     loss = score(h,r,t)\n",
    "    \n",
    "#     f_hat = tape.gradient(loss, h)\n",
    "\n",
    "# print(tape.gradient(f_hat, a))\n",
    "with tf.GradientTape() as tape_:\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        tape.watch(A)\n",
    "        tape.watch(embeddings)\n",
    "        \n",
    "        h = tf.Variable([[1.0, 2.0]])\n",
    "        r = tf.Variable([[1.0, 3.0]])\n",
    "        t = tf.Variable([[1.0, 4.0]])\n",
    "        \n",
    "        #h,r,t = tf.nn.embedding_lookup(embeddings,[i,j,k])\n",
    "\n",
    "        a = A[i,j,k]\n",
    "\n",
    "        loss = score(h,r,t)\n",
    "\n",
    "        f_hat = tape.gradient(loss, h)\n",
    "\n",
    "    #print(tape_.gradient(f_hat, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 2.]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 3.]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 4.]], dtype=float32)>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape_.watched_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
