{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import os\n",
    "import cne\n",
    "import maxent\n",
    "from scipy.stats import halfnorm\n",
    "import utils\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 4\n"
     ]
    }
   ],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "print(f'CPU count: {joblib.cpu_count()}')\n",
    "\n",
    "data = np.load(os.path.join('.','data','royalty_spouse.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data['X_train']\n",
    "test = data['X_test']\n",
    "\n",
    "train_exp = data['train_exp']\n",
    "test_exp = data['test_exp']\n",
    "\n",
    "\n",
    "full_train = np.concatenate((train,train_exp.reshape(-1,3)), axis=0)\n",
    "full_test = np.concatenate((test,test_exp.reshape(-1,3)), axis=0)\n",
    "full_data = np.concatenate((full_train,full_test), axis=0)\n",
    "\n",
    "entities = data['entities'].tolist()\n",
    "relations = data['relations'].tolist()\n",
    "\n",
    "num_entities = len(entities)\n",
    "num_relations = len(relations)\n",
    "\n",
    "ent2idx = dict(zip(entities, range(num_entities)))\n",
    "rel2idx = dict(zip(relations, range(num_relations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2idx = utils.array2idx(full_train,ent2idx,rel2idx)\n",
    "test2idx = utils.array2idx(test,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = utils.get_adjacency_matrix(full_train,entities,num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "s1 = 1\n",
    "s2 = 1.5\n",
    "learning_rate = .001\n",
    "max_iter = 2\n",
    "gamma = (1/(s1**2)) - (1/(s2**2))\n",
    "top_k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, grad norm: 645.6384, obj: 112601.1830, obj smoothness: 112601.1830\n",
      "Epoch: 1, grad norm: 644.9050, obj: 112375.4409, obj smoothness: 225.7422\n"
     ]
    }
   ],
   "source": [
    "prior = maxent.BGDistr(A) \n",
    "prior.fit()\n",
    "\n",
    "CNE = cne.ConditionalNetworkEmbedding(\n",
    "    A=A,\n",
    "    d=embedding_dim,\n",
    "    s1=s1,\n",
    "    s2=s2,\n",
    "    prior_dist=prior\n",
    "    )\n",
    "CNE.fit(lr=learning_rate, max_iter=max_iter)\n",
    "\n",
    "X = CNE._ConditionalNetworkEmbedding__emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pij(i,j,s1,s2,prior):\n",
    "    \n",
    "    p_prior = prior.get_row_probability([i], [j])\n",
    "    \n",
    "    normal_s1 = halfnorm.rvs(loc=0,scale=s1,size=1,random_state=SEED)\n",
    "    normal_s2 = halfnorm.rvs(loc=0,scale=s2,size=1,random_state=SEED)\n",
    "    \n",
    "    numerator = p_prior * normal_s1\n",
    "    denom = numerator + (1-p_prior)*normal_s2\n",
    "    \n",
    "    return numerator/denom\n",
    "\n",
    "def get_hessian(i,s1,s2,gamma,X,A,embedding_dim):\n",
    "    \n",
    "    hessian = np.zeros(shape=(embedding_dim,embedding_dim))\n",
    "\n",
    "    for j in range(A.shape[0]):\n",
    "\n",
    "        if i != j:\n",
    "\n",
    "            x_i = X[i,:]\n",
    "            x_j = X[j,:]\n",
    "\n",
    "            x_diff = (x_i - x_j).reshape(-1,1)  \n",
    "            \n",
    "            prob = get_pij(i,j,s1,s2,prior)\n",
    "\n",
    "            h = (gamma**2) * np.dot(x_diff,x_diff.T) * (prob * (1-prob))\n",
    "\n",
    "            p_diff_mat = gamma * (prob - A[i,j])[0] * np.identity(h.shape[0])\n",
    "\n",
    "            hessian += (p_diff_mat - h)\n",
    "            \n",
    "    return hessian\n",
    "\n",
    "def explaiNE(i,j,k,l,s1,s2,embedding_dim,gamma,X,A):\n",
    "\n",
    "    hessian = get_hessian(i=i,s1=s1,s2=s2,gamma=gamma,X=X,A=A,embedding_dim=embedding_dim)\n",
    "    pij = get_pij(i=i,j=j,s1=s1,s2=s2,prior=prior)\n",
    "\n",
    "    invert = (-hessian) / ((gamma**2 * (pij) * (1-pij)))\n",
    "\n",
    "    hess_inv = np.linalg.inv(invert)\n",
    "\n",
    "    x_i = X[i,:]\n",
    "    x_j = X[j,:]\n",
    "    x_k = X[k,:]\n",
    "    x_l = X[l,:]\n",
    "\n",
    "    xij_diff = (x_i - x_j).T\n",
    "\n",
    "    xlk_diff = (x_l - x_k)\n",
    "\n",
    "    return np.dot(np.dot(xij_diff, hess_inv), xlk_diff).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explanations(i,j,s1,s2,embedding_dim,gamma,X,A,top_k,train2idx):\n",
    "\n",
    "    row,col = A.nonzero()\n",
    "\n",
    "    neighbors = []\n",
    "\n",
    "    for idx, l in enumerate(col):\n",
    "        if l == i:\n",
    "\n",
    "            if (i,j) != (row[idx],col[idx]):\n",
    "\n",
    "                neighbors.append([row[idx],col[idx]])\n",
    "\n",
    "    if len(neighbors) > top_k:\n",
    "\n",
    "        temp = []\n",
    "\n",
    "        for k,l in neighbors:\n",
    "\n",
    "            score = explaiNE(i,j,k,l,s1,s2,embedding_dim,gamma,X,A)\n",
    "\n",
    "            temp.append(((k,l),score))\n",
    "\n",
    "        # temp = joblib.Parallel(n_jobs=-2,verbose=20)(joblib.delayed(loop)(i,j,\n",
    "        #     k,l,s1,s2,embedding_dim,gamma,X,A, train2idx) for k,l in neighbors)\n",
    "\n",
    "    else:\n",
    "\n",
    "        temp = []\n",
    "\n",
    "        for k,_,l in train2idx[0:5]:\n",
    "\n",
    "            if (i,j) != (k,l):\n",
    "\n",
    "                score = explaiNE(i,j,k,l,s1,s2,embedding_dim,gamma,X,A)\n",
    "\n",
    "                temp.append(((k,l),score))\n",
    "\n",
    "        # temp = joblib.Parallel(n_jobs=-2,verbose=20)(joblib.delayed(loop)(i,j,\n",
    "        #     k,l,s1,s2,embedding_dim,gamma,X,A, train2idx) for k,_,l in train2idx if (i,j) != (k,l))\n",
    "\n",
    "    sorted_scores = sorted(temp,key=lambda x:x[1], reverse=True)[0:top_k]\n",
    "\n",
    "    explanation = [np.array(tup) for tup,_ in sorted_scores]\n",
    "\n",
    "    return np.array(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_scores = sorted(temp,key=lambda x:x[1], reverse=True)[0:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   1 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   2 | elapsed:   15.5s finished\n"
     ]
    }
   ],
   "source": [
    "explanations = joblib.Parallel(n_jobs=-2, verbose=20)(\n",
    "    joblib.delayed(get_explanations)(i,j,s1,s2,embedding_dim,gamma,X,A,top_k,train2idx) for i,_,j in test2idx[0:2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(explanations).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.jaccard_score(explanation,explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.jaccard_score(np.array(explanations), np.array(explanations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testexp2idx = utils.array2idx(test_exp,ent2idx,rel2idx)\n",
    "\n",
    "a = np.concatenate([testexp2idx[:,:,0],testexp2idx[:,:,2]],axis=1).reshape(-1,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.jaccard_score(a[0:2],np.array(explanations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
