{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb15k_237 = np.load('./data/fb15k_237.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_train = fb15k_237['train']\n",
    "fb_valid = fb15k_237['valid']\n",
    "fb_test = fb15k_237['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = set(np.concatenate((fb_train[:,0], fb_train[:,2]), axis=0))\n",
    "all_relations = set(fb_train[:,1])\n",
    "\n",
    "num_entities = len(entities)\n",
    "num_relations = len(all_relations)\n",
    "\n",
    "ent2idx = dict(zip(entities, range(num_entities)))\n",
    "rel2idx = dict(zip(all_relations, range(num_relations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2idx = []\n",
    "\n",
    "for head, rel, tail in fb_train:\n",
    "    \n",
    "    head_idx = ent2idx[head]\n",
    "    tail_idx = ent2idx[tail]\n",
    "    rel_idx = rel2idx[rel]\n",
    "\n",
    "    train2idx.append([head_idx, rel_idx, tail_idx])\n",
    "    \n",
    "train2idx = np.array(train2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_embedding = tf.keras.layers.Embedding(\n",
    "#     input_dim=num_entities,\n",
    "#     output_dim=embedding_size\n",
    "#     )\n",
    "# relation_embedding = tf.keras.layers.Embedding(\n",
    "#     input_dim=num_relations,\n",
    "#     output_dim=embedding_size\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 2\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 2\n",
    "MARGIN = 1\n",
    "ent_shape = (num_entities, EMBEDDING_SIZE)\n",
    "rel_shape = (num_relations, EMBEDDING_SIZE)\n",
    "\n",
    "sqrt_size = 6 / np.sqrt(EMBEDDING_SIZE)\n",
    "\n",
    "ent_embeddings = tf.Variable(\n",
    "    initial_value=tf.random.uniform(shape=ent_shape, minval=-sqrt_size, maxval=sqrt_size), \n",
    "    trainable=True, \n",
    "    shape=ent_shape\n",
    "    )\n",
    "\n",
    "rel_embeddings = tf.Variable(\n",
    "    initial_value=tf.random.uniform(shape=rel_shape, minval=-sqrt_size, maxval=sqrt_size), \n",
    "    trainable=True, \n",
    "    shape=rel_shape\n",
    "    )\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train2idx[:,0], train2idx[:,1], train2idx[:,2])).batch(BATCH_SIZE)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_triples(head, rel, tail):\n",
    "    \n",
    "    cond = tf.random.uniform(head.shape, 0, 2, dtype=tf.int64) #1 means keep entity\n",
    "    rnd = tf.random.uniform(head.shape, 0, num_entities-1, dtype=tf.int64)\n",
    "    \n",
    "    neg_head = tf.where(cond == 1, head, rnd)\n",
    "    neg_tail = tf.where(cond == 1, rnd, tail)   \n",
    "    \n",
    "    return neg_head, neg_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for head, rel, tail in train_data:\n",
    "        \n",
    "        neg_head, neg_tail = get_negative_triples(head, rel, tail)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            pos_h_e = tf.nn.embedding_lookup(ent_embeddings,head)\n",
    "            pos_t_e = tf.nn.embedding_lookup(ent_embeddings,tail)\n",
    "            pos_r_e = tf.nn.embedding_lookup(rel_embeddings, rel)\n",
    "\n",
    "            neg_h_e = tf.nn.embedding_lookup(ent_embeddings,neg_head)\n",
    "            neg_t_e = tf.nn.embedding_lookup(ent_embeddings,neg_tail)\n",
    "            neg_r_e = tf.nn.embedding_lookup(rel_embeddings, rel)\n",
    "\n",
    "            pos = tf.reduce_sum(tf.square(pos_h_e + pos_r_e - pos_t_e), axis=1, keepdims=True)\n",
    "            neg = tf.reduce_sum(tf.square(neg_h_e + neg_r_e - neg_t_e), axis=1, keepdims=True)    \n",
    "\n",
    "            embedding_loss = tf.reduce_sum(tf.maximum(pos - neg + MARGIN, 0))\n",
    "        \n",
    "        grads = tape.gradient(embedding_loss,[ent_embeddings, rel_embeddings])\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, [ent_embeddings, rel_embeddings]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
