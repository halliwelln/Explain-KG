{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = np.matrix('1, 1, 1, 1;'\n",
    "#                    '1, 0, 0, 0;'\n",
    "#                    '0, 1, 0, 1;'\n",
    "#                    '0, 0, 1, 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree = np.array(matrix).sum(axis=1)\n",
    "# degree_mat = np.diag(degree)\n",
    "# degree_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import karate_club_graph, to_numpy_matrix\n",
    "zkc = karate_club_graph()\n",
    "order = sorted(list(zkc.nodes()))\n",
    "A = to_numpy_matrix(zkc, nodelist=order)\n",
    "I = np.eye(zkc.number_of_nodes())\n",
    "A_hat = A + I\n",
    "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
    "#D_hat = np.matrix(np.diag(D_hat))**-1\n",
    "D_hat = np.linalg.inv(np.diag(D_hat))\n",
    "\n",
    "#degree_indices = [[i,i] for i in range(zkc.number_of_nodes())]\n",
    "#D_hat_sparse = tf.sparse.SparseTensor(degree_indices,values=D_hat,dense_shape=[34,34])\n",
    "D_indices = []\n",
    "D_values = []\n",
    "for i in range(len(D_hat)):\n",
    "    \n",
    "    for j in range(len(D_hat)):\n",
    "        \n",
    "        if D_hat[i,j] != 0:\n",
    "            \n",
    "            D_indices.append([i,j])\n",
    "            D_values.append(np.sqrt(D_hat[i,j]))\n",
    "\n",
    "D_hat_inv_sparse = tf.sparse.SparseTensor(D_indices,values=D_values,dense_shape=[34,34])      \n",
    "# W_1 = np.random.normal(\n",
    "#     loc=0, scale=1, size=(zkc.number_of_nodes(), 4))\n",
    "# W_2 = np.random.normal(\n",
    "#     loc=0, size=(W_1.shape[1], 2))\n",
    "\n",
    "# def gcn_layer(A_hat, D_hat, X, W):\n",
    "#     return D_hat**-1 * A_hat * X * W\n",
    "# H_1 = gcn_layer(A_hat, D_hat, I, W_1)\n",
    "# H_2 = gcn_layer(A_hat, D_hat, H_1, W_2)\n",
    "# output = H_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.sparse import csr_matrix\n",
    "\n",
    "# A_hat = csr_matrix(np.array(A_hat))\n",
    "# I = csr_matrix(np.array(I))\n",
    "# D_hat = csr_matrix(np.array(D_hat))\n",
    "X_indices = []\n",
    "X_values = []\n",
    "for i in range(len(I)):\n",
    "    \n",
    "    for j in range(len(I)):\n",
    "        \n",
    "        if I[i,j] != 0:\n",
    "            \n",
    "            X_indices.append([i,j])\n",
    "            X_values.append(I[i,j])\n",
    "            \n",
    "X_sparse = tf.sparse.SparseTensor(X_indices,values=X_values,dense_shape=[34,34])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_indices = []\n",
    "for i in range(len(A_hat)):\n",
    "    \n",
    "    for j in range(len(A_hat)):\n",
    "        \n",
    "        if A_hat[i,j] == 1.:\n",
    "            \n",
    "            adj_indices.append([i,j])\n",
    "            \n",
    "#indices = tf.cast(tf.convert_to_tensor(indices),dtype=tf.int64)\n",
    "#values = tf.cast(tf.convert_to_tensor(np.ones(len(indices))),dtype=tf.int64)\n",
    "A_hat_sparse = tf.sparse.SparseTensor(adj_indices,np.ones(len(adj_indices)), dense_shape=[34,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = tf.cast(tf.convert_to_tensor(indices),dtype=tf.int64)\n",
    "# values = tf.cast(tf.convert_to_tensor(np.ones(len(indices))),dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.matmul(np.randn(A_hat.shape))\n",
    "#tf.matmul(A_hat,A_hat,a_is_sparse=True,b_is_sparse=True)\n",
    "\n",
    "#tf.matmul(a_sparse,a_sparse,a_is_sparse=True,b_is_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,**kwargs):\n",
    "        super(GCN,self).__init__(**kwargs)\n",
    "        self.units=units\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1][-1],self.units),\n",
    "            trainable=True,\n",
    "            name='kernel',\n",
    "            initializer=tf.keras.initializers.RandomNormal(seed=SEED)\n",
    "        )\n",
    "\n",
    "    def call(self,inputs):\n",
    "\n",
    "        D_hat_inv,A_hat,H = inputs\n",
    "        \n",
    "        #DHW = tf.matmul(D_hat_inv,tf.matmul(H,self.kernel))\n",
    "        #output = tf.matmul(D_hat_inv,tf.matmul(A_hat,DHW))\n",
    "\n",
    "        DHW = tf.keras.backend.dot(D_hat_inv,tf.keras.backend.dot(H,self.kernel))\n",
    "        output = tf.keras.backend.dot(D_hat_inv,tf.keras.backend.dot(A_hat,DHW))\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(GCN, self).get_config()\n",
    "        config = {'units': self.units}\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k hop subgraph -> Adjacency matrix of k neighbors? Features for k neighbors\n",
    "#define masks (2 vectors, 1 for each node, feature mask?)\n",
    "#feed masked data into model to compute predictions: subgraph preds vs masked subgraph preds\n",
    "\n",
    "#why return node and edge feature mask?\n",
    "\n",
    "#a = tf.keras.layers.ReLU()(GCN(4)([D_hat**-1,A_hat,I])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x155cf1910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FEATURES = I.shape[0]\n",
    "feature_input = tf.keras.layers.Input(shape=(NUM_FEATURES,),sparse=True,name='feature_input')\n",
    "adjacency_input = tf.keras.layers.Input(shape=(NUM_FEATURES,),sparse=True,name='adjacency_input')\n",
    "degree_input = tf.keras.layers.Input(shape=(NUM_FEATURES,),sparse=True,name='degree_input')\n",
    "\n",
    "# feature_mask = tf.keras.layers.Masking(mask_value=-1,name='feature_mask')(feature_input)\n",
    "# adjacency_mask = tf.keras.layers.Masking(mask_value=-1,name='adjacency_mask')(adjacency_input)\n",
    "# degree_mask = tf.keras.layers.Masking(mask_value=-1,name='degree_mask')(degree_input)\n",
    "\n",
    "gcn_ = GCN(4,name='gcn')([degree_input,adjacency_input,feature_input])\n",
    "a2 = tf.keras.layers.Activation('sigmoid')(gcn_)\n",
    "model = tf.keras.Model(inputs=[degree_input,adjacency_input,feature_input], outputs=a2)\n",
    "\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy')\n",
    "\n",
    "#model.fit(x=[D_hat,A_hat,I],y=tf.keras.utils.to_categorical(np.ones(34),4),batch_size=34)\n",
    "model.fit(x=[D_hat_inv_sparse,A_hat_sparse,X_sparse],y=tf.keras.utils.to_categorical(np.ones(34),4),\n",
    "          batch_size=34,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = np.array([\n",
    "        \n",
    "#             [0, 1, 2],\n",
    "#             [2, 3, 4],\n",
    "#             [4, 5, 6],\n",
    "#             [7, 7, 8],\n",
    "        \n",
    "#     ], dtype=K.floatx())\n",
    "# input_edge = np.array([\n",
    "        \n",
    "#             [1, 1, 1, 0],\n",
    "#             [1, 1, 0, 0],\n",
    "#             [1, 0, 1, 0],\n",
    "#             [0, 0, 0, 1],\n",
    "        \n",
    "#     ], dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
