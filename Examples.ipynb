{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb15k_237 = np.load('./data/fb15k_237.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_train = fb15k_237['train']\n",
    "fb_valid = fb15k_237['valid']\n",
    "fb_test = fb15k_237['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = set(np.concatenate((fb_train[:,0], fb_train[:,2]), axis=0))\n",
    "all_relations = set(fb_train[:,1])\n",
    "\n",
    "num_entities = len(entities)\n",
    "num_relations = len(all_relations)\n",
    "\n",
    "ent2idx = dict(zip(entities, range(num_entities)))\n",
    "rel2idx = dict(zip(all_relations, range(num_relations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2idx = []\n",
    "\n",
    "for head, rel, tail in fb_train:\n",
    "    \n",
    "    head_idx = ent2idx[head]\n",
    "    tail_idx = ent2idx[tail]\n",
    "    rel_idx = rel2idx[rel]\n",
    "\n",
    "    train2idx.append([head_idx, rel_idx, tail_idx])\n",
    "    \n",
    "train2idx = np.array(train2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid2idx = []\n",
    "\n",
    "for head, rel, tail in fb_valid:\n",
    "    \n",
    "    head_idx = ent2idx[head]\n",
    "    tail_idx = ent2idx[tail]\n",
    "    rel_idx = rel2idx[rel]\n",
    "\n",
    "    valid2idx.append([head_idx, rel_idx, tail_idx])\n",
    "    \n",
    "valid2idx = np.array(valid2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 10\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 2\n",
    "MARGIN = 2\n",
    "SQRT_SIZE = 6 / np.sqrt(EMBEDDING_SIZE)\n",
    "\n",
    "pos_head_input = tf.keras.layers.Input(shape=(1,), name='pos_head_input')\n",
    "neg_head_input = tf.keras.layers.Input(shape=(1,), name='neg_head_input')\n",
    "pos_tail_input = tf.keras.layers.Input(shape=(1,), name='pos_tail_input')\n",
    "neg_tail_input = tf.keras.layers.Input(shape=(1,), name='neg_tail_input')\n",
    "relation_input = tf.keras.layers.Input(shape=(1,), name='relation_input')\n",
    "\n",
    "entity_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=num_entities,\n",
    "    output_dim=EMBEDDING_SIZE,\n",
    "    name='entity_embeddings',\n",
    "    #embeddings_initializer=tf.keras.initializers.RandomUniform(minval=-SQRT_SIZE, maxval=SQRT_SIZE, seed=123)\n",
    "    #embeddings_regularizer=tf.keras.regularizers.l2(.01)\n",
    "    )\n",
    "\n",
    "relation_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=num_relations,\n",
    "    output_dim=EMBEDDING_SIZE,\n",
    "    name='relation_embeddings',\n",
    "    #embeddings_initializer=tf.keras.initializers.RandomUniform(minval=-SQRT_SIZE, maxval=SQRT_SIZE, seed=123)\n",
    "    #embeddings_regularizer=tf.keras.regularizers.l2(.01)\n",
    "    )\n",
    "\n",
    "pos_head_e = entity_embedding(pos_head_input)\n",
    "neg_head_e = entity_embedding(neg_head_input)\n",
    "pos_tail_e = entity_embedding(pos_tail_input)\n",
    "neg_tail_e = entity_embedding(neg_tail_input)\n",
    "rel_e = relation_embedding(relation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(\n",
    "    inputs=[\n",
    "        pos_head_input,\n",
    "        neg_head_input, \n",
    "        pos_tail_input, \n",
    "        neg_tail_input, \n",
    "        relation_input\n",
    "        ], \n",
    "    outputs=[\n",
    "        pos_head_e,\n",
    "        neg_head_e, \n",
    "        pos_tail_e, \n",
    "        neg_tail_e, \n",
    "        rel_e\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ent_shape = (num_entities, EMBEDDING_SIZE)\n",
    "# rel_shape = (num_relations, EMBEDDING_SIZE)\n",
    "\n",
    "# sqrt_size = 6 / np.sqrt(EMBEDDING_SIZE)\n",
    "\n",
    "# ent_embeddings = tf.Variable(\n",
    "#     initial_value=tf.random.uniform(shape=ent_shape, minval=-sqrt_size, maxval=sqrt_size), \n",
    "#     trainable=True, \n",
    "#     shape=ent_shape\n",
    "#     )\n",
    "\n",
    "# rel_embeddings = tf.Variable(\n",
    "#     initial_value=tf.random.uniform(shape=rel_shape, minval=-sqrt_size, maxval=sqrt_size), \n",
    "#     trainable=True, \n",
    "#     shape=rel_shape\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negative_triples(head, rel, tail):\n",
    "    \n",
    "    cond = tf.random.uniform(head.shape, 0, 2, dtype=tf.int64) #1 means keep entity\n",
    "    rnd = tf.random.uniform(head.shape, 0, num_entities-1, dtype=tf.int64)\n",
    "    \n",
    "    neg_head = tf.where(cond == 1, head, rnd)\n",
    "    neg_tail = tf.where(cond == 1, rnd, tail)   \n",
    "    \n",
    "    return neg_head, neg_tail\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train2idx[:,0], train2idx[:,1], train2idx[:,2]))\n",
    "train_data = train_data.shuffle(buffer_size=50000).batch(BATCH_SIZE)\n",
    "\n",
    "#exp_decay = tf.keras.optimizers.schedules.ExponentialDecay(.01, 1000, .05)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(10):\n",
    "    \n",
    "#     for head, rel, tail in train_data:\n",
    "        \n",
    "#         neg_head, neg_tail = get_negative_triples(head, rel, tail)\n",
    "\n",
    "#         with tf.GradientTape() as tape:\n",
    "\n",
    "#             pos_h_e = tf.nn.embedding_lookup(ent_embeddings,head)\n",
    "#             pos_t_e = tf.nn.embedding_lookup(ent_embeddings,tail)\n",
    "#             pos_r_e = tf.nn.embedding_lookup(rel_embeddings,rel)\n",
    "\n",
    "#             neg_h_e = tf.nn.embedding_lookup(ent_embeddings,neg_head)\n",
    "#             neg_t_e = tf.nn.embedding_lookup(ent_embeddings,neg_tail)\n",
    "#             neg_r_e = tf.nn.embedding_lookup(rel_embeddings,rel)\n",
    "\n",
    "#             pos = tf.reduce_sum(tf.square(pos_h_e + pos_r_e - pos_t_e), axis=1, keepdims=True)\n",
    "#             neg = tf.reduce_sum(tf.square(neg_h_e + neg_r_e - neg_t_e), axis=1, keepdims=True)    \n",
    "\n",
    "#             embedding_loss = tf.reduce_sum(tf.maximum(pos - neg + MARGIN, 0))\n",
    "        \n",
    "#         transE_grads = tape.gradient(embedding_loss,[ent_embeddings, rel_embeddings])\n",
    "\n",
    "#         optimizer.apply_gradients(zip(transE_grads, [ent_embeddings, rel_embeddings]))\n",
    "        \n",
    "#     print('Current loss ', embedding_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 114.58287 at epoch 0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    for head, rel, tail in train_data:\n",
    "                \n",
    "        neg_head, neg_tail = get_negative_triples(head, rel, tail)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            pos_head_e,neg_head_e, pos_tail_e, neg_tail_e, rel_e = model([head, neg_head, tail, neg_tail, rel])\n",
    "            \n",
    "            pos = tf.reduce_sum(tf.square(pos_head_e + rel_e - pos_tail_e), axis=1, keepdims=True)\n",
    "            neg = tf.reduce_sum(tf.square(neg_head_e + rel_e - neg_tail_e), axis=1, keepdims=True)    \n",
    "\n",
    "            embedding_loss = tf.reduce_sum(tf.maximum(pos - neg + MARGIN, 0))\n",
    "            \n",
    "        grads = tape.gradient(embedding_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    \n",
    "    if not epoch % 10:\n",
    "        print('Current loss' , embedding_loss.numpy(),'at epoch', epoch)\n",
    "    \n",
    "    losses.append(embedding_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
