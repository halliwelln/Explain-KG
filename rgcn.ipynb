{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "data = np.load(os.path.join('.','data','royalty.npz'))\n",
    "\n",
    "triples = data['triples']\n",
    "traces = data['traces']\n",
    "entities = data['entities'].tolist()\n",
    "num_entities = len(entities)\n",
    "relations = data['relations'].tolist()\n",
    "num_relations = len(relations)\n",
    "embedding_dim = 3\n",
    "ent2idx = dict(zip(entities, range(num_entities)))\n",
    "rel2idx = dict(zip(relations, range(num_relations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2idx = utils.array2idx(triples, ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.python.ops import embedding_ops\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "entity_embeddings = Embedding(\n",
    "    input_dim=num_entities,\n",
    "    output_dim=embedding_dim,\n",
    "    name='entity_embeddings',\n",
    "    embeddings_initializer=RandomUniform(\n",
    "        minval=-1,\n",
    "        maxval=1,\n",
    "        seed=SEED\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_input = tf.keras.Input(shape=(), name='head_input',dtype=tf.int64)\n",
    "rel_input = tf.keras.Input(shape=(), name='rel_input',dtype=tf.int64)\n",
    "tail_input = tf.keras.Input(shape=(), name='tail_input',dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_e = entity_embeddings(head_input)\n",
    "tail_e = entity_embeddings(tail_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_relations,output_dim,**kwargs):\n",
    "        super(RGCN_Layer,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        self.output_dim = output_dim\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "\n",
    "        in_shape = input_shape[-1][-1]\n",
    "\n",
    "        self.W_r = self.add_weight(\n",
    "            shape=(self.num_relations,self.output_dim,in_shape),\n",
    "            trainable=True,\n",
    "            initializer=\"random_normal\",\n",
    "            name='W_r'\n",
    "        )\n",
    "        \n",
    "        self.W0 = self.add_weight(\n",
    "            shape=(self.output_dim,in_shape),\n",
    "            trainable=True,\n",
    "            initializer='random_normal',\n",
    "            name='W0'\n",
    "        )\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        head_input,tail_input = inputs\n",
    "        \n",
    "        tail_update = tf.matmul(self.W_r,tail_input,transpose_b=True)\n",
    "        \n",
    "        head_update = tf.matmul(self.W0,head_input,transpose_b=True)\n",
    "        \n",
    "        update = tf.reduce_sum(tail_update + head_update, axis=0)\n",
    "\n",
    "        return tf.transpose(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistMult(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_relations,**kwargs):\n",
    "        super(DistMult,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        embedding_dim = input_shape[0][-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.num_relations,embedding_dim),\n",
    "            trainable=True,\n",
    "            initializer='random_normal',\n",
    "            name='rel_embedding'\n",
    "        )\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        head_e,rel_idx,tail_e = inputs\n",
    "        \n",
    "        rel_e = embedding_ops.embedding_lookup_v2(self.kernel,rel_idx)\n",
    "        \n",
    "        return tf.reduce_sum(head_e*rel_e*tail_e, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x194dc596d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x194dc596d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x194dc59a90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x194dc59a90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "new_head = RGCN_Layer(num_relations=num_relations,output_dim=5)([head_e,tail_e])\n",
    "new_head = tf.keras.layers.Activation('sigmoid')(new_head)\n",
    "\n",
    "new_tail = RGCN_Layer(num_relations=num_relations,output_dim=5)([tail_e,head_e])\n",
    "new_tail = tf.keras.layers.Activation('sigmoid')(new_tail)\n",
    "\n",
    "output = DistMult(num_relations=num_relations)([new_head,rel_input,new_tail])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.Model([head_input,rel_input,tail_input],[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x=[train2idx[:,0],train2idx[:,1],train2idx[:,2]],y=np.ones(train2idx.shape[0]),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN_Model(tf.keras.Model):\n",
    "    def __init__(self,num_entities,*args,**kwargs):\n",
    "        super(RGCN_Model,self).__init__(*args, **kwargs)\n",
    "        self.num_entities = num_entities\n",
    "        \n",
    "    def train_step(self,data):\n",
    "\n",
    "        pos_head,rel,pos_tail = data[0]\n",
    "        y = data[1]\n",
    "        \n",
    "        neg_head, neg_tail = utils.get_negative_triples(\n",
    "            head=pos_head, \n",
    "            rel=rel, \n",
    "            tail=pos_tail,\n",
    "            num_entities=self.num_entities\n",
    "            )\n",
    "        \n",
    "        head = tf.concat([pos_head,neg_head],axis=0)\n",
    "        rel = tf.concat([rel,rel],axis=0)\n",
    "        tail = tf.concat([pos_tail,neg_tail],axis=0)\n",
    "        \n",
    "        y_neg = tf.zeros_like(y)\n",
    "        \n",
    "        y = tf.concat([y,y_neg],axis=0)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            y_pred = self([head,rel,tail],training=True)\n",
    "            \n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "            \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN_Model(inputs=[head_input,rel_input,tail_input],outputs=[output],num_entities=num_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x194de2f290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x194de2f290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x194de0e310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[train2idx[:,0],train2idx[:,1],train2idx[:,2]],y=np.ones(train2idx.shape[0]),epochs=2000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dgl\n",
    "# import torch as th\n",
    "# from dgl.nn import RelGraphConv\n",
    "# g = dgl.graph(([0,1,2,3,2,5,0], [1,2,3,4,0,3,1]))\n",
    "# conv = RelGraphConv(10, 5, 3, regularizer='basis')\n",
    "# feat = th.ones(6, 10)\n",
    "# etype = th.tensor(np.array([0,1,2,0,1,2,1]).astype(np.int64))\n",
    "# conv(g, feat, etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734378401915959"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict([train2idx[:,0],train2idx[:,1],train2idx[:,2]]) > .5).sum()/train2idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 583, 5732,  781, ..., 4703, 2114, 1917])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for triple i:\n",
    "    #get k hop subgraph?\n",
    "    #compute pred \n",
    "    #define masks\n",
    "    #optimize loss, return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjlist(train2idx,entities):\n",
    "\n",
    "    adj_list = [[] for _ in entities]\n",
    "\n",
    "    for i,triplet in enumerate(train2idx):\n",
    "        adj_list[triplet[0]].append([i, triplet[2]])\n",
    "        adj_list[triplet[2]].append([i, triplet[0]])\n",
    "\n",
    "    degrees = np.array([len(a) for a in adj_list])\n",
    "    adj_list = [np.array(a) for a in adj_list]\n",
    "    \n",
    "    return adj_list,degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_adjlist(train2idx,entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
