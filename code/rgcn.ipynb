{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "data = np.load(os.path.join('..','data','royalty.npz'))\n",
    "\n",
    "# triples = data['triples']\n",
    "# traces = data['traces']\n",
    "entities = data['entities'].tolist()\n",
    "num_entities = len(entities)\n",
    "relations = data['relations'].tolist()\n",
    "num_relations = len(relations)\n",
    "embedding_dim = 3\n",
    "ent2idx = dict(zip(entities, range(num_entities)))\n",
    "rel2idx = dict(zip(relations, range(num_relations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples, traces = data['grandmother_triples'], data['grandmother_traces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RGCN_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_relations,output_dim,**kwargs):\n",
    "        super(RGCN_Layer,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "\n",
    "        input_dim = int(input_shape[3][-1])\n",
    "        \n",
    "        self.relation_kernel = self.add_weight(\n",
    "            shape=(self.num_relations,input_dim, self.output_dim),\n",
    "            name=\"relation_kernels\",\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        self.self_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.output_dim),\n",
    "            name=\"self_kernel\",\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        embeddings,head_idx,tail_idx,head_e,tail_e,adj_mats = inputs\n",
    "\n",
    "        adj_mats = tf.squeeze(adj_mats,axis=0)\n",
    "        embeddings = tf.squeeze(embeddings,axis=0)\n",
    "\n",
    "        head_output = tf.matmul(head_e,self.self_kernel)\n",
    "        tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "        \n",
    "        for i in range(self.num_relations):\n",
    "            \n",
    "            adj_i = adj_mats[i]\n",
    "\n",
    "            head_adj = tf.nn.embedding_lookup(adj_i,head_idx)\n",
    "            tail_adj = tf.nn.embedding_lookup(adj_i,tail_idx)\n",
    "            \n",
    "            h_head = tf.matmul(head_adj,embeddings)\n",
    "            h_tail = tf.matmul(head_adj,embeddings)\n",
    "            \n",
    "            head_output += tf.matmul(h_head,self.relation_kernel[i])\n",
    "            tail_output += tf.matmul(h_tail,self.relation_kernel[i])\n",
    "        print(head_output)\n",
    "        return head_output,tail_output\n",
    "\n",
    "class DistMult(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_relations,**kwargs):\n",
    "        super(DistMult,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        embedding_dim = input_shape[0][-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.num_relations,embedding_dim),\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            ),\n",
    "            name='rel_embedding'\n",
    "        )\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        head_e,rel_idx,tail_e = inputs\n",
    "        \n",
    "        rel_e = tf.nn.embedding_lookup(self.kernel,rel_idx)\n",
    "        \n",
    "        return tf.sigmoid(tf.reduce_sum(head_e*rel_e*tail_e, axis=-1))\n",
    "\n",
    "def RGCN_Model(num_entities,num_relations,embedding_dim,output_dim,seed):\n",
    "\n",
    "    head_input = tf.keras.Input(shape=(None,), name='head_input',dtype=tf.int64)\n",
    "    rel_input = tf.keras.Input(shape=(None,), name='rel_input',dtype=tf.int64)\n",
    "    tail_input = tf.keras.Input(shape=(None,), name='tail_input',dtype=tf.int64)\n",
    "    all_entities = tf.keras.Input(shape=(num_entities), name='all_entities',dtype=tf.int64)\n",
    "\n",
    "    adj_inputs = tf.keras.Input(\n",
    "        shape=(\n",
    "            num_relations,\n",
    "            num_entities,\n",
    "            num_entities\n",
    "        ),\n",
    "        dtype=tf.float32,\n",
    "        name='adj_inputs'\n",
    "    )\n",
    "\n",
    "    entity_embeddings = Embedding(\n",
    "        input_dim=num_entities,\n",
    "        output_dim=embedding_dim,\n",
    "        name='entity_embeddings',\n",
    "        embeddings_initializer=tf.keras.initializers.RandomUniform(\n",
    "            minval=-1,\n",
    "            maxval=1,\n",
    "            seed=seed\n",
    "        )\n",
    "    )\n",
    "\n",
    "    head_e = entity_embeddings(head_input)\n",
    "    tail_e = entity_embeddings(tail_input)\n",
    "    all_e = entity_embeddings(all_entities)\n",
    "\n",
    "    new_head,new_tail = RGCN_Layer(num_relations=num_relations,output_dim=output_dim)([\n",
    "        all_e,\n",
    "        head_input,\n",
    "        tail_input,\n",
    "        head_e,\n",
    "        tail_e,\n",
    "        adj_inputs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    output = DistMult(num_relations=num_relations,name='output')([\n",
    "        new_head,rel_input,new_tail\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[\n",
    "            all_entities,\n",
    "            head_input,\n",
    "            rel_input,\n",
    "            tail_input,\n",
    "            adj_inputs\n",
    "        ],\n",
    "        outputs=[\n",
    "            output\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x194def9250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x194def9250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Tensor(\"rgcn__layer_2/add_6:0\", shape=(None, None, 5), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x10ef0b610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x10ef0b610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "data = np.load(os.path.join('..','data','royalty.npz'))\n",
    "\n",
    "entities = data['entities'].tolist()\n",
    "relations = data['relations'].tolist()\n",
    "\n",
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "EMBEDDING_DIM = 3\n",
    "OUTPUT_DIM = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "triples, traces = data['grandmother_triples'], data['grandmother_traces']\n",
    "\n",
    "train2idx = utils.array2idx(triples, ent2idx,rel2idx)[0:50]\n",
    "\n",
    "adj_mats = utils.get_adjacency_matrix_list(\n",
    "    num_relations=NUM_RELATIONS,\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    data=train2idx\n",
    ")\n",
    "\n",
    "train2idx = np.expand_dims(train2idx,axis=0)\n",
    "\n",
    "all_indices = np.arange(NUM_ENTITIES).reshape(1,-1)\n",
    "\n",
    "model = RGCN_Model(\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    num_relations=NUM_RELATIONS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.699007   -0.6982854   2.111158    1.1538045   1.0229496 ]\n",
      " [-1.2327528  -0.5284596   2.7230299  -0.10198206  0.97930473]\n",
      " [ 2.3285747  -1.7712145   1.3842101  -0.8483561   2.5338311 ]\n",
      " [-2.1758235   1.7526695  -0.09235287  1.2106485  -3.6162155 ]\n",
      " [-2.0883832   1.5262613   0.6255624   1.591172   -2.8304362 ]\n",
      " [-0.6130385   1.1747336  -2.6818242  -0.5391183  -2.8161879 ]\n",
      " [-0.96466255  0.40327057 -1.5458618  -0.08042149 -0.42481503]\n",
      " [-1.3678455  -0.72780263  2.9689212  -0.11470254  0.44061553]\n",
      " [-3.5915825   0.7576615   1.7813172   1.8677044  -0.31587684]\n",
      " [-3.5915825   0.7576615   1.7813172   1.8677044  -0.31587684]\n",
      " [-0.27286375 -0.16438943 -0.41759777 -1.0232383  -0.43014336]\n",
      " [-0.27286375 -0.16438943 -0.41759777 -1.0232383  -0.43014336]\n",
      " [-0.24571286 -0.8382114   0.9491942  -0.1227901   1.8838181 ]\n",
      " [-0.24571286 -0.8382114   0.9491942  -0.1227901   1.8838181 ]\n",
      " [-0.6775497  -0.17596447  0.04748043 -0.18793185  0.6000901 ]\n",
      " [-0.8476029   1.4350874  -1.7651579   1.1797358  -1.4912918 ]\n",
      " [ 2.1946754   0.39586174 -1.3105569   0.05664527 -1.2737641 ]\n",
      " [-0.6114936  -0.3172553   1.493858   -0.34721768 -0.10729374]\n",
      " [-0.6114936  -0.3172553   1.493858   -0.34721768 -0.10729374]\n",
      " [-1.5866907   1.70167    -1.1637721   1.5052172  -2.2943583 ]\n",
      " [-1.5353494  -0.32396615 -1.0622326  -2.1082869  -0.4530793 ]\n",
      " [ 3.500625   -0.76996493 -1.4166274  -0.9171646   1.9189396 ]\n",
      " [-1.5741353  -0.4358499   2.45117     0.39247727  0.03442591]\n",
      " [-1.1767254  -0.3846702   1.3200428   0.806308    1.4431115 ]\n",
      " [-1.1767254  -0.3846702   1.3200428   0.806308    1.4431115 ]\n",
      " [-2.043048    0.16304466 -3.4362426  -1.719918    0.46659487]\n",
      " [ 1.1164418  -0.3185339  -1.573429   -1.4981725   0.3826578 ]\n",
      " [-1.6917875  -0.19677639  6.3075714   2.7592902  -0.64004123]\n",
      " [ 2.3487334   0.8212939  -1.3132668   1.0643454  -1.2582715 ]\n",
      " [ 0.7021344  -0.8324118   4.4464397   2.8828597   2.7746913 ]\n",
      " [ 0.7021344  -0.8324118   4.4464393   2.8828597   2.7746913 ]\n",
      " [ 1.1496506  -0.8875799   3.7045012   0.5309026   0.5914513 ]], shape=(32, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.699007   -0.6982854   2.111158    1.1538045   1.0229496 ]\n",
      " [-0.12752986  0.05627038 -0.18538876  0.12929034  0.17296788]\n",
      " [ 2.3285747  -1.7712145   1.3842101  -0.8483561   2.5338311 ]\n",
      " [-1.6621132   0.16818278 -1.3295577  -0.5543832  -0.46168727]\n",
      " [-1.0659562   0.02105627 -0.63107216 -0.4104096  -0.28274357]\n",
      " [-0.5808767   1.1821762  -3.4837916  -0.28198105 -1.5229905 ]\n",
      " [-0.96466255  0.40327057 -1.5458618  -0.08042149 -0.42481503]\n",
      " [-1.3678455  -0.72780263  2.9689212  -0.11470254  0.44061553]\n",
      " [ 1.0555779   0.16141906  0.13323477  0.38236958  0.04457897]\n",
      " [-3.5915825   0.7576615   1.7813172   1.8677044  -0.31587684]\n",
      " [ 0.697887   -0.35484356  1.467114    1.0210803   1.6790483 ]\n",
      " [-0.53850734 -0.9352626   2.2016938  -0.24716151  0.833711  ]\n",
      " [-0.35199314  0.02792521 -0.41772357 -0.9452689  -1.3221972 ]\n",
      " [ 0.18763399 -0.31984815  1.128624    0.9840763   1.7538716 ]\n",
      " [-0.7136005   0.3921595  -1.5057567  -0.6596585  -1.1765065 ]\n",
      " [-0.40673792  0.68880683 -2.159715   -0.68202156 -1.6358559 ]\n",
      " [ 2.1946754   0.39586174 -1.3105569   0.05664527 -1.2737641 ]\n",
      " [-0.6114936  -0.3172553   1.493858   -0.34721768 -0.10729374]\n",
      " [-1.6721303   0.5846285  -2.3872032  -0.23725398 -0.44217116]\n",
      " [-1.0045723   0.09396737 -0.6985549   0.1112811   0.39406595]\n",
      " [-1.5353494  -0.32396615 -1.0622326  -2.1082869  -0.4530793 ]\n",
      " [ 3.500625   -0.76996493 -1.4166274  -0.9171646   1.9189396 ]\n",
      " [ 1.6392901  -0.05012832  0.9695014   0.37531936  0.07327101]\n",
      " [-0.07304804 -1.1427022   2.9667585  -0.28102854  0.85696256]\n",
      " [-1.1767254  -0.3846702   1.3200428   0.806308    1.4431115 ]\n",
      " [-2.043048    0.16304466 -3.4362426  -1.719918    0.46659487]\n",
      " [-1.5014795  -0.34773183 -0.02810262 -1.3589622  -1.1478441 ]\n",
      " [ 0.13057822  1.2812521  -3.2918782   0.37793502 -0.8833476 ]\n",
      " [ 2.3487334   0.8212939  -1.3132668   1.0643454  -1.2582715 ]\n",
      " [ 0.87447053 -0.26583672  1.1080797  -0.05394374 -0.07756446]\n",
      " [ 0.7021344  -0.8324118   4.4464393   2.8828597   2.7746913 ]\n",
      " [ 1.7579374  -0.13456562  1.2459767   0.35141295  0.09101459]], shape=(32, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.1496209  -0.88765246  3.70422     0.53081083  0.5916169 ]\n",
      " [-0.9495131  -0.40531272  0.53029513 -0.7316427  -0.54297924]\n",
      " [ 1.152467    0.1725713  -3.9012218  -1.9728712  -1.1375806 ]\n",
      " [ 1.5280294   1.1842649   3.4171817   5.234231   -0.21169472]\n",
      " [ 1.5280294   1.1842649   3.4171817   5.234231   -0.21169472]\n",
      " [-0.58593327  0.32875267  1.1429865   1.4484613   0.19037157]\n",
      " [-3.583498    1.1867758  -0.4481839  -0.12572557 -1.6025888 ]\n",
      " [-3.583498    1.1867758  -0.4481839  -0.12572557 -1.6025888 ]\n",
      " [-1.9777081   1.1683242   0.04056346  1.5903244  -0.8763155 ]\n",
      " [-0.660312    0.868863   -0.5804444  -0.268895   -1.8846947 ]\n",
      " [-1.5552449   0.92033273 -0.680035   -0.32671833 -2.2640195 ]\n",
      " [ 0.2349589  -0.45427245  0.5672355  -0.5438843   0.40429384]\n",
      " [ 0.05064905  0.66652876 -1.5121565   0.81443167  0.04413897]\n",
      " [ 0.17650104  0.47808033 -4.181284   -1.7157195  -0.5036052 ]\n",
      " [-1.0878485  -0.14860278  1.5113139   1.4318687   0.9747968 ]\n",
      " [ 2.0622215  -0.33315066  1.5858741   0.43448198  0.5237601 ]\n",
      " [ 1.0828813  -0.9151634   0.63204134 -1.7203465   0.7720408 ]\n",
      " [ 1.8208876  -0.17918943 -0.6765347  -0.5451066   0.8343175 ]], shape=(18, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.62645745 -0.91168445  2.235324    0.48451382  1.9264168 ]\n",
      " [ 0.44670245 -0.50747     1.4642929  -0.52974665 -0.380387  ]\n",
      " [-0.56634706  1.2345595  -3.5328436   0.15988082 -0.9271953 ]\n",
      " [ 0.87022567 -0.14464112  0.8331111   0.21461736  0.19111806]\n",
      " [-0.55769855 -1.1625297   2.816503   -0.15659267  1.2237585 ]\n",
      " [ 0.559148    1.0065446  -2.565017   -0.72161776 -2.36119   ]\n",
      " [-0.20950846 -1.4892662   3.9178116   0.19145729  1.9850821 ]\n",
      " [-3.583498    1.1867758  -0.4481839  -0.12572557 -1.6025888 ]\n",
      " [ 0.3970607   0.6862931  -1.5250394   0.65336645  0.09049177]\n",
      " [-0.660312    0.868863   -0.5804444  -0.268895   -1.8846947 ]\n",
      " [-0.404176   -0.3235648   0.80499774 -0.31661546  0.19329846]\n",
      " [ 0.2349589  -0.45427245  0.5672355  -0.5438843   0.40429384]\n",
      " [ 0.16885366 -0.21651174  0.51880765 -0.73282665 -0.9098379 ]\n",
      " [ 0.74387014  0.05766997  0.08768095 -0.55723554 -1.1381751 ]\n",
      " [-1.0878485  -0.14860278  1.5113139   1.4318687   0.9747968 ]\n",
      " [-0.10496362 -0.2591186   0.6857997   0.22433317  0.65242785]\n",
      " [ 0.5645276  -0.24428856  0.83981085 -0.403977   -0.5201533 ]\n",
      " [-1.1072028   0.0737886  -0.72969186 -0.08406752  0.15900044]], shape=(18, 5), dtype=float32)\n",
      "loss 1.4894965887069702 after epoch 0\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((\n",
    "        train2idx[0,:,0],\n",
    "        train2idx[0,:,1],\n",
    "        train2idx[0,:,2], \n",
    "        np.ones(train2idx.shape[1])\n",
    "    )\n",
    ").batch(32)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    for pos_head,rel,pos_tail,y in data:\n",
    "\n",
    "        neg_head, neg_tail = utils.get_negative_triples(\n",
    "            head=pos_head, \n",
    "            rel=rel, \n",
    "            tail=pos_tail,\n",
    "            num_entities=NUM_ENTITIES\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            y_pos_pred = model([\n",
    "                all_indices,\n",
    "                pos_head,\n",
    "                rel,\n",
    "                pos_tail,\n",
    "                adj_mats\n",
    "                ],\n",
    "                training=True\n",
    "            )\n",
    "\n",
    "            y_neg_pred = model([\n",
    "                all_indices,\n",
    "                neg_head,\n",
    "                rel,\n",
    "                neg_tail,\n",
    "                adj_mats\n",
    "                ],\n",
    "                training=True\n",
    "            )\n",
    "\n",
    "            y_pred = tf.concat([y_pos_pred,y_neg_pred],axis=0)\n",
    "            y_true = tf.concat([y,tf.zeros_like(y)],axis=0)\n",
    "\n",
    "            loss = bce(y_true,y_pred)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    print(f'loss {loss} after epoch {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x139efaef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x139efaef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Tensor(\"functional_5/rgcn__layer_2/add_6:0\", shape=(None, 50, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(\n",
    "    x=[\n",
    "        all_indices,\n",
    "        train2idx[:,:,0],\n",
    "        train2idx[:,:,1],\n",
    "        train2idx[:,:,2],\n",
    "        adj_mats\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'acc {(preds > .5).sum()/train2idx.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2idx = utils.array2idx(triples, ent2idx,rel2idx)\n",
    "\n",
    "adj_mats = []\n",
    "for i in range(num_relations):\n",
    "    \n",
    "    adj = np.zeros((num_entities,num_entities))\n",
    "    \n",
    "    for h,_,t in (train2idx[train2idx[:,1] == i]):\n",
    "        adj[h,t] = 1\n",
    "        adj[t,h] = 1\n",
    "        \n",
    "    adj_mats.append(adj)\n",
    "    \n",
    "def neighbors(train2idx, entities):\n",
    "    a_list = [[] for _ in entities]\n",
    "    for h,r,t in train2idx:\n",
    "        a_list[h].append([r, t])\n",
    "        a_list[t].append([r, h])\n",
    "\n",
    "    degrees = np.array([len(a) for a in a_list])\n",
    "    a_list = [np.array(a) for a in a_list]\n",
    "                 \n",
    "    return a_list, degrees\n",
    "\n",
    "a_list, degrees = neighbors(train2idx,entities)\n",
    "\n",
    "train2idx = np.expand_dims(train2idx,axis=0)\n",
    "adj_mats = np.expand_dims(adj_mats,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_neighbors(train_triples,entities):\n",
    "    \n",
    "#     adj_list = [[] for _ in entities]\n",
    "#     for i,triplet in enumerate(train_triples):\n",
    "#         adj_list[triplet[0]].append([i, triplet[2]])\n",
    "#         #adj_list[triplet[2]].append([i, triplet[0]])\n",
    "\n",
    "#     degrees = np.array([len(a) for a in adj_list])\n",
    "#     adj_list = [np.array(a) for a in adj_list]\n",
    "\n",
    "#     return adj_list, degrees\n",
    "\n",
    "# adj_list, degrees = get_neighbors(train2idx,entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,i in enumerate(a_list):\n",
    "    if i.shape[0] > 2:\n",
    "        print(idx)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,i in enumerate(train2idx[0]):\n",
    "    \n",
    "    h,r,t = i\n",
    "    \n",
    "    if h == 50:\n",
    "        \n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats[0,2,:,:].sum(axis=0)[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.python.ops import embedding_ops\n",
    "\n",
    "entity_embeddings = Embedding(\n",
    "    input_dim=num_entities,\n",
    "    output_dim=embedding_dim,\n",
    "    name='entity_embeddings',\n",
    "    embeddings_initializer=RandomUniform(\n",
    "        minval=-1,\n",
    "        maxval=1,\n",
    "        seed=SEED\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_input = tf.keras.Input(shape=(), name='head_input',dtype=tf.int64)\n",
    "rel_input = tf.keras.Input(shape=(), name='rel_input',dtype=tf.int64)\n",
    "tail_input = tf.keras.Input(shape=(), name='tail_input',dtype=tf.int64)\n",
    "all_entities = tf.keras.Input(shape=(num_entities), name='all_entities',dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj_inputs = [tf.keras.Input(shape=(num_relations,num_entities,num_entities),dtype=tf.float32,name='adj_'+str(i)) for i in range(num_relations)]\n",
    "\n",
    "adj_inputs = tf.keras.Input(shape=(num_relations,num_entities,num_entities),dtype=tf.float32,name='adj_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_e)\n",
    "# print(head_input)\n",
    "# print(tail_input)\n",
    "# print(head_e)\n",
    "# print(tail_e)\n",
    "# print(adj_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_e = entity_embeddings(head_input)\n",
    "tail_e = entity_embeddings(tail_input)\n",
    "all_e = entity_embeddings(all_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.matmul(tf.ones((1,5)), tf.ones((5,10)))\n",
    "#tf.keras.backend.dot(tf.ones((10,1)),tf.ones((1,5)))\n",
    "#tf.squeeze(tf.tensordot(tf.ones((5,5)),tf.ones((5,1)),axes=1),axis=1)\n",
    "#tf.tensordot(tf.ones((5,5)),tf.ones((5,5)),axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RGCN_Layer(tf.keras.layers.Layer):\n",
    "#     def __init__(self,num_relations,output_dim,**kwargs):\n",
    "#         super(RGCN_Layer,self).__init__(**kwargs)\n",
    "#         self.num_relations = num_relations\n",
    "#         self.output_dim = output_dim\n",
    "    \n",
    "#     def build(self,input_shape):\n",
    "\n",
    "#         in_shape = input_shape[-1][-1]\n",
    "\n",
    "#         self.W_r = self.add_weight(\n",
    "#             shape=(self.num_relations,self.output_dim,in_shape),\n",
    "#             trainable=True,\n",
    "#             initializer=\"random_normal\",\n",
    "#             name='W_r'\n",
    "#         )\n",
    "        \n",
    "#         self.W0 = self.add_weight(\n",
    "#             shape=(self.output_dim,in_shape),\n",
    "#             trainable=True,\n",
    "#             initializer='random_normal',\n",
    "#             name='W0'\n",
    "#         )\n",
    "        \n",
    "#     def call(self,inputs):\n",
    "        \n",
    "#         head_input,tail_input = inputs\n",
    "        \n",
    "#         #filter_W_r = embedding_ops.embedding_lookup_v2(self.W_r,rel_input)\n",
    "        \n",
    "#         tail_update = tf.matmul(self.W_r,tail_input,transpose_b=True)\n",
    "        \n",
    "#         head_update = tf.matmul(self.W0,head_input,transpose_b=True)\n",
    "        \n",
    "#         update = tf.reduce_sum(tail_update + head_update, axis=0)\n",
    "\n",
    "#         return tf.transpose(update)\n",
    "\n",
    "\n",
    "# class RGCN_Layer(tf.keras.layers.Layer):\n",
    "#     def __init__(self,num_relations,output_dim,**kwargs):\n",
    "#         super(RGCN_Layer,self).__init__(**kwargs)\n",
    "#         self.num_relations = num_relations\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "#     def build(self,input_shape):\n",
    "\n",
    "#         #input_dim = int(input_shape[0][0])\n",
    "#         input_dim = int(input_shape[2][-1])\n",
    "        \n",
    "#         self.relation_kernels = [\n",
    "#                 self.add_weight(\n",
    "#                     shape=(input_dim, self.output_dim),\n",
    "#                     name=\"relation_kernels\",\n",
    "#                     trainable=True,\n",
    "#                     initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "#                 )\n",
    "#                 for _ in range(self.num_relations)\n",
    "#             ]\n",
    "\n",
    "#         self.self_kernel = self.add_weight(\n",
    "#             shape=(input_dim, self.output_dim),\n",
    "#             name=\"self_kernel\",\n",
    "#             trainable=True,\n",
    "#             initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "#         )\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "        \n",
    "#         head_idx,tail_idx,head_e, tail_e, *A_mats = inputs\n",
    " \n",
    "#         head_output = tf.matmul(head_e,self.self_kernel)\n",
    "#         tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "        \n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             A = tf.squeeze(A_mats[i],axis=0)\n",
    "#             #A = A_mats[i]\n",
    "\n",
    "#             head_A_mat = embedding_ops.embedding_lookup_v2(A,head_idx)\n",
    "#             tail_A_mat = embedding_ops.embedding_lookup_v2(A,tail_idx)\n",
    "#             sliced_A_head = embedding_ops.embedding_lookup_v2(tf.transpose(head_A_mat),head_idx)\n",
    "#             sliced_A_tail = embedding_ops.embedding_lookup_v2(tf.transpose(tail_A_mat),head_idx)\n",
    "            \n",
    "#             #print(sliced_A_head)\n",
    "\n",
    "#             h_head = tf.tensordot(sliced_A_head, head_e,axes=1)\n",
    "#             h_tail = tf.tensordot(sliced_A_tail, tail_e,axes=1)\n",
    "            \n",
    "#             head_output += tf.tensordot(h_head,self.relation_kernels[i],axes=1)\n",
    "#             tail_output += tf.tensordot(h_tail,self.relation_kernels[i],axes=1)\n",
    "        \n",
    "#         return head_output,tail_output\n",
    "        \n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             h = tf.tensordot(A_mats[i], features,axes=1)\n",
    "#             output += tf.tensordot(h,self.relation_kernels[i],axes=1)\n",
    "            \n",
    "#         return tf.squeeze(output,axis=0)\n",
    "\n",
    "# class RGCN_Layer(tf.keras.layers.Layer):\n",
    "#     def __init__(self,num_relations,input_dim,output_dim,**kwargs):\n",
    "#         super(RGCN_Layer,self).__init__(**kwargs)\n",
    "#         self.num_relations = num_relations\n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "#     def build(self,input_shape):\n",
    "                \n",
    "#         self.relation_kernels = self.add_weight(\n",
    "#             shape=(self.num_relations,self.input_dim, self.output_dim),\n",
    "#             name=\"relation_kernels\",\n",
    "#             trainable=True,\n",
    "#             initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "#         )\n",
    "\n",
    "#         self.self_kernel = self.add_weight(\n",
    "#             shape=(self.input_dim, self.output_dim),\n",
    "#             name=\"self_kernel\",\n",
    "#             trainable=True,\n",
    "#             initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "#         )\n",
    "        \n",
    "#     def call(self,inputs):\n",
    "        \n",
    "#         adj_list, head_idx,rel_idx,tail_idx = inputs\n",
    "        \n",
    "#         #head_e = embedding_ops.embedding_lookup_v2(adj_list,head_idx)\n",
    "#         head_e = adj_list[head_idx]\n",
    "#         rel_e = \n",
    "                \n",
    "#         return adj_list[head_idx]\n",
    "\n",
    "\n",
    "#RGCN_Layer(num_relations=2,input_dim=3,output_dim=5)([adj_list,[6,7],[1,1],[2,2]])\n",
    "#RGCN_Layer(num_relations=2,input_dim=3,output_dim=5)([adj_list,6,1,2])\n",
    "\n",
    "#update custom training loop\n",
    "\n",
    "# class RGCN_Layer(tf.keras.layers.Layer):\n",
    "#     def __init__(self,num_relations,output_dim,**kwargs):\n",
    "#         super(RGCN_Layer,self).__init__(**kwargs)\n",
    "#         self.num_relations = num_relations\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "#     def build(self,input_shape):\n",
    "        \n",
    "#         input_dim = int(input_shape[0][-1])\n",
    "        \n",
    "#         self.relation_kernels = [\n",
    "#                 self.add_weight(\n",
    "#                     shape=(input_dim, self.output_dim),\n",
    "#                     name=\"relation_kernels\",\n",
    "#                     trainable=True,\n",
    "#                     initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "#                 )\n",
    "#                 for _ in range(self.num_relations)\n",
    "#             ]\n",
    "\n",
    "#         self.self_kernel = self.add_weight(\n",
    "#             shape=(input_dim, self.output_dim),\n",
    "#             name=\"self_kernel\",\n",
    "#             trainable=True,\n",
    "#             initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "#         )\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "        \n",
    "#         features, *A_mats = inputs\n",
    "#         print('features',features)\n",
    "#         print('self_kernel',self.self_kernel)\n",
    "#         #features = tf.squeeze(features, axis=0)\n",
    "        \n",
    "#         output = tf.matmul(features,self.self_kernel)\n",
    "#         #print('output',output)\n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             #A_mat = tf.squeeze(A_mats[i],axis=0)\n",
    "#             #print('A_mats',A_mats[i])\n",
    "#             h = tf.tensordot(A_mats[i], features,axes=1)\n",
    "#             #print('h',h)\n",
    "#             output += tf.tensordot(h,self.relation_kernels[i],axes=1)\n",
    "            \n",
    "#         return output#tf.squeeze(output,axis=0)\n",
    "\n",
    "class RGCN_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_relations,output_dim,**kwargs):\n",
    "        super(RGCN_Layer,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "\n",
    "        input_dim = int(input_shape[3][-1])\n",
    "        \n",
    "        self.relation_kernel = self.add_weight(\n",
    "                    shape=(self.num_relations,input_dim, self.output_dim),\n",
    "                    name=\"relation_kernels\",\n",
    "                    trainable=True,\n",
    "                    initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.self_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.output_dim),\n",
    "            name=\"self_kernel\",\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED)\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        embeddings,head_idx,tail_idx,head_e,tail_e,adj_mats = inputs\n",
    "         \n",
    "        head_output = tf.matmul(head_e,self.self_kernel)\n",
    "        tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "        \n",
    "#         head_idx = tf.squeeze(head_idx,axis=0)\n",
    "#         tail_idx = tf.squeeze(tail_idx,axis=0)        \n",
    "        adj_mats = tf.squeeze(adj_mats,axis=0)\n",
    "        embeddings = tf.squeeze(embeddings,axis=0)\n",
    "        print('head_idx',head_idx)\n",
    "        print('tail_idx',tail_idx)\n",
    "        \n",
    "        for i in range(self.num_relations):\n",
    "            \n",
    "            adj_i = adj_mats[i]\n",
    "\n",
    "            head_adj = tf.nn.embedding_lookup(adj_i,head_idx)\n",
    "            tail_adj = tf.nn.embedding_lookup(adj_i,tail_idx)\n",
    "            \n",
    "            h_head = tf.matmul(head_adj,embeddings)\n",
    "            h_tail = tf.matmul(head_adj,embeddings)\n",
    "            \n",
    "            head_output += tf.matmul(h_head,self.relation_kernel[i])\n",
    "            tail_output += tf.matmul(h_tail,self.relation_kernel[i])\n",
    "\n",
    "        return head_output,tail_output\n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             adj_i = adj_mats[i]\n",
    "            \n",
    "#             head_adj = tf.transpose(tf.nn.embedding_lookup(adj_i,head_idx))\n",
    "#             tail_adj = tf.transpose(tf.nn.embedding_lookup(adj_i,tail_idx))\n",
    "            \n",
    "#             h_head = tf.tensordot(head_adj, head_e,axes=1)\n",
    "#             h_tail = tf.tensordot(tail_adj, tail_e,axes=1)\n",
    "\n",
    "#             head_output += tf.tensordot(h_head,self.relation_kernel[i],axes=1)\n",
    "#             tail_output += tf.tensordot(h_tail,self.relation_kernel[i],axes=1)  \n",
    "            \n",
    "#         head_output = tf.reduce_mean(head_output,axis=0)\n",
    "#         tail_output = tf.reduce_mean(tail_output,axis=0)\n",
    "        \n",
    "#         return head_output,tail_output\n",
    "\n",
    "#             h_head = tf.tensordot(head_adj, head_e,axes=1)\n",
    "#             h_tail = tf.tensordot(tail_adj, tail_e,axes=1)\n",
    "            \n",
    "#             head_output += tf.tensordot(h_head,self.relation_kernel[i],axes=1)\n",
    "#             tail_output += tf.tensordot(h_tail,self.relation_kernel[i],axes=1)  \n",
    "            \n",
    "#         return head_output,head_output\n",
    "\n",
    "\n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             A = tf.squeeze(A_mats[i],axis=0)\n",
    "#             #A = A_mats[i]\n",
    "\n",
    "#             head_A_mat = embedding_ops.embedding_lookup_v2(A,head_idx)\n",
    "#             tail_A_mat = embedding_ops.embedding_lookup_v2(A,tail_idx)\n",
    "#             sliced_A_head = embedding_ops.embedding_lookup_v2(tf.transpose(head_A_mat),head_idx)\n",
    "#             sliced_A_tail = embedding_ops.embedding_lookup_v2(tf.transpose(tail_A_mat),head_idx)\n",
    "            \n",
    "#             #print(sliced_A_head)\n",
    "# \n",
    "#             h_head = tf.tensordot(sliced_A_head, head_e,axes=1)\n",
    "#             h_tail = tf.tensordot(sliced_A_tail, tail_e,axes=1)\n",
    "            \n",
    "#             head_output += tf.tensordot(h_head,self.relation_kernels[i],axes=1)\n",
    "#             tail_output += tf.tensordot(h_tail,self.relation_kernels[i],axes=1)\n",
    "        \n",
    "#         return head_output,tail_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGCN_Layer(num_relations=num_relations,output_dim=5)([\n",
    "#     entity_embeddings(np.arange(num_entities).reshape(1,-1)),\n",
    "#     train2idx[0:,274:275,0],\n",
    "#     train2idx[0:,274:275,2],\n",
    "#     entity_embeddings(train2idx[0,274:275,0]),\n",
    "#     entity_embeddings(train2idx[0,274:275,2]),\n",
    "#     adj_mats\n",
    "#     ]\n",
    "# )\n",
    "#entity_embeddings(np.arange(num_entities).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x194cf80050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x194cf80050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "head_idx Tensor(\"head_input_3:0\", shape=(None,), dtype=int64)\n",
      "tail_idx Tensor(\"tail_input_3:0\", shape=(None,), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'rgcn__layer_7/add_6:0' shape=(None, 5) dtype=float32>,\n",
       " <tf.Tensor 'rgcn__layer_7/add_7:0' shape=(None, 5) dtype=float32>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RGCN_Layer(num_relations=num_relations,output_dim=5)([head_input,tail_input,head_e,tail_e] + adj_inputs)\n",
    "#RGCN_Layer(num_relations=num_relations,output_dim=5)([entity_embeddings(tf.convert_to_tensor([1,2,3]))]+[np.eye(num_entities) for _ in relations])\n",
    "\n",
    "# RGCN_Layer(num_relations=num_relations,output_dim=5)([\n",
    "#     np.random.randn(num_entities,3),\n",
    "#     train2idx[0:,274:275,0],\n",
    "#     train2idx[0:,274:275,2],\n",
    "#     entity_embeddings(train2idx[0,274:275,0]),\n",
    "#     entity_embeddings(train2idx[0,274:275,2]),\n",
    "#     adj_mats\n",
    "#     ]\n",
    "# )\n",
    "RGCN_Layer(num_relations=num_relations,output_dim=5)([\n",
    "    all_e,\n",
    "    head_input,\n",
    "    tail_input,\n",
    "    head_e,\n",
    "    tail_e,\n",
    "    adj_inputs\n",
    "    \n",
    "])\n",
    "\n",
    "#RGCN_Layer(num_relations=num_relations,output_dim=5)([head_input,tail_input,head_e,tail_e,adj_inputs])\n",
    "\n",
    "#RGCN_Layer(num_relations=num_relations,output_dim=5)([np.random.randn(num_entities,5)]+[np.eye(num_entities) for _ in relations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistMult(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_relations,**kwargs):\n",
    "        super(DistMult,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        embedding_dim = input_shape[0][-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.num_relations,embedding_dim),\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(mean=0.0,stddev=1,seed=SEED),\n",
    "            name='rel_embedding'\n",
    "        )\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        head_e,rel_idx,tail_e = inputs\n",
    "        \n",
    "        rel_e = tf.nn.embedding_lookup(self.kernel,rel_idx)\n",
    "        \n",
    "        return tf.sigmoid(tf.reduce_sum(head_e*rel_e*tail_e, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_idx Tensor(\"head_input_3:0\", shape=(None,), dtype=int64)\n",
      "tail_idx Tensor(\"tail_input_3:0\", shape=(None,), dtype=int64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x194d1f7ad0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x194d1f7ad0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "##### new_head = RGCN_Layer(num_relations=num_relations,output_dim=5)([head_e,tail_e])\n",
    "# new_head = tf.keras.layers.Activation('sigmoid')(new_head)\n",
    "\n",
    "# new_tail = RGCN_Layer(num_relations=num_relations,output_dim=5)([tail_e,head_e])\n",
    "# new_tail = tf.keras.layers.Activation('sigmoid')(new_tail)\n",
    "\n",
    "# output = DistMult(num_relations=num_relations)([new_head,rel_input,new_tail])\n",
    "#DistMult(num_relations=num_relations)([np.ones((6,5)),[2,2],[2,2],[1,1]])\n",
    "new_head,new_tail = RGCN_Layer(num_relations=num_relations,output_dim=5)([\n",
    "    all_e,\n",
    "    head_input,\n",
    "    tail_input,\n",
    "    head_e,\n",
    "    tail_e,\n",
    "    adj_inputs\n",
    "    \n",
    "])\n",
    "\n",
    "output = DistMult(num_relations=num_relations,name='output')([new_head,rel_input,new_tail])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'output/Sigmoid_5:0' shape=(None,) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = tf.keras.Model([head_input,rel_input,tail_input],[output])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x=[train2idx[:,0],train2idx[:,1],train2idx[:,2]],y=np.ones(train2idx.shape[0]),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RGCN_Model(tf.keras.Model):\n",
    "#     def __init__(self,num_entities,*args,**kwargs):\n",
    "#         super(RGCN_Model,self).__init__(*args, **kwargs)\n",
    "#         self.num_entities = num_entities\n",
    "        \n",
    "#     def train_step(self,data):\n",
    "\n",
    "#         embeddings,pos_head,rel,pos_tail,*adj_mats = data[0]\n",
    "#         y = data[1]\n",
    "        \n",
    "#         neg_head, neg_tail = utils.get_negative_triples(\n",
    "#             head=pos_head, \n",
    "#             rel=rel, \n",
    "#             tail=pos_tail,\n",
    "#             num_entities=self.num_entities\n",
    "#             )\n",
    "        \n",
    "#         head = tf.concat([pos_head,neg_head],axis=0)\n",
    "#         rel = tf.concat([rel,rel],axis=0)\n",
    "#         tail = tf.concat([pos_tail,neg_tail],axis=0)\n",
    "                \n",
    "#         y = tf.concat([y,tf.zeros_like(y)],axis=0)\n",
    "        \n",
    "#         with tf.GradientTape() as tape:\n",
    "            \n",
    "#             y_pred = self([embeddings,head,rel,tail,*adj_mats],training=True)\n",
    "            \n",
    "#             loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "            \n",
    "#         trainable_vars = self.trainable_variables\n",
    "#         gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "#         self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "\n",
    "#         return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(\n",
    "    inputs=[\n",
    "        all_entities,\n",
    "        head_input,\n",
    "        rel_input,\n",
    "        tail_input,\n",
    "        adj_inputs\n",
    "    ],\n",
    "    outputs=[\n",
    "        output\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_idx tf.Tensor(\n",
      "[ 583 5732  781  115 3894 3749 3608 1246 4088 4088 3685 3685  884  884\n",
      " 1577 2363 5579 2006 2006 1813 4317 3452  406 2508 2508  257  274 5926\n",
      " 1609 1900 1900  549], shape=(32,), dtype=int64)\n",
      "tail_idx tf.Tensor(\n",
      "[5001 5368 3454 5339 5339 3998  400  700 3708 1583 2562 1605 2853 2586\n",
      " 1605 1582 2286 5492 3640 1546 1319 1769 2109 3516 4709 5926  469 5218\n",
      " 5369 3568  863 3511], shape=(32,), dtype=int64)\n",
      "head_idx tf.Tensor(\n",
      "[ 583  347 3094  115 2081  413 3928 4702 4519 4088 3685 3982 4699 4478\n",
      " 3019 2363 2426 2006  928 1813 2157 3452  406 2508 3024  257 3181 5926\n",
      " 1609 1974 3084 3051], shape=(32,), dtype=int64)\n",
      "tail_idx tf.Tensor(\n",
      "[2485 5368 3454 4945 5339 3998  400  700 3708 3926   42 1605 2853 2586\n",
      " 1605 1701 2286 1836 3640 1242 1319 4556 3959 3271 4709 2981  469 3874\n",
      "  458 3568  863 3511], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "all_indices = np.arange(num_entities).reshape(1,-1)\n",
    "# num_epochs = 1\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(epoch)\n",
    "data = tf.data.Dataset.from_tensor_slices((train2idx[0,:,0],train2idx[0,:,1],train2idx[0,:,2], np.ones(train2idx.shape[1]))).batch(32)\n",
    "\n",
    "for pos_head,rel,pos_tail,y in data:\n",
    "    \n",
    "    neg_head, neg_tail = utils.get_negative_triples(\n",
    "        head=pos_head, \n",
    "        rel=rel, \n",
    "        tail=pos_tail,\n",
    "        num_entities=num_entities\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        y_pos_pred = model([\n",
    "            all_indices,\n",
    "            pos_head,\n",
    "            rel,\n",
    "            pos_tail,\n",
    "            adj_mats\n",
    "        ],\n",
    "            training=True\n",
    "        )\n",
    "        \n",
    "        y_neg_pred = model([\n",
    "            all_indices,\n",
    "            neg_head,\n",
    "            rel,\n",
    "            neg_tail,\n",
    "            adj_mats\n",
    "        ],\n",
    "            training=True\n",
    "        )\n",
    "        \n",
    "        y_pred = tf.concat([y_pos_pred,y_neg_pred],axis=0)\n",
    "        y_true = tf.concat([y,tf.zeros_like(y)],axis=0)\n",
    "        \n",
    "        loss = bce(y_true,y_pred)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x194d239680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x194d239680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Model was constructed with shape (None,) for input Tensor(\"head_input_3:0\", shape=(None,), dtype=int64), but it was called on an input with incompatible shape (1, 50).\n",
      "WARNING:tensorflow:Model was constructed with shape (None,) for input Tensor(\"rel_input_3:0\", shape=(None,), dtype=int64), but it was called on an input with incompatible shape (1, 50).\n",
      "WARNING:tensorflow:Model was constructed with shape (None,) for input Tensor(\"tail_input_3:0\", shape=(None,), dtype=int64), but it was called on an input with incompatible shape (1, 50).\n",
      "head_idx Tensor(\"IteratorGetNext:1\", shape=(1, 50), dtype=int64)\n",
      "tail_idx Tensor(\"IteratorGetNext:3\", shape=(1, 50), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# inputs = {**{\"all_entities\":np.arange(num_entities),\n",
    "#      \"head_input\":train2idx[:,0],\n",
    "#      \"rel_input\":train2idx[:,1],\n",
    "#      \"tail_input\":train2idx[:,2]},**{\"adj_\"+str(i):adj_mats[i] for i in range(num_relations)}}\n",
    "\n",
    "# model.inputs\n",
    "\n",
    "preds_a = model.predict(\n",
    "    x=[\n",
    "        all_indices,\n",
    "        train2idx[:,:,0],\n",
    "        train2idx[:,:,1],\n",
    "        train2idx[:,:,2],\n",
    "        adj_mats\n",
    "    ],\n",
    "    batch_size=1\n",
    ")\n",
    "# preds_b = model.predict(\n",
    "#     x=[\n",
    "#         all_indices,\n",
    "#         train2idx[:,:,0],\n",
    "#         train2idx[:,:,1],\n",
    "#         train2idx[:,:,2],\n",
    "#         adj_mats\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     x=[\n",
    "#         train2idx[:,0],\n",
    "#         train2idx[:,1],\n",
    "#         train2idx[:,2],\n",
    "#         *adj_mats\n",
    "#     ],\n",
    "#     y=np.ones(train2idx.shape[0]),\n",
    "#     epochs=1,\n",
    "#     verbose=0,\n",
    "#     batch_size=1\n",
    "# )\n",
    "\n",
    "# model.fit(\n",
    "#     inputs,\n",
    "#     {\"output\":np.ones(train2idx.shape[0])},\n",
    "#     epochs=1,\n",
    "#     verbose=0,\n",
    "#     batch_size=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dgl\n",
    "# import torch as th\n",
    "# from dgl.nn import RelGraphConv\n",
    "# g = dgl.graph(([0,1,2,3,2,5,0], [1,2,3,4,0,3,1]))\n",
    "# conv = RelGraphConv(10, 5, 3, regularizer='basis')\n",
    "# feat = th.ones(6, 10)\n",
    "# etype = th.tensor(np.array([0,1,2,0,1,2,1]).astype(np.int64))\n",
    "# conv(g, feat, etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict([train2idx[:,0],train2idx[:,1],train2idx[:,2]]) > .5).sum()/train2idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.sparse.sparse_dense_matmul(sparse_tensor, zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zeros = tf.zeros(shape=[num_entities,num_relations,num_entities],dtype=tf.float64)\n",
    "# adj = np.zeros(shape=[num_entities,num_relations,num_entities])\n",
    "\n",
    "# for h,r,t in train2idx:\n",
    "    \n",
    "#     adj[h,r,t] = 1\n",
    "    \n",
    "# adj = tf.convert_to_tensor(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get neighbors of head+tail\n",
    "#update rgcn -> for each triple, feed in neighbors (update weight matrix?, normalize by degrees)\n",
    "#GNNEXPLAINER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = tf.Variable(\n",
    "#     initial_value=tf.random.uniform(\n",
    "#         minval=0,\n",
    "#         maxval=1,\n",
    "#         shape=[\n",
    "#             num_entities,\n",
    "#             num_relations,\n",
    "#             num_entities\n",
    "#         ]\n",
    "#     ),\n",
    "#     trainable=True,\n",
    "#     shape=[\n",
    "#         num_entities,\n",
    "#         num_relations,\n",
    "#         num_entities\n",
    "#     ],\n",
    "#     name='mask'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "# model.predict(\n",
    "#     x=[\n",
    "#         train2idx[i,0].reshape(-1,1),\n",
    "#         train2idx[i,1].reshape(-1,1),\n",
    "#         train2idx[i,2].reshape(-1,1)\n",
    "#     ],\n",
    "#     batch_size=1\n",
    "# )\n",
    "model.predict(\n",
    "    x=[\n",
    "        train2idx[:,0],\n",
    "        train2idx[:,1],\n",
    "        train2idx[:,2]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for triple i:\n",
    "    #get k hop subgraph?\n",
    "    #compute pred \n",
    "    #define masks\n",
    "    #optimize loss, return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_adjlist(train2idx,entities):\n",
    "\n",
    "#     adj_list = [[] for _ in entities]\n",
    "\n",
    "#     for i,triplet in enumerate(train2idx):\n",
    "#         adj_list[triplet[0]].append([i, triplet[2]])\n",
    "#         adj_list[triplet[2]].append([i, triplet[0]])\n",
    "\n",
    "#     degrees = np.array([len(a) for a in adj_list])\n",
    "#     adj_list = [np.array(a) for a in adj_list]\n",
    "    \n",
    "#     return adj_list,degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_adjlist(train2idx,entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
