{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import random as rn\n",
    "import RGCN\n",
    "import explaiNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('..','data','royalty.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'spouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triples,traces,nopred = utils.concat_triples(data, data['rules'])\n",
    "# entities = data['all_entities'].tolist()\n",
    "# relations = data['all_relations'].tolist()\n",
    "\n",
    "triples,traces,nopred = utils.concat_triples(data, [RULE,'brother','sister'])\n",
    "sister_relations = data['sister_relations'].tolist()\n",
    "sister_entities = data['sister_entities'].tolist()\n",
    "\n",
    "brother_relations = data['brother_relations'].tolist()\n",
    "brother_entities = data['brother_entities'].tolist()\n",
    "\n",
    "entities = np.unique(data[RULE + '_entities'].tolist()+brother_entities+sister_entities).tolist()\n",
    "relations = np.unique(data[RULE + '_relations'].tolist()+brother_relations+sister_relations).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "TOP_K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "idx2ent = dict(zip(range(NUM_ENTITIES),entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.load(os.path.join('..','data','preds','explaine_'+RULE+'_preds.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = int(pred_data['best_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3,shuffle=True,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_data = [test_idx for _, test_idx in kf.split(X=triples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = cf_data[best_idx]\n",
    "\n",
    "cv_triples = triples[idx]\n",
    "cv_traces = traces[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2idx = utils.array2idx(cv_triples,ent2idx,rel2idx)\n",
    "testexp2idx = utils.array2idx(cv_traces,ent2idx,rel2idx)[:,:,[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pred_data['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard, scores = explaiNE.jaccard_score(testexp2idx,preds,TOP_K,return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_idx = scores < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_triples = cv_triples[error_idx]\n",
    "error_traces = cv_traces[error_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(error_triples[i])\n",
    "print(error_traces[i][0:TOP_K,])\n",
    "print(idx2ent[preds[i][0][0]],idx2ent[preds[i][0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join('..','data','weights',RULE+'.h5'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_scores = []\n",
    "preds = []\n",
    "\n",
    "train2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "trainexp2idx = utils.array2idx(traces,ent2idx,rel2idx)\n",
    "nopred2idx = utils.array2idx(nopred,ent2idx,rel2idx)\n",
    "\n",
    "#adjacency_data = tf.concat([train2idx,trainexp2idx.reshape(-1,3),nopred2idx],axis=0)\n",
    "\n",
    "test2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "testexp2idx = utils.array2idx(traces,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_data = tf.concat([\n",
    "    train2idx,\n",
    "    trainexp2idx.reshape(-1,3),\n",
    "    nopred2idx,\n",
    "    test2idx,\n",
    "    testexp2idx.reshape(-1,3)\n",
    "    ],axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_data[adjacency_data[:,0] == h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraphs_list = [utils.get_adj_mats(testexp2idx[i],NUM_ENTITIES,NUM_RELATIONS) for i in range(testexp2idx.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.from_tensor_slices((test2idx[:,0],test2idx[:,1],test2idx[:,2],testexp2idx)).batch(1)\n",
    "\n",
    "dist_dataset = strategy.experimental_distribute_dataset(d)\n",
    "\n",
    "# for h,r,t,l in dist_dataset:\n",
    "#     print(h,r,t,tf.squeeze(l,axis=0))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraphs = true_subgraphs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in true_subgraphs[5].indices:\n",
    "#     print(row)\n",
    "\n",
    "tf.reduce_all(true_subgraphs[5].indices[0] == true_subgraphs[5].indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_jaccard(true_exp,pred_exp):\n",
    "    \n",
    "    num_true_traces = true_exp.shape[0]\n",
    "    num_pred_traces = pred_exp.shape[0]\n",
    "    \n",
    "    count = 0\n",
    "    for pred_row in pred_exp:\n",
    "        for true_row in true_exp:\n",
    "            if tf.reduce_all(pred_row == true_row):\n",
    "                count += 1\n",
    "    score = count / (num_true_traces + num_pred_traces-count)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cond(tf.reduce_all(true_subgraphs[5].indices[0]==true_subgraphs[5].indices[0]), lambda :1, lambda:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_subgraphs[5].indices\n",
    "tf.boolean_mask(train2idx,train2idx[:,0] == 167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2idx[train2idx[:,0] == 167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "model = RGCN.get_RGCN_Model(\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    num_relations=NUM_RELATIONS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "model.load_weights(os.path.join('..','data','weights',RULE+'.h5'))\n",
    "#kf = KFold(n_splits=3,shuffle=True,random_state=SEED)\n",
    "cv_scores = []\n",
    "cv_preds = []\n",
    "\n",
    "masks = [tf.Variable(\n",
    "        initial_value=tf.random.normal(\n",
    "            (1,NUM_ENTITIES,NUM_ENTITIES), \n",
    "            mean=0, \n",
    "            stddev=1, \n",
    "            dtype=tf.float32, \n",
    "            seed=SEED),\n",
    "        name='mask_'+str(i),\n",
    "        trainable=True) for i in range(NUM_RELATIONS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[0].assign(tf.random.normal(\n",
    "            (1,NUM_ENTITIES,NUM_ENTITIES), \n",
    "            mean=0, \n",
    "            stddev=1, \n",
    "            dtype=tf.float32, \n",
    "            seed=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2idx = tf.expand_dims(test2idx,axis=0)\n",
    "\n",
    "jaccard_scores = []\n",
    "preds = []\n",
    "\n",
    "adj_mats = utils.get_adj_mats(adjacency_data, NUM_ENTITIES,NUM_RELATIONS)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "\n",
    "        tape.watch(masks)\n",
    "\n",
    "        masked_adjs = [adj_mats[i] * tf.sigmoid(masks[i]) for i in range(NUM_RELATIONS)]\n",
    "\n",
    "        test_preds =  model([\n",
    "            all_indices,\n",
    "            test2idx[:,0:2,0],\n",
    "            test2idx[:,0:2,1],\n",
    "            test2idx[:,0:2,2],\n",
    "            masked_adjs\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        loss = tf.reduce_mean(-1 * tf.math.log(test_preds+0.00001))#+ tf.reduce_mean(masks)\n",
    "\n",
    "    print(f\"Loss {loss} @ epoch {epoch}\")\n",
    "    grads = tape.gradient(loss,masks)\n",
    "    optimizer.apply_gradients(zip(grads,masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_subgraphs(\n",
    "    true_subgraphs,\n",
    "    adj_mats,\n",
    "    masks,\n",
    "    num_relations,\n",
    "    num_entities,\n",
    "    threshold\n",
    "    ):\n",
    "    \n",
    "    '''Compute jaccard score across all relations for one triple'''\n",
    "\n",
    "    scores = []\n",
    "    pred_graphs = []\n",
    "\n",
    "    for i in range(num_relations):\n",
    "\n",
    "        mask_i = adj_mats[i] * tf.nn.sigmoid(masks[i])\n",
    "\n",
    "        non_masked_indices = tf.gather(mask_i.indices[mask_i.values > threshold], [1,2],axis=1)\n",
    "\n",
    "        if non_masked_indices.shape[0]:\n",
    "\n",
    "            pred_graph = csr_matrix(\n",
    "                (tf.ones(non_masked_indices.shape[0]),(non_masked_indices[:,0],non_masked_indices[:,1])),\n",
    "                shape=(num_entities,num_entities)\n",
    "            )\n",
    "\n",
    "            pred_graphs.append(non_masked_indices)\n",
    "\n",
    "        else:\n",
    "\n",
    "            pred_graph = csr_matrix(([],([],[])),shape=(num_entities,num_entities))\n",
    "            pred_graphs.append([])\n",
    "\n",
    "        true_indices = true_subgraphs[i].indices\n",
    "\n",
    "        if true_indices.shape[0]:\n",
    "\n",
    "            gather = tf.gather(true_indices,[1,2],axis=1)\n",
    "\n",
    "            true_graph = csr_matrix(\n",
    "                (true_subgraphs[i].values,(gather[:,0],gather[:,1])),\n",
    "                shape=(num_entities,num_entities))\n",
    "\n",
    "        else:\n",
    "            true_graph = csr_matrix(([],([],[])),shape=(num_entities,num_entities))\n",
    "\n",
    "\n",
    "        score = jaccard_score(true_graph,pred_graph,average='micro')\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    return tf.reduce_mean(scores[1:]), pred_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraphs = utils.get_adj_mats(testexp2idx[0],NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard, _ = score_subgraphs(\n",
    "#     true_subgraphs=true_subgraphs,\n",
    "#     adj_mats=adj_mats,\n",
    "#     masks=masks,\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     threshold=THRESHOLD\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_RELATIONS):\n",
    "    \n",
    "    print(tf.sparse.to_dense(adj_mats[i]).numpy().sum())\n",
    "    print(tf.nn.sigmoid(masks[i]).numpy().sum())\n",
    "    mask_i = adj_mats[i] * tf.nn.sigmoid(masks[i])\n",
    "\n",
    "    non_masked_indices = tf.gather(mask_i.indices[mask_i.values > THRESHOLD], [1,2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1*tf.math.log(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_i = true_subgraphs[5] * tf.nn.sigmoid(masks[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.cast(tf.sigmoid(true_subgraphs[5].values) > .5,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'spouse'\n",
    "sister_relations = data['sister_relations'].tolist()\n",
    "sister_entities = data['sister_entities'].tolist()\n",
    "\n",
    "brother_relations = data['brother_relations'].tolist()\n",
    "brother_entities = data['brother_entities'].tolist()\n",
    "\n",
    "entities = np.unique(data[RULE + '_entities'].tolist()+brother_entities+sister_entities).tolist()\n",
    "relations = np.unique(data[RULE + '_relations'].tolist()+brother_relations+sister_relations).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp = tf.convert_to_tensor(np.array([[0,922,8507],[0,0,0],[0,1,1]]))\n",
    "pred_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_exp = mask_i.indices[mask_i.values > .5]\n",
    "true_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.cast(tf.reduce_sum(tf.cast(mask_i.values > .5,dtype=tf.float32)),dtype=tf.int32)\n",
    "#mask_i.indices[mask_i.values > .5]\n",
    "# def fun(x):\n",
    "#     print(x)\n",
    "#     other = mask_i.indices[mask_i.values > .5]\n",
    "#     print('equality',tf.equal(x,other))\n",
    "#     return tf.reduce_all(tf.equal(x,other),axis=1)\n",
    "# tf.map_fn(fn=fun,elems=mask_i.indices[mask_i.values > .5],dtype=tf.bool)\n",
    "\n",
    "def outer(x):\n",
    "    def inner(y):\n",
    "#         print('x',x)\n",
    "#         print('y',y)\n",
    "#         print('equality',tf.reduce_all(tf.equal(x,y)))\n",
    "        return tf.reduce_all(tf.equal(x,y))\n",
    "    \n",
    "    return tf.map_fn(fn=inner,elems=pred_exp,dtype=tf.bool)\n",
    "\n",
    "tf.reduce_sum(tf.cast(tf.map_fn(fn=outer,elems=true_exp,\n",
    "                                dtype=tf.bool),dtype=tf.float32),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     test2idx = tf.expand_dims(test2idx,axis=0)\n",
    "\n",
    "#     jaccard_scores = []\n",
    "#     preds = []\n",
    "\n",
    "#     adj_mats = utils.get_adj_mats(adjacency_data, NUM_ENTITIES,NUM_RELATIONS)\n",
    "\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "#         with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "\n",
    "#             tape.watch(masks)\n",
    "\n",
    "#             masked_adjs = [adj_mats[i] * tf.sigmoid(masks[i]) for i in range(NUM_RELATIONS)]\n",
    "\n",
    "#             test_preds =  model([\n",
    "#                 all_indices,\n",
    "#                 test2idx[:,0:2,0],\n",
    "#                 test2idx[:,0:2,1],\n",
    "#                 test2idx[:,0:2,2],\n",
    "#                 masked_adjs\n",
    "#                 ]\n",
    "#             )\n",
    "\n",
    "#             penalty = tf.reduce_sum([tf.reduce_sum(\n",
    "#                 tf.cast(masked_adjs[i].values > .5,dtype=tf.int64)) for i in range(NUM_RELATIONS)])\n",
    "\n",
    "#             loss = tf.reduce_mean(-1 * tf.math.log(test_preds+0.00001)) + (.001 * penalty.numpy())#+ tf.reduce_mean(masks)\n",
    "\n",
    "#         print(f\"Loss {tf.reduce_mean(loss)} @ epoch {epoch}\")\n",
    "\n",
    "#         grads = tape.gradient(loss,masks)\n",
    "#         optimizer.apply_gradients(zip(grads,masks))\n",
    "\n",
    "#     j_scores = []\n",
    "\n",
    "#     #for i in range(testexp2idx.shape[0]):\n",
    "#     for i in range(2):\n",
    "\n",
    "#         true_subgraphs = utils.get_adj_mats(testexp2idx[i],NUM_ENTITIES,NUM_RELATIONS)\n",
    "\n",
    "#         jaccard, _ = score_subgraphs(\n",
    "#             true_subgraphs=true_subgraphs,\n",
    "#             adj_mats=adj_mats,\n",
    "#             masks=masks,\n",
    "#             num_relations=NUM_RELATIONS,\n",
    "#             num_entities=NUM_ENTITIES,\n",
    "#             threshold=THRESHOLD\n",
    "#         )\n",
    "\n",
    "#         j_scores.append(jaccard)\n",
    "#         #preds.append(pred)\n",
    "\n",
    "#     cv_avg = tf.reduce_mean(j_scores)\n",
    "#     print(f\"Cv jaccard scores {cv_avg}\")\n",
    "\n",
    "#     cv_scores.append(cv_avg)\n",
    "#     #cv_preds.append(preds)\n",
    "\n",
    "\n",
    "# best_idx = np.argmin(cv_scores)\n",
    "# #best_preds = cv_preds[best_idx]\n",
    "\n",
    "# print(f\"Overall jaccard score: {tf.reduce_mean(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(os.path.join('..','data','preds','gnn_explainer_'+RULE+'_preds.npz'),\n",
    "#     preds=pred_graphs,embedding_dim=EMBEDDING_DIM,k=K,\n",
    "#     threshold=THRESHOLD,learning_rate=LEARNING_RATE,num_epochs=NUM_EPOCHS\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "in_file=np.load(os.path.join('..','data','preds','gnn_explainer_'+'spouse'+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# head_output = tf.matmul(tf.reshape(entity_embeddings[head],(1,-1)),self_kernel)\n",
    "# tail_output = tf.matmul(tf.reshape(entity_embeddings[tail],(1,-1)),self_kernel)\n",
    "\n",
    "# for i in range(NUM_RELATIONS):\n",
    "\n",
    "#     adj_i = tf.sparse.to_dense(adj_mats[i])[0] * tf.sigmoid(masks[i][0])\n",
    "\n",
    "#     sum_embeddings = tf.matmul(adj_i,entity_embeddings)\n",
    "\n",
    "#     head_update = tf.reshape(sum_embeddings[head],(1,-1))\n",
    "#     tail_update = tf.reshape(sum_embeddings[tail],(1,-1))\n",
    "\n",
    "#     head_output += tf.matmul(head_update,relation_kernel[i])\n",
    "#     tail_output += tf.matmul(tail_update,relation_kernel[i])\n",
    "\n",
    "# # for i in range(NUM_RELATIONS):\n",
    "\n",
    "# #     adj_i = tf.sparse.reshape(adj_mats[i] * tf.sigmoid(masks[i]), (NUM_ENTITIES,NUM_ENTITIES))\n",
    "\n",
    "# head_output = tf.sigmoid(head_output)\n",
    "# tail_output = tf.sigmoid(tail_output)\n",
    "\n",
    "# pred = tf.sigmoid(tf.reduce_sum(head_output*relation_kernel[rel]*tail_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
