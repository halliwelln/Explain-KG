{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import random as rn\n",
    "import RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('..','data','royalty.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'full_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples,traces,nopred = utils.concat_triples(data, data['rules'])\n",
    "entities = data['all_entities'].tolist()\n",
    "relations = data['all_relations'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "EMBEDDING_DIM = 50\n",
    "OUTPUT_DIM = 50\n",
    "LEARNING_RATE = .01\n",
    "NUM_EPOCHS = 2\n",
    "THRESHOLD = .01\n",
    "K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "all_indices = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "model = RGCN.get_RGCN_Model(\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    num_relations=NUM_RELATIONS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join('..','data','weights',RULE+'.h5'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "relation_embeddings = model.get_layer('output').get_weights()[0]\n",
    "\n",
    "relation_kernel, self_kernel = model.get_layer('rgcn__layer').get_weights()\n",
    "\n",
    "entity_embeddings = model.get_layer('entity_embeddings').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_scores = []\n",
    "preds = []\n",
    "\n",
    "train2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "trainexp2idx = utils.array2idx(traces,ent2idx,rel2idx)\n",
    "nopred2idx = utils.array2idx(nopred,ent2idx,rel2idx)\n",
    "\n",
    "adjacency_data = tf.concat([train2idx,trainexp2idx.reshape(-1,3),nopred2idx],axis=0)\n",
    "\n",
    "test2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "testexp2idx = utils.array2idx(traces,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(data_subset,node_idx):\n",
    "    \n",
    "    neighbors = tf.concat([data_subset[data_subset[:,0] == node_idx],\n",
    "                           data_subset[data_subset[:,2] == node_idx]],axis=0)\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "def get_computation_graph(head,rel,tail,k,data,num_relations):\n",
    "\n",
    "    '''Get k hop neighbors (may include duplicates)'''\n",
    "         \n",
    "    # subset = data[data[:,1] == rel]\n",
    "\n",
    "    # neighbors_head = get_neighbors(subset,head)\n",
    "    # neighbors_tail = get_neighbors(subset,tail)\n",
    "\n",
    "    neighbors_head = get_neighbors(data,head)\n",
    "    neighbors_tail = get_neighbors(data,tail)\n",
    "\n",
    "    all_neighbors = tf.concat([neighbors_head,neighbors_tail],axis=0)\n",
    "\n",
    "    if k > 1:\n",
    "        num_indices = all_neighbors.shape[0]\n",
    "\n",
    "        seen_nodes = []\n",
    "        \n",
    "        for _ in range(k-1):#-1 since we already computed 1st degree neighbors above\n",
    "\n",
    "            for idx in range(num_indices):\n",
    "\n",
    "                head_neighbor_idx = all_neighbors[idx,0]\n",
    "                tail_neighbor_idx = all_neighbors[idx,2]\n",
    "\n",
    "                if head_neighbor_idx not in seen_nodes:\n",
    "                    \n",
    "                    seen_nodes.append(head_neighbor_idx)\n",
    "\n",
    "                    more_head_neighbors = get_neighbors(data,head_neighbor_idx)\n",
    "\n",
    "                    all_neighbors = tf.concat([all_neighbors,more_head_neighbors],axis=0)\n",
    "\n",
    "                if tail_neighbor_idx not in seen_nodes:\n",
    "\n",
    "                    seen_nodes.append(tail_neighbor_idx)\n",
    "\n",
    "                    more_tail_neighbors = get_neighbors(data,tail_neighbor_idx)\n",
    "\n",
    "                    all_neighbors = tf.concat([all_neighbors,more_tail_neighbors],axis=0)\n",
    "\n",
    "    return all_neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "head = test2idx[i,0]\n",
    "rel = test2idx[i,1]\n",
    "tail = test2idx[i,2]\n",
    "\n",
    "comp_graph = get_computation_graph(head,rel,tail,K,adjacency_data,NUM_RELATIONS)\n",
    "\n",
    "adj_mats = utils.get_adj_mats(comp_graph, NUM_ENTITIES, NUM_RELATIONS)\n",
    "\n",
    "masks = [tf.Variable(\n",
    "        initial_value=tf.random.normal(\n",
    "            (1,NUM_ENTITIES,NUM_ENTITIES), \n",
    "            mean=0, \n",
    "            stddev=1, \n",
    "            dtype=tf.float32, \n",
    "            seed=SEED),\n",
    "        name='mask_'+str(i),\n",
    "        trainable=True) for i in range(NUM_RELATIONS)\n",
    "]\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "    #with tf.GradientTape() as tape:\n",
    "\n",
    "        tape.watch(masks)\n",
    "\n",
    "        head_output = tf.matmul(tf.reshape(entity_embeddings[head],(1,-1)),self_kernel)\n",
    "        tail_output = tf.matmul(tf.reshape(entity_embeddings[tail],(1,-1)),self_kernel)\n",
    "\n",
    "        for i in range(NUM_RELATIONS):\n",
    "\n",
    "            adj_i = tf.sparse.to_dense(adj_mats[i])[0] * tf.sigmoid(masks[i][0])\n",
    "\n",
    "            sum_embeddings = tf.matmul(adj_i,entity_embeddings)\n",
    "\n",
    "            head_update = tf.reshape(sum_embeddings[head],(1,-1))\n",
    "            tail_update = tf.reshape(sum_embeddings[tail],(1,-1))\n",
    "\n",
    "            head_output += tf.matmul(head_update,relation_kernel[i])\n",
    "            tail_output += tf.matmul(tail_update,relation_kernel[i])\n",
    "\n",
    "        head_output = tf.sigmoid(head_output)\n",
    "        tail_output = tf.sigmoid(tail_output)\n",
    "\n",
    "        pred = tf.sigmoid(tf.reduce_sum(head_output*relation_kernel[rel]*tail_output))\n",
    "\n",
    "        loss = -1 * tf.math.log(pred+0.00001)# + tf.reduce_mean(masks)\n",
    "\n",
    "    print(f\"Loss {tf.squeeze(loss).numpy()} @ epoch {epoch}\")\n",
    "\n",
    "    grads = tape.gradient(loss,masks)\n",
    "    optimizer.apply_gradients(zip(grads,masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraphs = utils.get_adj_mats(testexp2idx[i],NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "pred_graphs = []\n",
    "\n",
    "for i in range(NUM_RELATIONS):\n",
    "\n",
    "    mask_i = adj_mats[i] * tf.nn.sigmoid(masks[i])\n",
    "\n",
    "    non_masked_indices = mask_i.indices[mask_i.values > .01]\n",
    "\n",
    "    pred_graph = tf.sparse.SparseTensor(\n",
    "        indices=non_masked_indices,\n",
    "        values=tf.ones(non_masked_indices.shape[0]),\n",
    "        dense_shape=(1,NUM_ENTITIES,NUM_ENTITIES)\n",
    "        )\n",
    "\n",
    "    pred_graph = tf.sparse.to_dense(pred_graph)\n",
    "    true_graph = tf.sparse.to_dense(true_subgraphs[i])\n",
    "\n",
    "    #print(np.argwhere(pred_graph.numpy()))\n",
    "    #print(np.argwhere(true_graph.numpy()))\n",
    "\n",
    "    score = utils.tf_binary_jaccard(true_graph,pred_graph)\n",
    "\n",
    "    if tf.math.is_nan(score):\n",
    "        scores.append(0)\n",
    "    else:\n",
    "        scores.append(score)\n",
    "\n",
    "    graph = np.argwhere(pred_graph.numpy().squeeze())\n",
    "    col = np.ones((graph.shape[0],1),dtype=np.int64) * i\n",
    "    out_graph = np.concatenate([graph[:,0].reshape(-1,1),col,graph[:,1].reshape(-1,1)],axis=1)\n",
    "\n",
    "    if out_graph.shape[0]:\n",
    "        pred_graphs.append(out_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join('..','data','preds','gnn_explainer_'+RULE+'_preds.npz'),\n",
    "    preds=pred_graphs,embedding_dim=EMBEDDING_DIM,k=K,\n",
    "    threshold=THRESHOLD,learning_rate=LEARNING_RATE,num_epochs=NUM_EPOCHS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# in_file=np.load(os.path.join('..','data','preds','gnn_explainer_'+'spouse'+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
