{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import random as rn\n",
    "import RGCN\n",
    "from explaiNE import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('..','data','royalty.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples,traces,nopred = utils.concat_triples(data, data['rules'])\n",
    "entities = data['all_entities'].tolist()\n",
    "relations = data['all_relations'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79960"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7526 + 8668 + 8917 + 6277 + 6277 + 7736 + 10762 + 10057 + 13740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54065"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3763 + 8668 + 8917 + 2003 + 2159 + 7736 + 10762 + 10057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47735"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6114 + 3606 + 3376 + 6928 + 6928 + 4331 + 5602 + 4705 + 6145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6145"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(parent_triples[:,0].tolist() + parent_triples[:,2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41638, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7736, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples[triples[:,1] == 'grandparent'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_triples = nopred[nopred[:,1] == 'parent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'uncle'\n",
    "\n",
    "triples,traces,nopred = utils.concat_triples(data, [RULE,'brother','sister'])\n",
    "# sister_relations = data['sister_relations'].tolist()\n",
    "# sister_entities = data['sister_entities'].tolist()\n",
    "\n",
    "# brother_relations = data['brother_relations'].tolist()\n",
    "# brother_entities = data['brother_entities'].tolist()\n",
    "\n",
    "# entities = np.unique(data[RULE + '_entities'].tolist()+brother_entities+sister_entities).tolist()\n",
    "# relations = np.unique(data[RULE + '_relations'].tolist()+brother_relations+sister_relations).tolist()\n",
    "\n",
    "# NUM_ENTITIES = len(entities)\n",
    "# NUM_RELATIONS = len(relations)\n",
    "\n",
    "# ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "# rel2idx = dict(zip(relations, range(NUM_RELATIONS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['Marie_Henriette_of_Austria', 'sister',\n",
       "         'Archduchess_Hermine_of_Austria'],\n",
       "        ['Princess_Clémentine_of_Belgium', 'parent',\n",
       "         'Marie_Henriette_of_Austria'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']],\n",
       "\n",
       "       [['Leopold_II_of_Belgium', 'sister', 'Carlota_of_Mexico'],\n",
       "        ['Princess_Clémentine_of_Belgium', 'parent',\n",
       "         'Leopold_II_of_Belgium'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']]], dtype='<U76')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces[7274:7276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "jaccard_score([1,0],[1,2],average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(data['brother_triples'], axis=0).shape\n",
    "#triples,traces,nopred = utils.concat_triples(data, data['rules'])\n",
    "\n",
    "\n",
    "# triples,traces,nopred = utils.concat_triples(data, [RULE,'brother','sister'])\n",
    "# sister_relations = data['sister_relations'].tolist()\n",
    "# sister_entities = data['sister_entities'].tolist()\n",
    "\n",
    "# brother_relations = data['brother_relations'].tolist()\n",
    "# brother_entities = data['brother_entities'].tolist()\n",
    "\n",
    "# entities = np.unique(data[RULE + '_entities'].tolist()+brother_entities+sister_entities).tolist()\n",
    "# relations = np.unique(data[RULE + '_relations'].tolist()+brother_relations+sister_relations).tolist()\n",
    "\n",
    "# NUM_ENTITIES = len(entities)\n",
    "# NUM_RELATIONS = len(relations)\n",
    "# EMBEDDING_DIM = 50\n",
    "# OUTPUT_DIM = 50\n",
    "\n",
    "# ALL_INDICES = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "# ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "# rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "# model = RGCN.get_RGCN_Model(\n",
    "# num_entities=NUM_ENTITIES,\n",
    "# num_relations=NUM_RELATIONS,\n",
    "# embedding_dim=EMBEDDING_DIM,\n",
    "# output_dim=OUTPUT_DIM,\n",
    "# seed=SEED\n",
    "# )\n",
    "\n",
    "triples,traces,nopred = utils.concat_triples(data, data['rules'])\n",
    "entities = data['all_entities'].tolist()\n",
    "relations = data['all_relations'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join('..','data','weights',RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "#trainexp2idx = utils.array2idx(traces,ent2idx,rel2idx)\n",
    "nopred2idx = utils.array2idx(nopred,ent2idx,rel2idx)\n",
    "\n",
    "test2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "testexp2idx = utils.array2idx(traces,ent2idx,rel2idx)\n",
    "\n",
    "ADJACENCY_DATA = tf.concat([\n",
    "    #train2idx,\n",
    "    #trainexp2idx.reshape(-1,3),\n",
    "    nopred2idx,\n",
    "    test2idx,\n",
    "    testexp2idx.reshape(-1,3)\n",
    "    ],axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mats = utils.get_adj_mats(ADJACENCY_DATA,NUM_ENTITIES,NUM_RELATIONS)\n",
    "\n",
    "tf_data = tf.data.Dataset.from_tensor_slices(\n",
    "        (test2idx[:,0],test2idx[:,1],test2idx[:,2],testexp2idx)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for head, rel, tail, true_exp in tf_data:\n",
    "\n",
    "    with tf.GradientTape(watch_accessed_variables=False,persistent=True) as tape:\n",
    "\n",
    "        tape.watch(adj_mats)\n",
    "\n",
    "        pred = model([\n",
    "            ALL_INDICES,\n",
    "            tf.reshape(head,(1,-1)),\n",
    "            tf.reshape(rel,(1,-1)),\n",
    "            tf.reshape(tail,(1,-1)),\n",
    "            adj_mats\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(NUM_RELATIONS):\n",
    "    \n",
    "    adj_mat_i = adj_mats[i]\n",
    "    \n",
    "    for idx,score in enumerate(tape.gradient(pred,adj_mat_i.values).numpy()):\n",
    "        if score:\n",
    "            scores.append((idx,i,score))\n",
    "            \n",
    "top_k_scores = sorted(scores, key=lambda x : x[2],reverse=True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_triples = []\n",
    "\n",
    "for idx,rel,score in top_k_scores:\n",
    "\n",
    "    indices =  adj_mats[rel].indices.numpy()[idx,1:]\n",
    "\n",
    "    head,tail = indices\n",
    "\n",
    "    pred_triple = [head,rel,tail]\n",
    "\n",
    "    pred_triples.append(pred_triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(os.path.join('..','data','preds','explaine_uncle_preds.npz'),allow_pickle=True)\n",
    "\n",
    "def jaccard_score(true_exp,pred_exp,top_k):\n",
    "\n",
    "    true_exp = true_exp[:top_k]#remove padding\n",
    "\n",
    "    num_true_traces = true_exp.shape[0]\n",
    "    num_pred_traces = pred_exp.shape[0]\n",
    "\n",
    "    count = 0\n",
    "    for pred_row in pred_exp:\n",
    "        for true_row in true_exp:\n",
    "            if (pred_row == true_row).all():\n",
    "                count +=1\n",
    "\n",
    "    score = count / (num_true_traces + num_pred_traces-count)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_traces = utils.array2idx(traces[d['test_idx']],ent2idx,rel2idx)\n",
    "\n",
    "# j = 0\n",
    "# num = d['preds'].shape[0]\n",
    "# for i in range(num):\n",
    "#     j += jaccard_score(new_traces[i],d['preds'][i],2)\n",
    "# print(j/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['spouse_entities'].shape[0])\n",
    "print(data['uncle_entities'].shape[0])\n",
    "print(data['aunt_entities'].shape[0])\n",
    "print(data['successor_entities'].shape[0])\n",
    "print(data['predecessor_entities'].shape[0])\n",
    "print(data['grandparent_entities'].shape[0])\n",
    "print(data['brother_entities'].shape[0])\n",
    "print(data['sister_entities'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['spouse_triples'].shape[0])\n",
    "print(data['uncle_triples'].shape[0])\n",
    "print(data['aunt_triples'].shape[0])\n",
    "print(data['brother_triples'].shape[0])\n",
    "print(data['sister_triples'].shape[0])\n",
    "print(data['successor_triples'].shape[0])\n",
    "print(data['predecessor_triples'].shape[0])\n",
    "print(data['grandparent_triples'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triples,traces,nopred = utils.concat_triples(data, data['rules'])\n",
    "# entities = data['all_entities'].tolist()\n",
    "# relations = data['all_relations'].tolist()\n",
    "RULE = 'brother'\n",
    "\n",
    "triples,traces,nopred = utils.concat_triples(data, [RULE,'brother','sister'])\n",
    "sister_relations = data['sister_relations'].tolist()\n",
    "sister_entities = data['sister_entities'].tolist()\n",
    "\n",
    "brother_relations = data['brother_relations'].tolist()\n",
    "brother_entities = data['brother_entities'].tolist()\n",
    "\n",
    "entities = np.unique(data[RULE + '_entities'].tolist()+brother_entities+sister_entities).tolist()\n",
    "relations = np.unique(data[RULE + '_relations'].tolist()+brother_relations+sister_relations).tolist()\n",
    "\n",
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "# CONSTRUCT {\n",
    "#     ?a dbo:uncle ?myuncle .\n",
    "# }\n",
    "# WHERE {\n",
    "#     ?myuncle dbo:brother ?myparent .\n",
    "#     ?a dbo:parent ?myparent . \n",
    "    \n",
    "#     FILTER (!EXISTS {?a dbo:uncle ?myuncle})\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(triples, axis=0).shape\n",
    "\n",
    "# np.unique(data['sister_triples'], axis=0, return_index=True)\n",
    "a = np.array([[1,2,3],[1,2,3],[1,0,0],[1,0,0],[1,2,2]])\n",
    "_, idx = np.unique(a, axis=0, return_index=True)\n",
    "\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if (current_preds == true_row).all(axis=1).sum() >= 1:             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_data = np.load(os.path.join('..','data','preds','gnn_explainer_'+RULE+'_preds.npz'),allow_pickle=True)\n",
    "\n",
    "gnn_exp2idx = utils.array2idx(traces[gnn_data['test_idx']],ent2idx,rel2idx)\n",
    "gnn_num_triples = gnn_exp2idx.shape[0]\n",
    "\n",
    "all_gnn_preds = gnn_data['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_exps(exp2idx,num_triples, trace_length):\n",
    "\n",
    "    true_exps = []\n",
    "    for i in range(num_triples):\n",
    "        \n",
    "        true_exps.append(exp2idx[i][0:trace_length,:])\n",
    "\n",
    "    true_exps = np.array(true_exps)\n",
    "\n",
    "    return true_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_true_exps = get_true_exps(gnn_exp2idx,gnn_num_triples, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_preds = []\n",
    "for i in range(all_gnn_preds.shape[0]):\n",
    "    preds_i = []\n",
    "    for idx, j in enumerate(all_gnn_preds[i]):\n",
    "        if j.shape[0] > 0:\n",
    "            rel = np.ones((j.shape[0]),dtype=np.int64) * idx\n",
    "            preds_i.append(np.column_stack((j[:,0],rel,j[:,1])))            \n",
    "    gnn_preds.append(np.concatenate(preds_i, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_tp = 0.0\n",
    "current_fp = 0.0\n",
    "current_fn = 0.0\n",
    "\n",
    "true_exp = gnn_true_exps[0]\n",
    "current_preds = gnn_preds[0]\n",
    "\n",
    "for pred_row in current_preds:\n",
    "    for true_row in true_exp:\n",
    "        print(pred_row)\n",
    "        print(true_row)\n",
    "        break\n",
    "    break\n",
    "#         reversed_row = true_row[[2,1,0]]\n",
    "        \n",
    "#         if (pred_row == true_row).all() or (pred_row == reversed_row).all():\n",
    "#             current_tp += 1            \n",
    "#         else:\n",
    "#             current_fp +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "print(triples[i])\n",
    "print(traces[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "# print(triples[i])\n",
    "# print(traces[i])\n",
    "\n",
    "plot_triples = np.concatenate([triples[i].reshape(1,3),traces[i].reshape(-1,3)], axis=0)\n",
    "plot_triples = plot_triples[0:-1,:]\n",
    "plot_triples-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.MultiDiGraph()\n",
    "# for triple in plot_triples:\n",
    "#     G.add_node(triple[0])\n",
    "#     #G.add_node(triple[1])\n",
    "#     G.add_node(triple[2])\n",
    "#     G.add_edge(triple[0], triple[1])\n",
    "#     G.add_edge(triple[1], triple[2])\n",
    "\n",
    "# pos = nx.spring_layout(G)\n",
    "# plt.figure(figsize=(6,4))\n",
    "# nx.draw(G, pos, edge_color='black', width=1, linewidths=1,\n",
    "#         node_size=500, node_color='skyblue', alpha=0.9,\n",
    "#         labels={node: node for node in G.nodes()})\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "for triple in plot_triples:\n",
    "    G.add_node(triple[0])\n",
    "    #G.add_node(triple[1])\n",
    "    G.add_node(triple[2])\n",
    "    #G.add_edge(triple[0], triple[1])\n",
    "    #G.add_edge(triple[1], triple[2])\n",
    "    G.add_edge(triple[0], triple[2])\n",
    "\n",
    "pos = nx.spring_layout(G,seed=SEED)\n",
    "#pos = nx.random_layout(G)\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "nx.draw(G, pos, edge_color='black', width=1, linewidths=1,\n",
    "        node_size=500, node_color='skyblue', alpha=0.9,\n",
    "        font_size=12,\n",
    "        labels={node: node for node in G.nodes()})\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={('Princess_Clémentine_of_Belgium',\n",
    "                                                 'Archduchess_Hermine_of_Austria'):'aunt',\n",
    "('Marie_Henriette_of_Austria',\n",
    " 'Archduchess_Hermine_of_Austria'):'sister',\n",
    "('Princess_Clémentine_of_Belgium','Marie_Henriette_of_Austria'):'parent'},\n",
    "                             font_color='black',font_size=12)\n",
    "ax = plt.gca()\n",
    "ax.margins(0.25)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('../data/plots/example.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "EMBEDDING_DIM = 50\n",
    "OUTPUT_DIM = 50\n",
    "\n",
    "ALL_INDICES = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(os.path.join('..','data','preds','explaine_'+RULE+'_preds.npz'))\n",
    "\n",
    "new_traces = utils.array2idx(traces[d['test_idx']],ent2idx,rel2idx)\n",
    "\n",
    "j = 0\n",
    "num = d['preds'].shape[0]\n",
    "for i in range(num):\n",
    "    j += jaccard_score(new_traces[i],d['preds'][i],1)\n",
    "print(j/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN.get_RGCN_Model(\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    num_relations=NUM_RELATIONS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "model.load_weights(os.path.join('..','data','weights',RULE+'.h5'))\n",
    "\n",
    "# X = model.get_layer('entity_embeddings').get_weights()[0]\n",
    "# S1 = 1.\n",
    "# S2 = 1.5\n",
    "# EMBEDDING_DIM = X.shape[1]\n",
    "# GAMMA = (1/(S1**2)) - (1/(S2**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file=np.load(os.path.join('..','data','preds','gnn_explainer_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_length = 2\n",
    "\n",
    "exp2idx = utils.array2idx(traces[in_file['test_idx']],ent2idx,rel2idx)\n",
    "num_triples = exp2idx.shape[0]\n",
    "\n",
    "true_exps = []\n",
    "for i in range(num_triples):\n",
    "    \n",
    "    true_exps.append(exp2idx[i][0:trace_length,:])\n",
    "\n",
    "true_exps = np.array(true_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explaine_in_file=np.load(os.path.join('..','data','preds','explaine_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explaine_in_file['preds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_preds = []\n",
    "for i in range(in_file['preds'].shape[0]):\n",
    "    preds_i = []\n",
    "    for idx, j in enumerate(in_file['preds'][i]):\n",
    "        if j.shape[0] > 0:\n",
    "            rel = np.ones((j.shape[0]),dtype=np.int64) * idx\n",
    "            preds_i.append(np.column_stack((j[:,0],rel,j[:,1])))            \n",
    "    clean_preds.append(np.concatenate(preds_i, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 0.0\n",
    "recall = 0.0\n",
    "\n",
    "for i in range(num_triples):\n",
    "    \n",
    "    current_tp = 0.0\n",
    "    current_fp = 0.0\n",
    "    current_fn = 0.0\n",
    "    \n",
    "    true_exp = true_exps[i]\n",
    "    current_preds = clean_preds[i]\n",
    "    \n",
    "    #print('pred size', current_preds.shape)\n",
    "    \n",
    "    for pred_row in current_preds:\n",
    "        \n",
    "        for true_row in true_exp:\n",
    "            \n",
    "            reversed_row = true_row[[2,1,0]]\n",
    "            \n",
    "            if (pred_row == true_row).all() or (pred_row == reversed_row).all():\n",
    "                current_tp += 1\n",
    "            elif (pred_row != true_row).all() or (pred_row != reversed_row).all():\n",
    "                current_fp += 1\n",
    "                \n",
    "            if (current_preds == true_row).all(axis=1).sum() >= 1:\n",
    "                #this means true explanation triple is in set of predicitons\n",
    "                pass\n",
    "            else:\n",
    "                current_fn += 1\n",
    "    \n",
    "    current_precision = current_tp / (current_tp + current_fp)\n",
    "    current_recall = current_tp / (current_tp + current_fn)\n",
    "    \n",
    "    precision += current_precision\n",
    "    recall += current_recall\n",
    "     \n",
    "precision /= num_triples\n",
    "recall /= num_triples\n",
    "\n",
    "print('precision',precision)\n",
    "print('recall',recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision = tp / (tp + fp)\n",
    "# recall = tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add relation to triple array (clean up preds)\n",
    "#add reverse triples to ground truth explanation\n",
    "#compute precision, recall for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# kf = KFold(n_splits=3,shuffle=True,random_state=SEED)\n",
    "# indices = [(train_idx,test_idx) for train_idx,test_idx in kf.split(X=triples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx,test_idx = indices[-1]\n",
    "\n",
    "# train2idx = utils.array2idx(triples[train_idx],ent2idx,rel2idx)\n",
    "# trainexp2idx = utils.array2idx(traces[train_idx],ent2idx,rel2idx)\n",
    "# nopred2idx = utils.array2idx(nopred,ent2idx,rel2idx)\n",
    "\n",
    "# test2idx = utils.array2idx(triples[test_idx],ent2idx,rel2idx)\n",
    "# testexp2idx = utils.array2idx(traces[test_idx],ent2idx,rel2idx)\n",
    "\n",
    "# ADJACENCY_DATA = tf.concat([\n",
    "#     train2idx,\n",
    "#     trainexp2idx.reshape(-1,3),\n",
    "#     nopred2idx,\n",
    "#     test2idx,\n",
    "#     testexp2idx.reshape(-1,3)\n",
    "#     ],axis=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file['preds'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj_mats = utils.get_adj_mats(ADJACENCY_DATA,NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_data = tf.data.Dataset.from_tensor_slices(\n",
    "#             (test2idx[:,0],test2idx[:,1],test2idx[:,2],testexp2idx)).batch(1)\n",
    "\n",
    "# for head,rel,tail,exp in tf_data:\n",
    "#     print(head,rel,tail,exp)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.GradientTape(watch_accessed_variables=False,persistent=True) as tape:\n",
    "    \n",
    "#     tape.watch(adj_mats)\n",
    "    \n",
    "#     pred = model([\n",
    "#         ALL_INDICES,\n",
    "#         tf.reshape(head,(1,-1)),\n",
    "#         tf.reshape(rel,(1,-1)),\n",
    "#         tf.reshape(tail,(1,-1)),\n",
    "#         adj_mats\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pred_indices(tape,pred,adj_mats_i,top_k):\n",
    "#     scores = []\n",
    "#     for idx, score in enumerate(tape.gradient(pred,adj_mats_i.values).numpy()):\n",
    "#         if score:\n",
    "#             scores.append((idx,score))\n",
    "    \n",
    "#     sorted_scores = sorted(scores, key=lambda x : x[1],reverse=True)[0:top_k]\n",
    "\n",
    "#     return [idx for idx,_ in sorted_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 2\n",
    "scores = []\n",
    "for i in range(NUM_RELATIONS):\n",
    "        \n",
    "    adj_mat_i = adj_mats[i]\n",
    "        \n",
    "    for idx, score in enumerate(tape.gradient(pred,adj_mat_i.values).numpy()):\n",
    "        if score:\n",
    "            scores.append((idx,i,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_scores = sorted(scores, key=lambda x : x[2],reverse=True)[:top_k]\n",
    "\n",
    "pred_triples = []\n",
    "\n",
    "for idx,rel,score in top_k_scores:\n",
    "    \n",
    "    indices =  adj_mats[rel].indices.numpy()[idx,1:]\n",
    "\n",
    "    head,tail = indices\n",
    "    \n",
    "    pred_triple = [head,rel,tail]\n",
    "    \n",
    "    pred_triples.append(pred_triple)\n",
    "\n",
    "np.array(pred_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(adj_mats,num_relations,top_k,tape,pred):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i in range(num_relations):\n",
    "        \n",
    "        adj_mat_i = adj_mats[i]\n",
    "        \n",
    "        for idx,score in enumerate(tape.gradient(pred,adj_mat_i.values).numpy()):\n",
    "            if score:\n",
    "                scores.append((idx,i,score))\n",
    "                \n",
    "    top_k_scores = sorted(scores, key=lambda x : x[2],reverse=True)[:top_k]\n",
    "    \n",
    "    pred_triples = []\n",
    "    \n",
    "    for idx,rel,score in top_k_scores:\n",
    "        \n",
    "        indices =  adj_mats[rel].indices.numpy()[idx,1:]\n",
    "\n",
    "        head,tail = indices\n",
    "\n",
    "        pred_triple = [head,rel,tail]\n",
    "\n",
    "        pred_triples.append(pred_triple)\n",
    "\n",
    "    return np.array(pred_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp = get_preds(adj_mats,NUM_RELATIONS,2,tape,pred)\n",
    "pred_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_score(true_exp,pred_exp,top_k):\n",
    "\n",
    "    true_exp = true_exp[:top_k]\n",
    "\n",
    "    num_true_traces = true_exp.shape[0]\n",
    "    num_pred_traces = pred_exp.shape[0]\n",
    "\n",
    "    count = 0\n",
    "    for pred_row in pred_exp:\n",
    "        for true_row in true_exp:\n",
    "            if (pred_row == true_row).all():\n",
    "                count +=1\n",
    "\n",
    "    score = count / (num_true_traces + num_pred_traces-count)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testexp2idx[0][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(pred_exp,pred_exp,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(os.path.join('..','data','preds','explaine_'+RULE+'_preds.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "\n",
    "new_traces = utils.array2idx(traces[d['test_idx']],ent2idx,rel2idx)\n",
    "\n",
    "num = d['preds'].shape[0]\n",
    "for i in range(num):\n",
    "    j += jaccard_score(new_traces[i],d['preds'][i],1)\n",
    "\n",
    "print(j/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.array2idx(traces[in_file['test_idx']],ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_pred = np.array([[0,850,920],[0,920,850],[0,920,8505],[0,8505 ,920]])\n",
    "\n",
    "# new_exp = np.array([[0,920,8505],[0,8505 ,920]])\n",
    "\n",
    "# num_true_traces = new_exp.shape[0]\n",
    "# num_pred_traces = new_pred.shape[0]\n",
    "\n",
    "# count = 0\n",
    "# for pred_row in new_pred:\n",
    "#     for true_row in new_exp:\n",
    "#         if (pred_row == true_row).all():\n",
    "#             count +=1\n",
    "\n",
    "# count / (num_true_traces + num_pred_traces-count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "idx2ent = dict(zip(range(NUM_ENTITIES),entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.load(os.path.join('..','data','preds','explaine_'+RULE+'_preds.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = int(pred_data['best_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3,shuffle=True,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_data = [test_idx for _, test_idx in kf.split(X=triples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = cf_data[best_idx]\n",
    "\n",
    "cv_triples = triples[idx]\n",
    "cv_traces = traces[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2idx = utils.array2idx(cv_triples,ent2idx,rel2idx)\n",
    "testexp2idx = utils.array2idx(cv_traces,ent2idx,rel2idx)[:,:,[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pred_data['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard, scores = explaiNE.jaccard_score(testexp2idx,preds,TOP_K,return_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_idx = scores < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_triples = cv_triples[error_idx]\n",
    "error_traces = cv_traces[error_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(error_triples[i])\n",
    "print(error_traces[i][0:TOP_K,])\n",
    "print(idx2ent[preds[i][0][0]],idx2ent[preds[i][0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join('..','data','weights',RULE+'.h5'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_scores = []\n",
    "preds = []\n",
    "\n",
    "train2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "trainexp2idx = utils.array2idx(traces,ent2idx,rel2idx)\n",
    "nopred2idx = utils.array2idx(nopred,ent2idx,rel2idx)\n",
    "\n",
    "#adjacency_data = tf.concat([train2idx,trainexp2idx.reshape(-1,3),nopred2idx],axis=0)\n",
    "\n",
    "test2idx = utils.array2idx(triples,ent2idx,rel2idx)\n",
    "testexp2idx = utils.array2idx(traces,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_data = tf.concat([\n",
    "    train2idx,\n",
    "    trainexp2idx.reshape(-1,3),\n",
    "    nopred2idx,\n",
    "    test2idx,\n",
    "    testexp2idx.reshape(-1,3)\n",
    "    ],axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_data[adjacency_data[:,0] == h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraphs_list = [utils.get_adj_mats(testexp2idx[i],NUM_ENTITIES,NUM_RELATIONS) for i in range(testexp2idx.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.from_tensor_slices((test2idx[:,0],test2idx[:,1],test2idx[:,2],testexp2idx)).batch(1)\n",
    "\n",
    "dist_dataset = strategy.experimental_distribute_dataset(d)\n",
    "\n",
    "# for h,r,t,l in dist_dataset:\n",
    "#     print(h,r,t,tf.squeeze(l,axis=0))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraphs = true_subgraphs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in true_subgraphs[5].indices:\n",
    "#     print(row)\n",
    "\n",
    "tf.reduce_all(true_subgraphs[5].indices[0] == true_subgraphs[5].indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_jaccard(true_exp,pred_exp):\n",
    "    \n",
    "    num_true_traces = true_exp.shape[0]\n",
    "    num_pred_traces = pred_exp.shape[0]\n",
    "    \n",
    "    count = 0\n",
    "    for pred_row in pred_exp:\n",
    "        for true_row in true_exp:\n",
    "            if tf.reduce_all(pred_row == true_row):\n",
    "                count += 1\n",
    "    score = count / (num_true_traces + num_pred_traces-count)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cond(tf.reduce_all(true_subgraphs[5].indices[0]==true_subgraphs[5].indices[0]), lambda :1, lambda:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_subgraphs[5].indices\n",
    "tf.boolean_mask(train2idx,train2idx[:,0] == 167)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2idx[train2idx[:,0] == 167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "model = RGCN.get_RGCN_Model(\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    num_relations=NUM_RELATIONS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "model.load_weights(os.path.join('..','data','weights',RULE+'.h5'))\n",
    "#kf = KFold(n_splits=3,shuffle=True,random_state=SEED)\n",
    "cv_scores = []\n",
    "cv_preds = []\n",
    "\n",
    "masks = [tf.Variable(\n",
    "        initial_value=tf.random.normal(\n",
    "            (1,NUM_ENTITIES,NUM_ENTITIES), \n",
    "            mean=0, \n",
    "            stddev=1, \n",
    "            dtype=tf.float32, \n",
    "            seed=SEED),\n",
    "        name='mask_'+str(i),\n",
    "        trainable=True) for i in range(NUM_RELATIONS)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[0].assign(tf.random.normal(\n",
    "            (1,NUM_ENTITIES,NUM_ENTITIES), \n",
    "            mean=0, \n",
    "            stddev=1, \n",
    "            dtype=tf.float32, \n",
    "            seed=SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2idx = tf.expand_dims(test2idx,axis=0)\n",
    "\n",
    "jaccard_scores = []\n",
    "preds = []\n",
    "\n",
    "adj_mats = utils.get_adj_mats(adjacency_data, NUM_ENTITIES,NUM_RELATIONS)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "\n",
    "        tape.watch(masks)\n",
    "\n",
    "        masked_adjs = [adj_mats[i] * tf.sigmoid(masks[i]) for i in range(NUM_RELATIONS)]\n",
    "\n",
    "        test_preds =  model([\n",
    "            all_indices,\n",
    "            test2idx[:,0:2,0],\n",
    "            test2idx[:,0:2,1],\n",
    "            test2idx[:,0:2,2],\n",
    "            masked_adjs\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        loss = tf.reduce_mean(-1 * tf.math.log(test_preds+0.00001))#+ tf.reduce_mean(masks)\n",
    "\n",
    "    print(f\"Loss {loss} @ epoch {epoch}\")\n",
    "    grads = tape.gradient(loss,masks)\n",
    "    optimizer.apply_gradients(zip(grads,masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_subgraphs(\n",
    "    true_subgraphs,\n",
    "    adj_mats,\n",
    "    masks,\n",
    "    num_relations,\n",
    "    num_entities,\n",
    "    threshold\n",
    "    ):\n",
    "    \n",
    "    '''Compute jaccard score across all relations for one triple'''\n",
    "\n",
    "    scores = []\n",
    "    pred_graphs = []\n",
    "\n",
    "    for i in range(num_relations):\n",
    "\n",
    "        mask_i = adj_mats[i] * tf.nn.sigmoid(masks[i])\n",
    "\n",
    "        non_masked_indices = tf.gather(mask_i.indices[mask_i.values > threshold], [1,2],axis=1)\n",
    "\n",
    "        if non_masked_indices.shape[0]:\n",
    "\n",
    "            pred_graph = csr_matrix(\n",
    "                (tf.ones(non_masked_indices.shape[0]),(non_masked_indices[:,0],non_masked_indices[:,1])),\n",
    "                shape=(num_entities,num_entities)\n",
    "            )\n",
    "\n",
    "            pred_graphs.append(non_masked_indices)\n",
    "\n",
    "        else:\n",
    "\n",
    "            pred_graph = csr_matrix(([],([],[])),shape=(num_entities,num_entities))\n",
    "            pred_graphs.append([])\n",
    "\n",
    "        true_indices = true_subgraphs[i].indices\n",
    "\n",
    "        if true_indices.shape[0]:\n",
    "\n",
    "            gather = tf.gather(true_indices,[1,2],axis=1)\n",
    "\n",
    "            true_graph = csr_matrix(\n",
    "                (true_subgraphs[i].values,(gather[:,0],gather[:,1])),\n",
    "                shape=(num_entities,num_entities))\n",
    "\n",
    "        else:\n",
    "            true_graph = csr_matrix(([],([],[])),shape=(num_entities,num_entities))\n",
    "\n",
    "\n",
    "        score = jaccard_score(true_graph,pred_graph,average='micro')\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    return tf.reduce_mean(scores[1:]), pred_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraphs = utils.get_adj_mats(testexp2idx[0],NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccard, _ = score_subgraphs(\n",
    "#     true_subgraphs=true_subgraphs,\n",
    "#     adj_mats=adj_mats,\n",
    "#     masks=masks,\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     threshold=THRESHOLD\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_RELATIONS):\n",
    "    \n",
    "    print(tf.sparse.to_dense(adj_mats[i]).numpy().sum())\n",
    "    print(tf.nn.sigmoid(masks[i]).numpy().sum())\n",
    "    mask_i = adj_mats[i] * tf.nn.sigmoid(masks[i])\n",
    "\n",
    "    non_masked_indices = tf.gather(mask_i.indices[mask_i.values > THRESHOLD], [1,2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1*tf.math.log(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_i = true_subgraphs[5] * tf.nn.sigmoid(masks[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(tf.cast(tf.sigmoid(true_subgraphs[5].values) > .5,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'spouse'\n",
    "sister_relations = data['sister_relations'].tolist()\n",
    "sister_entities = data['sister_entities'].tolist()\n",
    "\n",
    "brother_relations = data['brother_relations'].tolist()\n",
    "brother_entities = data['brother_entities'].tolist()\n",
    "\n",
    "entities = np.unique(data[RULE + '_entities'].tolist()+brother_entities+sister_entities).tolist()\n",
    "relations = np.unique(data[RULE + '_relations'].tolist()+brother_relations+sister_relations).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp = tf.convert_to_tensor(np.array([[0,922,8507],[0,0,0],[0,1,1]]))\n",
    "pred_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_exp = mask_i.indices[mask_i.values > .5]\n",
    "true_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.cast(tf.reduce_sum(tf.cast(mask_i.values > .5,dtype=tf.float32)),dtype=tf.int32)\n",
    "#mask_i.indices[mask_i.values > .5]\n",
    "# def fun(x):\n",
    "#     print(x)\n",
    "#     other = mask_i.indices[mask_i.values > .5]\n",
    "#     print('equality',tf.equal(x,other))\n",
    "#     return tf.reduce_all(tf.equal(x,other),axis=1)\n",
    "# tf.map_fn(fn=fun,elems=mask_i.indices[mask_i.values > .5],dtype=tf.bool)\n",
    "\n",
    "def outer(x):\n",
    "    def inner(y):\n",
    "#         print('x',x)\n",
    "#         print('y',y)\n",
    "#         print('equality',tf.reduce_all(tf.equal(x,y)))\n",
    "        return tf.reduce_all(tf.equal(x,y))\n",
    "    \n",
    "    return tf.map_fn(fn=inner,elems=pred_exp,dtype=tf.bool)\n",
    "\n",
    "tf.reduce_sum(tf.cast(tf.map_fn(fn=outer,elems=true_exp,\n",
    "                                dtype=tf.bool),dtype=tf.float32),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     test2idx = tf.expand_dims(test2idx,axis=0)\n",
    "\n",
    "#     jaccard_scores = []\n",
    "#     preds = []\n",
    "\n",
    "#     adj_mats = utils.get_adj_mats(adjacency_data, NUM_ENTITIES,NUM_RELATIONS)\n",
    "\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "#         with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "\n",
    "#             tape.watch(masks)\n",
    "\n",
    "#             masked_adjs = [adj_mats[i] * tf.sigmoid(masks[i]) for i in range(NUM_RELATIONS)]\n",
    "\n",
    "#             test_preds =  model([\n",
    "#                 all_indices,\n",
    "#                 test2idx[:,0:2,0],\n",
    "#                 test2idx[:,0:2,1],\n",
    "#                 test2idx[:,0:2,2],\n",
    "#                 masked_adjs\n",
    "#                 ]\n",
    "#             )\n",
    "\n",
    "#             penalty = tf.reduce_sum([tf.reduce_sum(\n",
    "#                 tf.cast(masked_adjs[i].values > .5,dtype=tf.int64)) for i in range(NUM_RELATIONS)])\n",
    "\n",
    "#             loss = tf.reduce_mean(-1 * tf.math.log(test_preds+0.00001)) + (.001 * penalty.numpy())#+ tf.reduce_mean(masks)\n",
    "\n",
    "#         print(f\"Loss {tf.reduce_mean(loss)} @ epoch {epoch}\")\n",
    "\n",
    "#         grads = tape.gradient(loss,masks)\n",
    "#         optimizer.apply_gradients(zip(grads,masks))\n",
    "\n",
    "#     j_scores = []\n",
    "\n",
    "#     #for i in range(testexp2idx.shape[0]):\n",
    "#     for i in range(2):\n",
    "\n",
    "#         true_subgraphs = utils.get_adj_mats(testexp2idx[i],NUM_ENTITIES,NUM_RELATIONS)\n",
    "\n",
    "#         jaccard, _ = score_subgraphs(\n",
    "#             true_subgraphs=true_subgraphs,\n",
    "#             adj_mats=adj_mats,\n",
    "#             masks=masks,\n",
    "#             num_relations=NUM_RELATIONS,\n",
    "#             num_entities=NUM_ENTITIES,\n",
    "#             threshold=THRESHOLD\n",
    "#         )\n",
    "\n",
    "#         j_scores.append(jaccard)\n",
    "#         #preds.append(pred)\n",
    "\n",
    "#     cv_avg = tf.reduce_mean(j_scores)\n",
    "#     print(f\"Cv jaccard scores {cv_avg}\")\n",
    "\n",
    "#     cv_scores.append(cv_avg)\n",
    "#     #cv_preds.append(preds)\n",
    "\n",
    "\n",
    "# best_idx = np.argmin(cv_scores)\n",
    "# #best_preds = cv_preds[best_idx]\n",
    "\n",
    "# print(f\"Overall jaccard score: {tf.reduce_mean(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(os.path.join('..','data','preds','gnn_explainer_'+RULE+'_preds.npz'),\n",
    "#     preds=pred_graphs,embedding_dim=EMBEDDING_DIM,k=K,\n",
    "#     threshold=THRESHOLD,learning_rate=LEARNING_RATE,num_epochs=NUM_EPOCHS\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "in_file=np.load(os.path.join('..','data','preds','gnn_explainer_'+'spouse'+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# head_output = tf.matmul(tf.reshape(entity_embeddings[head],(1,-1)),self_kernel)\n",
    "# tail_output = tf.matmul(tf.reshape(entity_embeddings[tail],(1,-1)),self_kernel)\n",
    "\n",
    "# for i in range(NUM_RELATIONS):\n",
    "\n",
    "#     adj_i = tf.sparse.to_dense(adj_mats[i])[0] * tf.sigmoid(masks[i][0])\n",
    "\n",
    "#     sum_embeddings = tf.matmul(adj_i,entity_embeddings)\n",
    "\n",
    "#     head_update = tf.reshape(sum_embeddings[head],(1,-1))\n",
    "#     tail_update = tf.reshape(sum_embeddings[tail],(1,-1))\n",
    "\n",
    "#     head_output += tf.matmul(head_update,relation_kernel[i])\n",
    "#     tail_output += tf.matmul(tail_update,relation_kernel[i])\n",
    "\n",
    "# # for i in range(NUM_RELATIONS):\n",
    "\n",
    "# #     adj_i = tf.sparse.reshape(adj_mats[i] * tf.sigmoid(masks[i]), (NUM_ENTITIES,NUM_ENTITIES))\n",
    "\n",
    "# head_output = tf.sigmoid(head_output)\n",
    "# tail_output = tf.sigmoid(tail_output)\n",
    "\n",
    "# pred = tf.sigmoid(tf.reduce_sum(head_output*relation_kernel[rel]*tail_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
