{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import random as rn\n",
    "import RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "RULE = 'aunt'\n",
    "\n",
    "data = np.load(os.path.join('..','data','royalty.npz'))\n",
    "\n",
    "triples, traces = data[RULE + '_triples'], data[RULE + '_traces']\n",
    "\n",
    "entities = data[RULE + '_entities'].tolist()\n",
    "relations = data[RULE + '_relations'].tolist()\n",
    "\n",
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "EMBEDDING_DIM = 25\n",
    "OUTPUT_DIM = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "train2idx = utils.array2idx(triples, ent2idx,rel2idx)\n",
    "\n",
    "NUM_TRIPLES = train2idx.shape[0]\n",
    "\n",
    "# adj_mats = utils.get_adjacency_matrix_list(\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     data=train2idx\n",
    "# )\n",
    "\n",
    "train2idx = np.expand_dims(train2idx,axis=0)\n",
    "all_indices = np.arange(NUM_ENTITIES).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainexp2idx = utils.array2idx(traces, ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.concatenate([train2idx[0][:,[0,2]],train2idx[0][:,[2,0]]],axis=0)\n",
    "\n",
    "# a = tf.sparse.SparseTensor(indices=indices,values=np.ones((indices.shape[0])),dense_shape=(NUM_ENTITIES,NUM_ENTITIES))\n",
    "# a = tf.sparse.reorder(\n",
    "#     a\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_adj_mats(data,num_entities,num_relations):\n",
    "\n",
    "#         adj_mats = []\n",
    "\n",
    "#         for i in range(num_relations):\n",
    "\n",
    "#             data_i = data[data[:,1] == i]\n",
    "\n",
    "#             indices = np.concatenate([data_i[:,[0,2]],data_i[:,[2,0]]],axis=0)\n",
    "\n",
    "#             sparse_mat = tf.sparse.SparseTensor(\n",
    "#                 indices=indices,\n",
    "#                 values=np.ones((indices.shape[0])),\n",
    "#                 dense_shape=(num_entities,num_entities)\n",
    "#                 )\n",
    "\n",
    "#             sparse_mat = tf.sparse.reorder(sparse_mat)\n",
    "\n",
    "#             sparse_mat = tf.sparse.reshape(sparse_mat, shape=(1,num_entities,num_entities))\n",
    "\n",
    "#             adj_mats.append(sparse_mat)\n",
    "\n",
    "#         return adj_mats\n",
    "\n",
    "# adj_mats = get_adj_mats(train2idx[0],NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train2idx = tf.convert_to_tensor(train2idx[0])\n",
    "\n",
    "def computation_graph_mats(head,tail,data,num_relations,num_entities):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbors_head = np.concatenate([train2idx[0][(train2idx[0][:,0] == 7874)],train2idx[0][(train2idx[0][:,2] == 7874)]])\n",
    "# neighbors_tail = np.concatenate([train2idx[0][(train2idx[0][:,0] == 8589)],train2idx[0][(train2idx[0][:,2] == 8589)]])\n",
    "\n",
    "# all_neighbors = np.concatenate([neighbors_head,neighbors_tail], axis=0)\n",
    "\n",
    "# indices = np.unique(all_neighbors[:,[1,0,2]], axis=0)\n",
    "\n",
    "# a = tf.sparse.SparseTensor(indices=indices,values=np.ones((indices.shape[0])),dense_shape=(1,NUM_ENTITIES,NUM_ENTITIES))\n",
    "# a = tf.sparse.reorder(\n",
    "#     a\n",
    "#)   \n",
    "#k_hop_adj_mats = tf.sparse.expand_dims(a, axis=0)\n",
    "# for i in neighbors_1_head[:,2]:\n",
    "#     print(i,train2idx[0][train2idx[0][:,0] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,r,t = train2idx[0,3,:]\n",
    "\n",
    "#filter train2idx to get neighbors -> feed into utils.get_adj_mats\n",
    "\n",
    "head = np.array([h])\n",
    "rel = np.array([r])\n",
    "tail = np.array([t])\n",
    "\n",
    "tf_k_hop_adj_mats = []\n",
    "\n",
    "for i in range(NUM_RELATIONS):\n",
    "    \n",
    "    data = tf_train2idx[tf_train2idx[:,1] == i]\n",
    "\n",
    "    tf_neighbors_head = tf.concat([data[data[:,0] == head],data[data[:,2] == head]],axis=0)\n",
    "    tf_neighbors_tail = tf.concat([data[(data[:,0] == tail) & (data[:,0] != head)],data[(data[:,2] == tail) & (data[:,0] != head)]],axis=0)\n",
    "\n",
    "    tf_all_neighbors = tf.concat([tf_neighbors_head,tf_neighbors_tail],axis=0)\n",
    "    \n",
    "    tf_indices = tf.transpose(tf.stack([tf_all_neighbors[:,0],tf_all_neighbors[:,2]]))\n",
    "\n",
    "    tf_k_hop_adj_mat = tf.sparse.SparseTensor(\n",
    "        indices=tf_indices,\n",
    "        values=tf.ones((tf_indices.shape[0])),\n",
    "        dense_shape=(NUM_ENTITIES,NUM_ENTITIES)\n",
    "    )\n",
    "    \n",
    "    tf_k_hop_adj_mat = tf.sparse.reorder(tf_k_hop_adj_mat)\n",
    "    \n",
    "    tf_k_hop_adj_mats.append(tf_k_hop_adj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_computation_graph(head,rel,tail,data,num_relations):\n",
    "    \n",
    "    '''Get 1st degree neighbors of head and tail'''\n",
    "     \n",
    "    subset = data[data[:,1] == rel]\n",
    "\n",
    "    neighbors_head = tf.concat([data[data[:,0] == head],\n",
    "                                data[data[:,2] == head]],axis=0)\n",
    "    neighbors_tail = tf.concat([data[(data[:,0] == tail) & (data[:,0] != head)],\n",
    "                                data[(data[:,2] == tail) & (data[:,0] != head)]],axis=0)\n",
    "\n",
    "    all_neighbors = tf.concat([neighbors_head,neighbors_tail],axis=0)\n",
    "\n",
    "    return all_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_mats(data,num_entities,num_relations,reshape=True):\n",
    "\n",
    "    adj_mats = []\n",
    "\n",
    "    for i in range(num_relations):\n",
    "\n",
    "        data_i = data[data[:,1] == i]\n",
    "   \n",
    "        indices = tf.concat([tf.gather(data_i,[0,2],axis=1),tf.gather(data_i,[2,0],axis=1)],axis=0)\n",
    "        \n",
    "        sparse_mat = tf.sparse.SparseTensor(\n",
    "            indices=indices,\n",
    "            values=tf.ones((indices.shape[0])),\n",
    "            dense_shape=(num_entities,num_entities)\n",
    "            )\n",
    "\n",
    "        sparse_mat = tf.sparse.reorder(sparse_mat)\n",
    "        \n",
    "        if reshape:\n",
    "            \n",
    "            sparse_mat = tf.sparse.reshape(sparse_mat, shape=(1,num_entities,num_entities))\n",
    "\n",
    "        adj_mats.append(sparse_mat)\n",
    "\n",
    "    return adj_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(34, 2), dtype=int64, numpy=\n",
       "array([[ 2425,  7667],\n",
       "       [ 2425,  7684],\n",
       "       [ 2425,  7699],\n",
       "       [ 2425,  7706],\n",
       "       [ 2425,  7712],\n",
       "       [ 2425,  7715],\n",
       "       [ 2425,  7839],\n",
       "       [ 2425,  7850],\n",
       "       [ 2425,  8589],\n",
       "       [ 2425,  8628],\n",
       "       [ 2425, 10731],\n",
       "       [ 2425, 11181],\n",
       "       [ 7667,  2425],\n",
       "       [ 7684,  2425],\n",
       "       [ 7699,  2425],\n",
       "       [ 7706,  2425],\n",
       "       [ 7712,  2425],\n",
       "       [ 7715,  2425],\n",
       "       [ 7805,  8589],\n",
       "       [ 7826,  8589],\n",
       "       [ 7833,  8589],\n",
       "       [ 7839,  2425],\n",
       "       [ 7850,  2425],\n",
       "       [ 7874,  8589],\n",
       "       [ 8589,  2425],\n",
       "       [ 8589,  7805],\n",
       "       [ 8589,  7826],\n",
       "       [ 8589,  7833],\n",
       "       [ 8589,  7874],\n",
       "       [ 8589,  8624],\n",
       "       [ 8624,  8589],\n",
       "       [ 8628,  2425],\n",
       "       [10731,  2425],\n",
       "       [11181,  2425]])>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.sparse.SparseTensor(indices=indices,values=np.ones((indices.shape[0])),dense_shape=(NUM_RELATIONS,NUM_ENTITIES,NUM_ENTITIES))\n",
    "#tf_indices = tf.transpose(tf.stack([tf_all_neighbors[:,1],tf_all_neighbors[:,0],tf_all_neighbors[:,2]]))\n",
    "\n",
    "c_graph = get_computation_graph(head,rel,tail,tf_train2idx,NUM_RELATIONS)\n",
    "get_adj_mats(c_graph, NUM_ENTITIES, NUM_RELATIONS,reshape=False)[1].indices\n",
    "\n",
    "#c_graph[c_graph[:,1] == 0]\n",
    "#tf.concat([tf_train2idx[tf_train2idx[:,0] == head],tf_train2idx[tf_train2idx[:,2] == head]],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_k_hop_adj_mats = tf.sparse.SparseTensor(\n",
    "#     indices=tf_indices,\n",
    "#     values=tf.ones((tf_indices.shape[0])),\n",
    "#     dense_shape=(NUM_RELATIONS,NUM_ENTITIES,NUM_ENTITIES))\n",
    "# tf_k_hop_adj_mats = tf.sparse.reorder(tf_k_hop_adj_mats)   \n",
    "# tf_k_hop_adj_mats = tf.sparse.expand_dims(tf_k_hop_adj_mats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method RGCN_Layer.call of <RGCN.RGCN_Layer object at 0x1945877ad0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RGCN_Layer.call of <RGCN.RGCN_Layer object at 0x1945877ad0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DistMult.call of <RGCN.DistMult object at 0x1943e06f50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DistMult.call of <RGCN.DistMult object at 0x1943e06f50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model = RGCN.get_RGCN_Model(\n",
    "        num_triples=NUM_TRIPLES,\n",
    "        num_entities=NUM_ENTITIES,\n",
    "        num_relations=NUM_RELATIONS,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        seed=SEED\n",
    "    )\n",
    "#model.load_weights(os.path.join('..','data','weights','rgcn.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_data = tf.expand_dims(tf_train2idx,axis=0)\n",
    "\n",
    "# model([all_indices, tf_data[:,:,0],tf_data[:,:,1],tf_data[:,:,2],tf_k_hop_adj_mats]) < .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [tf.Variable(\n",
    "            initial_value=tf.random.normal(\n",
    "                (NUM_ENTITIES,NUM_ENTITIES), \n",
    "                mean=0, \n",
    "                stddev=1, \n",
    "                dtype=tf.dtypes.float32, \n",
    "                seed=SEED),\n",
    "            name='mask_'+str(i),\n",
    "            trainable=True) for i in range(NUM_RELATIONS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'mask_0:0' shape=(14154, 14154) dtype=float32, numpy=\n",
       " array([[ 0.5693312 , -0.35097048,  0.60993767, ..., -0.3841859 ,\n",
       "         -1.5260998 , -2.1384628 ],\n",
       "        [-0.491991  ,  0.2880641 ,  0.48281935, ...,  2.5248125 ,\n",
       "         -0.13874033, -0.73854965],\n",
       "        [-1.024216  ,  0.24099654,  0.80837035, ...,  1.5315689 ,\n",
       "         -0.03924537,  0.4544497 ],\n",
       "        ...,\n",
       "        [-0.01932065,  0.92647284, -0.16475141, ..., -0.03513337,\n",
       "          2.0643313 ,  1.5485798 ],\n",
       "        [ 1.1980947 , -1.5618074 ,  0.66932935, ..., -0.5422449 ,\n",
       "         -0.22707364, -0.9244645 ],\n",
       "        [ 1.427597  ,  0.82098234,  1.7894857 , ...,  1.6456954 ,\n",
       "          0.18594119,  0.6266803 ]], dtype=float32)>,\n",
       " <tf.Variable 'mask_1:0' shape=(14154, 14154) dtype=float32, numpy=\n",
       " array([[ 0.7596297 ,  0.71485424,  0.05565393, ..., -0.99534994,\n",
       "         -0.6636354 , -1.4355375 ],\n",
       "        [-1.0351917 , -0.6631321 , -1.4279053 , ...,  0.5082331 ,\n",
       "         -1.2639966 , -0.25292748],\n",
       "        [ 0.5705039 ,  0.30452383,  1.5128876 , ...,  0.8542427 ,\n",
       "         -0.7121246 ,  0.02558553],\n",
       "        ...,\n",
       "        [-1.886578  , -0.13707715,  0.65484774, ..., -2.0028157 ,\n",
       "          1.8438172 ,  0.38065568],\n",
       "        [ 2.5213094 , -1.3284476 ,  0.42467126, ...,  1.5972447 ,\n",
       "          0.89676106,  0.06144577],\n",
       "        [-0.97752297, -1.2937081 , -2.3785067 , ...,  0.16124584,\n",
       "          0.38335037,  0.5983525 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bce = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_init = model(\n",
    "#             [\n",
    "#             all_indices,\n",
    "#             head.reshape(1,1),\n",
    "#             rel.reshape(1,1),\n",
    "#             tail.reshape(1,1),\n",
    "#             tf_k_hop_adj_mats\n",
    "#             ]\n",
    "#         )\n",
    "# y_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model([\n",
    "#             all_indices,\n",
    "#             train2idx[:,:,0],\n",
    "#             train2idx[:,:,1],\n",
    "#             train2idx[:,:,2],\n",
    "#             tf_k_hop_adj_mats\n",
    "#             ]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.9755638]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[0.52470076]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[0.9766091]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[0.5236299]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        tape.watch(masks)\n",
    "        \n",
    "        masked_adj = []\n",
    "        \n",
    "        for i in range(NUM_RELATIONS):\n",
    "            \n",
    "            masked_adj.append(tf_k_hop_adj_mats[i] * tf.nn.sigmoid(masks[i]))\n",
    "            \n",
    "        y_pred = model(\n",
    "            [\n",
    "            all_indices,\n",
    "            head.reshape(1,1),\n",
    "            rel.reshape(1,1),\n",
    "            tail.reshape(1,1),\n",
    "            masked_adj\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(y_pred)\n",
    "        loss = -1*tf.math.log(y_pred+.00001) + tf.reduce_mean(tf.nn.sigmoid(masks))\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "    grads = tape.gradient(loss,masks)\n",
    "    optimizer.apply_gradients(zip(grads,masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_subgraph = tf.cast((tf_k_hop_adj_mats*tf.nn.sigmoid(masks)) > .5,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_subgraph = [tf.cast((tf_k_hop_adj_mats[i]*tf.nn.sigmoid(masks[i])) > .5,dtype=tf.int32)\n",
    "#                  for i in range(NUM_RELATIONS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "true_subgraphs = get_adj_mats(tf_trainexp2idx[0],NUM_ENTITIES,NUM_RELATIONS,reshape=False)\n",
    "\n",
    "for i in range(NUM_RELATIONS):\n",
    "    \n",
    "    mask_i = tf_k_hop_adj_mats[i]*masks[i]\n",
    "    \n",
    "    if mask_i.indices.shape[0]:\n",
    "\n",
    "        non_masked_indices = mask_i.indices[mask_i.values > .5]\n",
    "\n",
    "        pred_graph = tf.sparse.SparseTensor(\n",
    "            indices=non_masked_indices,\n",
    "            values=tf.ones(non_masked_indices.shape[0]),\n",
    "            dense_shape=(NUM_ENTITIES,NUM_ENTITIES)\n",
    "        )\n",
    "        \n",
    "        pred_graph = tf.sparse.to_dense(pred_graph)\n",
    "        \n",
    "        true_graph = true_subgraphs[i]\n",
    "        \n",
    "        print(tf_binary_jaccard(true_graph,pred_graph))\n",
    "#    print(tf.sparse.to_dense(computation_graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODAY:\n",
    "#jaccard gnn explainer\n",
    "#name weight file -> retrain RGCN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.math.logical_and(tf_k_hop_adj_mats[1]==1.,tf_k_hop_adj_mats[1]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(tf_k_hop_adj_mats[1]* masks[1]).values > .5\n",
    "#a = tf.sparse.to_dense(tf_k_hop_adj_mats[1])\n",
    "#tf.reduce_sum(tf.cast(tf.math.logical_and(a==1,a==1), tf.float32))\n",
    "#tf_k_hop_adj_mats[1].indices[(tf_k_hop_adj_mats[1]* masks[1]).values > .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_binary_jaccard(true_graph,pred_graph):\n",
    "    \n",
    "    m11 = tf.reduce_sum(tf.cast(tf.math.logical_and(true_graph==1,\n",
    "                                                    pred_graph==1),dtype=tf.int32))\n",
    "    m01 = tf.reduce_sum(tf.cast(tf.math.logical_and(true_graph==0,\n",
    "                                                    pred_graph==1),dtype=tf.int32))\n",
    "    m10 = tf.reduce_sum(tf.cast(tf.math.logical_and(true_graph==1,\n",
    "                                                    pred_graph==0),dtype=tf.int32))\n",
    "    \n",
    "    return m11 / (m01 + m10 + m11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_trainexp2idx = tf.convert_to_tensor(trainexp2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[1405,  808]])>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(tf_trainexp2idx[0][tf_trainexp2idx[0][:,1] == 2],[0,2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int64, numpy=\n",
       "array([[2628, 2628],\n",
       "       [2628, 2628]])>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_subgraphs[0].indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = np.concatenate([train2idx[0][:,[1,0,2]],train2idx[0][:,[1,2,0]]],axis=0)\n",
    "\n",
    "#a = tf.sparse.expand_dims(a, axis=0)\n",
    "\n",
    "# a = tf.sparse.SparseTensor(indices=np.concatenate([np.zeros((train2idx.shape[1],1),dtype=np.int64),train2idx[0][:,[1,0,2]]], axis=1),\n",
    "#                           values=np.ones(train2idx.shape[1]),dense_shape=(1,NUM_RELATIONS,NUM_ENTITIES,NUM_ENTITIES))\n",
    "# a = tf.sparse.reorder(\n",
    "#     a\n",
    "# )\n",
    "\n",
    "#np.concatenate([np.zeros((train2idx.shape[1],1),dtype=np.int64),train2idx[0][:,[1,0,2]]],axis=1)\n",
    "#np.concatenate([np.zeros((train2idx.shape[1],1),dtype=np.int64),train2idx[0][:,[1,2,0]]],axis=1)\n",
    "\n",
    "\n",
    "#[0,4,823,4246]\n",
    "#0,4,1532,9141\n",
    "\n",
    "# np.argwhere(train2idx[0,:,0] == 1532)\n",
    "# triples[5313,:]\n",
    "\n",
    "#np.concatenate([train2idx[0,:,1].reshape(1,-1),train2idx[0,:,0].reshape(-1,1),train2idx[0,:,2].reshape(-1,1)],axis=1)\n",
    "#np.swapaxis(train2idx,)\n",
    "\n",
    "#tf.sparse.to_dense(a)\n",
    "\n",
    "#tf.nn.embedding_lookup_sparse(a, tf.convert_to_tensor([3,3]),sp_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.nn.embedding_lookup_sparse(a, train2idx[:,0:5,0],sp_weights=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(a_dense[8,15:20,:],tf.ones((14154,5),tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sparse.sparse_dense_matmul(a,tf.ones((14154,5),tf.float64))[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=[\n",
    "        all_indices,\n",
    "        train2idx[:,:,0],\n",
    "        train2idx[:,:,1],\n",
    "        train2idx[:,:,2],\n",
    "        adj_mats\n",
    "        ],\n",
    "    y=np.ones(NUM_TRIPLES).reshape(1,-1),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# bce = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# data = tf.data.Dataset.from_tensor_slices((\n",
    "#         train2idx[0,:,0],\n",
    "#         train2idx[0,:,1],\n",
    "#         train2idx[0,:,2], \n",
    "#         np.ones(train2idx.shape[1])\n",
    "#     )\n",
    "# ).batch(BATCH_SIZE)\n",
    "\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "#     for pos_head,rel,pos_tail,y in data:\n",
    "\n",
    "#         neg_head, neg_tail = utils.get_negative_triples(\n",
    "#             head=pos_head, \n",
    "#             rel=rel, \n",
    "#             tail=pos_tail,\n",
    "#             num_entities=NUM_ENTITIES\n",
    "#         )\n",
    "\n",
    "#         with tf.GradientTape() as tape:\n",
    "            \n",
    "# #             print(all_indices.shape)\n",
    "# #             print(pos_head.shape)\n",
    "# #             print(adj_mats.shape)\n",
    "\n",
    "#             y_pos_pred = model([\n",
    "#                 all_indices,\n",
    "#                 pos_head,\n",
    "#                 rel,\n",
    "#                 pos_tail,\n",
    "#                 adj_mats\n",
    "#                 ],\n",
    "#                 training=True\n",
    "#             )\n",
    "\n",
    "#             y_neg_pred = model([\n",
    "#                 all_indices,\n",
    "#                 neg_head,\n",
    "#                 rel,\n",
    "#                 neg_tail,\n",
    "#                 adj_mats\n",
    "#                 ],\n",
    "#                 training=True\n",
    "#             )\n",
    "\n",
    "#             y_pred = tf.concat([y_pos_pred,y_neg_pred],axis=0)\n",
    "#             y_true = tf.concat([y,tf.zeros_like(y)],axis=0)\n",
    "\n",
    "#             loss = bce(y_true,y_pred)\n",
    "\n",
    "#         grads = tape.gradient(loss, model.trainable_weights)\n",
    "#         optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "#     print(f'loss {loss} after epoch {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_indices.shape)\n",
    "print(train2idx[:,:,0].shape)\n",
    "print(train2idx[:,:,1].shape)\n",
    "print(train2idx[:,:,2].shape)\n",
    "print(adj_mats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = model.predict(\n",
    "    x=[\n",
    "        all_indices,\n",
    "        train2idx[:,:,0],\n",
    "        train2idx[:,:,1],\n",
    "        train2idx[:,:,2],\n",
    "        adj_mats\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.where(adj_mats[0,2,:][train2idx[:,0:1,0]]==1.)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model([\n",
    "    all_indices,\n",
    "    train2idx[:,0:1,0],\n",
    "    train2idx[:,0:1,1],\n",
    "    train2idx[:,0:1,2],\n",
    "    k_hop_adj_mats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = model.get_layer('entity_embeddings').get_weights()[0]\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,_,t = train2idx[0,0,:]\n",
    "\n",
    "k_hop_adj_mats = []\n",
    "\n",
    "for r in range(NUM_RELATIONS):\n",
    "\n",
    "    k_hop_adj_mat = np.zeros((NUM_ENTITIES,NUM_ENTITIES))\n",
    "\n",
    "    head_neighbors = tf.where(adj_mats[0,r,:][h]==1.)[:,-1]\n",
    "    tail_neighbors = tf.where(adj_mats[0,r,:][t]==1.)[:,-1]\n",
    "\n",
    "    for h_i in head_neighbors:\n",
    "        k_hop_adj_mat[h,h_i] = 1.\n",
    "        k_hop_adj_mat[h_i,h] = 1.\n",
    "        \n",
    "    for t_i in tail_neighbors:\n",
    "        k_hop_adj_mat[t,t_i] = 1.\n",
    "        k_hop_adj_mat[t_i,t] = 1.\n",
    "\n",
    "    k_hop_adj_mats.append(k_hop_adj_mat)\n",
    "\n",
    "k_hop_adj_mats = np.expand_dims(k_hop_adj_mats,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "\n",
    "tf_train2idx = tf.convert_to_tensor(train2idx)\n",
    "tf_k_hop_adj_mats = tf.convert_to_tensor(k_hop_adj_mats,dtype=tf.float32)\n",
    "tf_all_indices = tf.convert_to_tensor(all_indices)\n",
    "\n",
    "y_true = model([\n",
    "    all_indices,\n",
    "    train2idx[:,0:1,0],\n",
    "    train2idx[:,0:1,1],\n",
    "    train2idx[:,0:1,2],\n",
    "    k_hop_adj_mats])\n",
    "\n",
    "masks = tf.Variable(\n",
    "        initial_value=tf.random.normal(\n",
    "            (adj_mats.shape), \n",
    "            mean=0, \n",
    "            stddev=1, \n",
    "            dtype=tf.dtypes.float32, \n",
    "            seed=SEED),\n",
    "        name='mask',\n",
    "        trainable=True\n",
    "    )\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "with tf.GradientTape() as tape:\n",
    "    \n",
    "    #tape.watch(tf_train2idx)\n",
    "    #tape.watch(tf_k_hop_adj_mats)\n",
    "    tape.watch(masks)\n",
    "\n",
    "    \n",
    "    masked_adj = tf_k_hop_adj_mats*tf.nn.sigmoid(masks)\n",
    "    \n",
    "    y_pred = model([\n",
    "        tf_all_indices,\n",
    "        tf_train2idx[:,0:1,0],\n",
    "        tf_train2idx[:,0:1,1],\n",
    "        tf_train2idx[:,0:1,2],\n",
    "        masked_adj])\n",
    "\n",
    "    loss = bce(y_true,y_pred)\n",
    "    \n",
    "grads = tape.gradient(loss,masks)\n",
    "optimizer.apply_gradients(zip(grads,masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subgraph = tf.cast((tf_k_hop_adj_mats*tf.nn.sigmoid(masks)) > .5,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reduce_sum(tape.gradient(loss,tf_k_hop_adj_mats)[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp to subgraph function\n",
    "#list for jaccard scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainexp2idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraph = []\n",
    "\n",
    "for i in range(NUM_RELATIONS):\n",
    "    \n",
    "    mat = np.zeros((NUM_ENTITIES,NUM_ENTITIES))\n",
    "\n",
    "    exp_triples = trainexp2idx[0][trainexp2idx[0][:,1] == i]\n",
    "    \n",
    "    for exp_h,_,exp_t in exp_triples:\n",
    "        \n",
    "        mat[exp_h,exp_t] = 1\n",
    "        mat[exp_t,exp_h] = 1\n",
    "        \n",
    "    true_subgraph.append(mat)\n",
    "\n",
    "true_subgraph = np.expand_dims(true_subgraph,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_subgraph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_jaccard(truth,pred):\n",
    "    \n",
    "    m11 = np.logical_and(truth==1,pred==1).sum()\n",
    "    m01 = np.logical_and(truth==0,pred==1).sum()\n",
    "    m10 = np.logical_and(truth==1,pred==0).sum()\n",
    "    \n",
    "    return (m11 / (m01+m10+m11))\n",
    "\n",
    "binary_jaccard(truth,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth = np.array([[1,1,1],[1,0,0],[1,0,0]])\n",
    "# pred = np.array([[1,1,1],[1,0,0],[1,0,0]])\n",
    "\n",
    "# a = truth.sum()\n",
    "# b = pred.sum()\n",
    "# intersect = np.logical_and(truth, pred)\n",
    "# print(truth)\n",
    "# print(pred)\n",
    "# print(intersect)\n",
    "# print(intersect.sum()/(a+b-intersect.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail_triples = []\n",
    "# for i in tail_indices:\n",
    "#     tail_triples.append((h,r,i.numpy()[0]))\n",
    "    \n",
    "# tail_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class New_RGCN_Layer(tf.keras.layers.Layer):\n",
    "#     def __init__(self,num_relations,output_dim,**kwargs):\n",
    "#         super(New_RGCN_Layer,self).__init__(**kwargs)\n",
    "#         self.num_relations = num_relations\n",
    "#         self.output_dim = output_dim\n",
    "        \n",
    "#     def build(self,input_shape):\n",
    "\n",
    "#         input_dim = int(input_shape[-2][-1])\n",
    "        \n",
    "#         self.relation_kernel = self.add_weight(\n",
    "#             shape=(self.num_relations,input_dim, self.output_dim),\n",
    "#             name=\"relation_kernels\",\n",
    "#             trainable=True,\n",
    "#             initializer=tf.keras.initializers.RandomNormal(\n",
    "#                 mean=0.0,\n",
    "#                 stddev=1,\n",
    "#                 seed=SEED\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "\n",
    "#         self.self_kernel = self.add_weight(\n",
    "#             shape=(input_dim, self.output_dim),\n",
    "#             name=\"self_kernel\",\n",
    "#             trainable=True,\n",
    "#             initializer=tf.keras.initializers.RandomNormal(\n",
    "#                 mean=0.0,\n",
    "#                 stddev=1,\n",
    "#                 seed=SEED\n",
    "#             )\n",
    "#         )\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "        \n",
    "#         embeddings,head_idx,head_e,tail_idx,tail_e,adj_mats = inputs\n",
    "        \n",
    "# #         print('embeddings',embeddings.shape)\n",
    "# #         print('head_idx',head_idx.shape)\n",
    "# #         print('head_e',head_e.shape)\n",
    "# #         print('adj_mats',adj_mats.shape)\n",
    "            \n",
    "#         head_output = tf.matmul(head_e,self.self_kernel)\n",
    "#         tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "        \n",
    "#         #print('head_output',head_output.shape)\n",
    "        \n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             adj_i = adj_mats[i]\n",
    "\n",
    "#             #print('adj_i',adj_i.shape)\n",
    "            \n",
    "#             head_adj = tf.nn.embedding_lookup(adj_i,head_idx)\n",
    "#             tail_adj = tf.nn.embedding_lookup(adj_i,tail_idx)\n",
    "            \n",
    "#             #print('head_adj',head_adj.shape)\n",
    "            \n",
    "#             #print('head_adj',head_adj.shape)\n",
    "#             #print('embeddings',embeddings.shape)\n",
    "            \n",
    "#             head_update = tf.matmul(head_adj,embeddings)\n",
    "#             tail_update = tf.matmul(tail_adj,embeddings)\n",
    "\n",
    "#             head_output += tf.matmul(head_update,self.relation_kernel[i])\n",
    "#             tail_output += tf.matmul(tail_update,self.relation_kernel[i])\n",
    "       \n",
    "#         return head_output, tail_output\n",
    "    \n",
    "# class DistMult(tf.keras.layers.Layer):\n",
    "#     def __init__(self, num_relations,**kwargs):\n",
    "#         super(DistMult,self).__init__(**kwargs)\n",
    "#         self.num_relations = num_relations\n",
    "        \n",
    "#     def build(self,input_shape):\n",
    "        \n",
    "#         embedding_dim = input_shape[0][-1]\n",
    "        \n",
    "#         self.kernel = self.add_weight(\n",
    "#             shape=(self.num_relations,embedding_dim),\n",
    "#             trainable=True,\n",
    "#             initializer=tf.keras.initializers.RandomNormal(\n",
    "#                 mean=0.0,\n",
    "#                 stddev=1,\n",
    "#                 seed=SEED\n",
    "#             ),\n",
    "#             name='rel_embedding'\n",
    "#         )\n",
    "        \n",
    "#     def call(self,inputs):\n",
    "        \n",
    "#         head_e,rel_idx,tail_e = inputs\n",
    "        \n",
    "#         rel_e = tf.nn.embedding_lookup(self.kernel,rel_idx)\n",
    "        \n",
    "#         score = tf.sigmoid(tf.reduce_sum(head_e*rel_e*tail_e,axis=-1))\n",
    "        \n",
    "#         return tf.expand_dims(score,axis=0)\n",
    "#         embeddings,head_idx,tail_idx,head_e,tail_e,adj_mats = inputs\n",
    "\n",
    "#         adj_mats = tf.squeeze(adj_mats,axis=0)\n",
    "#         embeddings = tf.squeeze(embeddings,axis=0)\n",
    "\n",
    "#         head_output = tf.matmul(head_e,self.self_kernel)\n",
    "#         tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "        \n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             adj_i =x adj_mats[i]\n",
    "\n",
    "#             head_adj = tf.nn.embedding_lookup(adj_i,head_idx)\n",
    "#             tail_adj = tf.nn.embedding_lookup(adj_i,tail_idx)\n",
    "            \n",
    "#             h_head = tf.matmul(head_adj,embeddings)\n",
    "#             h_tail = tf.matmul(head_adj,embeddings)\n",
    "            \n",
    "#             head_output += tf.matmul(h_head,self.relation_kernel[i])\n",
    "#             tail_output += tf.matmul(h_tail,self.relation_kernel[i])\n",
    "\n",
    "#         return head_output,tail_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = tf.data.Dataset.from_tensor_slices((\n",
    "#         train2idx[:,:,0],\n",
    "#         train2idx[:,:,1],\n",
    "#         train2idx[:,:,2], \n",
    "#         np.ones(train2idx.shape[1]).reshape(1,-1)\n",
    "#     )\n",
    "# ).batch(1)\n",
    "\n",
    "# for h,r,t,y in data:\n",
    "\n",
    "#     neg_head, neg_tail = utils.get_negative_triples(head=h,rel=r,tail=t,num_entities=NUM_ENTITIES)\n",
    "#     print(h)\n",
    "#     print(neg_head)\n",
    "#     print(t) \n",
    "#     print(neg_tail)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_entities = tf.keras.Input(shape=(NUM_ENTITIES,), name='all_entities',dtype=tf.int64)\n",
    "# head_input = tf.keras.Input(shape=(None,), name='head_input',batch_size=1,dtype=tf.int64)\n",
    "# rel_input = tf.keras.Input(shape=(None,), name='rel_input',batch_size=1,dtype=tf.int64)\n",
    "# tail_input = tf.keras.Input(shape=(None,), name='tail_input',batch_size=1,dtype=tf.int64)\n",
    "\n",
    "# adj_inputs = tf.keras.Input(\n",
    "#         shape=(\n",
    "#             NUM_RELATIONS,\n",
    "#             NUM_ENTITIES,\n",
    "#             NUM_ENTITIES\n",
    "#         ),\n",
    "#         dtype=tf.float32,\n",
    "#         name='adj_inputs'\n",
    "#     )\n",
    "\n",
    "# entity_embeddings = Embedding(\n",
    "#         input_dim=NUM_ENTITIES,\n",
    "#         output_dim=EMBEDDING_DIM,\n",
    "#         name='entity_embeddings',\n",
    "#         embeddings_initializer=tf.keras.initializers.RandomUniform(\n",
    "#             minval=-1,\n",
    "#             maxval=1,\n",
    "#             seed=SEED\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# all_e = entity_embeddings(all_entities)\n",
    "# head_e = entity_embeddings(head_input)\n",
    "# tail_e = entity_embeddings(tail_input)\n",
    "\n",
    "# all_e = tf.keras.layers.Lambda(lambda x:x[0,:,:])(all_e)\n",
    "# head_e = tf.keras.layers.Lambda(lambda x:x[0,:,:])(head_e)\n",
    "# tail_e = tf.keras.layers.Lambda(lambda x:x[0,:,:])(tail_e)\n",
    "\n",
    "# head_index = tf.keras.layers.Lambda(lambda x:x[0,:])(head_input)\n",
    "# rel_index = tf.keras.layers.Lambda(lambda x:x[0,:])(rel_input)\n",
    "# tail_index = tf.keras.layers.Lambda(lambda x:x[0,:])(tail_input)\n",
    "\n",
    "# adj_mats_layer = tf.keras.layers.Lambda(lambda x:x[0,:,:])(adj_inputs)\n",
    "# #embeddings,head_idx,head_e,tail_idx,tail_e,adj_mats\n",
    "\n",
    "# new_head,new_tail = New_RGCN_Layer(NUM_RELATIONS,OUTPUT_DIM)([all_e,head_index,head_e,tail_index,tail_e,adj_mats_layer])\n",
    "# #new_head = New_RGCN_Layer(NUM_RELATIONS,OUTPUT_DIM)([all_entities,])\n",
    "\n",
    "# output = DistMult(num_relations=NUM_RELATIONS,name='output')([new_head,rel_index,new_tail])\n",
    "\n",
    "# output = tf.keras.layers.Dense(train2idx.shape[1],activation='sigmoid')(output)\n",
    "\n",
    "# #output = tf.keras.layers.Dense(1)(output)\n",
    "# #output = tf.keras.layers.Reshape((1,))(output)\n",
    "# # m = tf.keras.Model([head_input],[out])\n",
    "# # m([train2idx[:,0:32,0]])\n",
    "# m = tf.keras.Model([all_entities,head_input,rel_input,tail_input,adj_inputs],[output])\n",
    "\n",
    "# m([np.arange(NUM_ENTITIES).reshape(1,-1),train2idx[:,:,0],train2idx[:,:,1],train2idx[:,:,2],adj_mats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.compile(\n",
    "#     loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "#     optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# )\n",
    "\n",
    "# #m.summary()\n",
    "# m.fit(x=[\n",
    "#     all_indices,\n",
    "#     train2idx[:,:,0],\n",
    "#     train2idx[:,:,1],\n",
    "#     train2idx[:,:,2],\n",
    "#     adj_mats\n",
    "# ],\n",
    "#     y=np.ones(train2idx.shape[1]).reshape(1,-1),\n",
    "#     epochs=NUM_EPOCHS,\n",
    "#     batch_size=1,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = m.predict(\n",
    "#     x=[\n",
    "#         all_indices,\n",
    "#         train2idx[:,:,0],\n",
    "#         train2idx[:,:,1],\n",
    "#         train2idx[:,:,2],\n",
    "#         adj_mats\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m([all_indices,train2idx[:,0:1,0],train2idx[:,0:1,1],train2idx[:,0:1,2],masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_model = tf.keras.Model(inputs=m.input,outputs=m.get_layer('entity_embeddings').output)\n",
    "\n",
    "#embeddings = m.get_layer('entity_embeddings').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_embeddings,tail_embeddings = embeddings_model([\n",
    "#     all_indices,\n",
    "#     train2idx[:,0:1,0],\n",
    "#     train2idx[:,0:1,1],\n",
    "#     train2idx[:,0:1,2],\n",
    "#     adj_mats\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train2idx[0,:,:][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.where(adj_mats[0][2][100]==1.).numpy()\n",
    "#np.argwhere(train2idx[0,:,2]== 100)\n",
    "\n",
    "# for h,_,t in train2idx[:,822,:]:\n",
    "    \n",
    "#     head_neighbors = tf.where(adj_mats[0][2][h]==1.).numpy()\n",
    "#     tail_neighbors = tf.where(adj_mats[0][2][t]==1.).numpy()\n",
    "#tf.where(adj_mats[0][2][100]==1.).numpy()\n",
    "#tf.where(adj_mats[0,2,[100,100,100]]==1.)[:,-1]\n",
    "#train2idx[:,822,[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.nn.embedding_lookup(embeddings,train2idx[0,0:1,0])\n",
    "#k_hop_adj_mats*tf.nn.sigmoid(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for triple in test set:\n",
    "    #get k hop subgraph of each triple (all neighbors of head/tail)\n",
    "    #compute adjacency matrix of subgraph (1,NUM_RELATIONS,NUM_ENTITIES,NUM_ENTITIES)\n",
    "    #compute pred of triple\n",
    "    #for i in iter:\n",
    "        #learn mask\n",
    "        #mask * adj matrix \n",
    "    #mask * adj matrix-> reduce output to ints\n",
    "#edge_mask = tf.cast((k_hop_adj_mats*tf.nn.sigmoid(masks)) > .1,dtype=tf.int32)\n",
    "#tf.nn.sigmoid(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head_indices = tf.where(edge_mask[0,2,h,:] == 1)\n",
    "# tail_indices = tf.where(edge_mask[0,2,t,:] == 1)\n",
    "# swap = tf.concat([tf.reshape(indices[:,1],(-1,1)),tf.reshape(indices[:,0],(-1,1))],axis=1)\n",
    "\n",
    "# unique_indices = tf.concat([indices,swap],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
