{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "data = np.load(os.path.join('..','data','royalty.npz'))\n",
    "\n",
    "entities = data['entities'].tolist()\n",
    "relations = data['relations'].tolist()\n",
    "\n",
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "EMBEDDING_DIM = 30\n",
    "OUTPUT_DIM = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "triples, traces = data['grandmother_triples'], data['grandmother_traces']\n",
    "\n",
    "train2idx = utils.array2idx(triples, ent2idx,rel2idx)\n",
    "\n",
    "adj_mats = utils.get_adjacency_matrix_list(\n",
    "    num_relations=NUM_RELATIONS,\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    data=train2idx\n",
    ")\n",
    "\n",
    "train2idx = np.expand_dims(train2idx,axis=0)\n",
    "\n",
    "all_indices = np.arange(NUM_ENTITIES).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_relations,output_dim,**kwargs):\n",
    "        super(RGCN_Layer,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "\n",
    "        input_dim = int(input_shape[-2][-1])\n",
    "        \n",
    "        self.relation_kernel = self.add_weight(\n",
    "            shape=(self.num_relations,input_dim, self.output_dim),\n",
    "            name=\"relation_kernels\",\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.self_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.output_dim),\n",
    "            name=\"self_kernel\",\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        embeddings,head_idx,head_e,tail_idx,tail_e,adj_mats = inputs\n",
    "            \n",
    "        head_output = tf.matmul(head_e,self.self_kernel)\n",
    "        tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "                \n",
    "        for i in range(self.num_relations):\n",
    "            \n",
    "            adj_i = adj_mats[i]\n",
    "            \n",
    "            head_adj = tf.nn.embedding_lookup(adj_i,head_idx)\n",
    "            tail_adj = tf.nn.embedding_lookup(adj_i,tail_idx)\n",
    "            \n",
    "            head_update = tf.matmul(head_adj,embeddings)\n",
    "            tail_update = tf.matmul(tail_adj,embeddings)\n",
    "\n",
    "            head_output += tf.matmul(head_update,self.relation_kernel[i])\n",
    "            tail_output += tf.matmul(tail_update,self.relation_kernel[i])\n",
    "       \n",
    "        return head_output, tail_output\n",
    "\n",
    "class DistMult(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_relations,**kwargs):\n",
    "        super(DistMult,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        embedding_dim = input_shape[0][-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.num_relations,embedding_dim),\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            ),\n",
    "            name='rel_embedding'\n",
    "        )\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        head_e,rel_idx,tail_e = inputs\n",
    "        \n",
    "        rel_e = tf.nn.embedding_lookup(self.kernel,rel_idx)\n",
    "        \n",
    "        score = tf.sigmoid(tf.reduce_sum(head_e*rel_e*tail_e,axis=-1))\n",
    "\n",
    "        return tf.expand_dims(score,axis=0)\n",
    "\n",
    "class RGCN_Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,num_entities,*args,**kwargs):\n",
    "        super(RGCN_Model,self).__init__(*args, **kwargs)\n",
    "        self.num_entities = num_entities\n",
    "\n",
    "    def train_step(self,data):\n",
    "\n",
    "        all_indices,pos_head,rel,pos_tail,adj_mats = data[0]\n",
    "        y = data[1]\n",
    "\n",
    "        neg_head, neg_tail = utils.get_negative_triples(\n",
    "                head=pos_head, \n",
    "                rel=rel, \n",
    "                tail=pos_tail,\n",
    "                num_entities=self.num_entities\n",
    "            )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            y_pos_pred = self([\n",
    "                    all_indices,\n",
    "                    pos_head,\n",
    "                    rel,\n",
    "                    pos_tail,\n",
    "                    adj_mats\n",
    "                    ],\n",
    "                    training=True\n",
    "                )\n",
    "            \n",
    "            y_neg_pred = self([\n",
    "                    all_indices,\n",
    "                    neg_head,\n",
    "                    rel,\n",
    "                    neg_tail,\n",
    "                    adj_mats\n",
    "                    ],\n",
    "                    training=True\n",
    "                )\n",
    "\n",
    "            y_pred = tf.concat([y_pos_pred,y_neg_pred],axis=1)\n",
    "            y_true = tf.concat([y,tf.zeros_like(y)],axis=1)\n",
    "            \n",
    "            loss = self.compiled_loss(y_true,y_pred)\n",
    "\n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        self.compiled_metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x19510db590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RGCN_Layer.call of <__main__.RGCN_Layer object at 0x19510db590>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "head_output (None, None, 50)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x19512ffc90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method DistMult.call of <__main__.DistMult object at 0x19512ffc90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Tensor(\"output/Sigmoid_4:0\", shape=(None, None), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The last dimension of the inputs to `Dense` should be defined. Found `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7079857878db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-30-31c3d5564e57>\u001b[0m in \u001b[0;36mget_RGCN_Model\u001b[0;34m(num_entities, num_relations, embedding_dim, output_dim, seed)\u001b[0m\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     model = tf.keras.Model(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m       raise ValueError('The last dimension of the inputs to `Dense` '\n\u001b[0m\u001b[1;32m   1169\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1170\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The last dimension of the inputs to `Dense` should be defined. Found `None`."
     ]
    }
   ],
   "source": [
    "# model = get_RGCN_Model(\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     embedding_dim=EMBEDDING_DIM,\n",
    "#     output_dim=OUTPUT_DIM,\n",
    "#     seed=SEED\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((\n",
    "        train2idx[0,:,0],\n",
    "        train2idx[0,:,1],\n",
    "        train2idx[0,:,2], \n",
    "        np.ones(train2idx.shape[1])\n",
    "    )\n",
    ").batch(BATCH_SIZE)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    for pos_head,rel,pos_tail,y in data:\n",
    "\n",
    "        neg_head, neg_tail = utils.get_negative_triples(\n",
    "            head=pos_head, \n",
    "            rel=rel, \n",
    "            tail=pos_tail,\n",
    "            num_entities=NUM_ENTITIES\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "#             print(all_indices.shape)\n",
    "#             print(pos_head.shape)\n",
    "#             print(adj_mats.shape)\n",
    "\n",
    "            y_pos_pred = model([\n",
    "                all_indices,\n",
    "                pos_head,\n",
    "                rel,\n",
    "                pos_tail,\n",
    "                adj_mats\n",
    "                ],\n",
    "                training=True\n",
    "            )\n",
    "\n",
    "            y_neg_pred = model([\n",
    "                all_indices,\n",
    "                neg_head,\n",
    "                rel,\n",
    "                neg_tail,\n",
    "                adj_mats\n",
    "                ],\n",
    "                training=True\n",
    "            )\n",
    "\n",
    "            y_pred = tf.concat([y_pos_pred,y_neg_pred],axis=0)\n",
    "            y_true = tf.concat([y,tf.zeros_like(y)],axis=0)\n",
    "\n",
    "            loss = bce(y_true,y_pred)\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    print(f'loss {loss} after epoch {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_indices.shape)\n",
    "print(train2idx[:,:,0].shape)\n",
    "print(train2idx[:,:,1].shape)\n",
    "print(train2idx[:,:,2].shape)\n",
    "print(adj_mats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(\n",
    "    x=[\n",
    "        all_indices,\n",
    "        train2idx[:,:,0],\n",
    "        train2idx[:,:,1],\n",
    "        train2idx[:,:,2],\n",
    "        adj_mats\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_RGCN_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_relations,output_dim,**kwargs):\n",
    "        super(New_RGCN_Layer,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "\n",
    "        input_dim = int(input_shape[-2][-1])\n",
    "        \n",
    "        self.relation_kernel = self.add_weight(\n",
    "            shape=(self.num_relations,input_dim, self.output_dim),\n",
    "            name=\"relation_kernels\",\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        self.self_kernel = self.add_weight(\n",
    "            shape=(input_dim, self.output_dim),\n",
    "            name=\"self_kernel\",\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        embeddings,head_idx,head_e,tail_idx,tail_e,adj_mats = inputs\n",
    "        \n",
    "#         print('embeddings',embeddings.shape)\n",
    "#         print('head_idx',head_idx.shape)\n",
    "#         print('head_e',head_e.shape)\n",
    "#         print('adj_mats',adj_mats.shape)\n",
    "            \n",
    "        head_output = tf.matmul(head_e,self.self_kernel)\n",
    "        tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "        \n",
    "        #print('head_output',head_output.shape)\n",
    "        \n",
    "        for i in range(self.num_relations):\n",
    "            \n",
    "            adj_i = adj_mats[i]\n",
    "\n",
    "            #print('adj_i',adj_i.shape)\n",
    "            \n",
    "            head_adj = tf.nn.embedding_lookup(adj_i,head_idx)\n",
    "            tail_adj = tf.nn.embedding_lookup(adj_i,tail_idx)\n",
    "            \n",
    "            #print('head_adj',head_adj.shape)\n",
    "            \n",
    "            #print('head_adj',head_adj.shape)\n",
    "            #print('embeddings',embeddings.shape)\n",
    "            \n",
    "            head_update = tf.matmul(head_adj,embeddings)\n",
    "            tail_update = tf.matmul(tail_adj,embeddings)\n",
    "\n",
    "            head_output += tf.matmul(head_update,self.relation_kernel[i])\n",
    "            tail_output += tf.matmul(tail_update,self.relation_kernel[i])\n",
    "       \n",
    "        return head_output, tail_output\n",
    "    \n",
    "class DistMult(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_relations,**kwargs):\n",
    "        super(DistMult,self).__init__(**kwargs)\n",
    "        self.num_relations = num_relations\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        embedding_dim = input_shape[0][-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(self.num_relations,embedding_dim),\n",
    "            trainable=True,\n",
    "            initializer=tf.keras.initializers.RandomNormal(\n",
    "                mean=0.0,\n",
    "                stddev=1,\n",
    "                seed=SEED\n",
    "            ),\n",
    "            name='rel_embedding'\n",
    "        )\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        \n",
    "        head_e,rel_idx,tail_e = inputs\n",
    "        \n",
    "        rel_e = tf.nn.embedding_lookup(self.kernel,rel_idx)\n",
    "        \n",
    "        score = tf.sigmoid(tf.reduce_sum(head_e*rel_e*tail_e,axis=-1))\n",
    "        \n",
    "        return tf.expand_dims(score,axis=0)\n",
    "#         embeddings,head_idx,tail_idx,head_e,tail_e,adj_mats = inputs\n",
    "\n",
    "#         adj_mats = tf.squeeze(adj_mats,axis=0)\n",
    "#         embeddings = tf.squeeze(embeddings,axis=0)\n",
    "\n",
    "#         head_output = tf.matmul(head_e,self.self_kernel)\n",
    "#         tail_output = tf.matmul(tail_e,self.self_kernel)\n",
    "        \n",
    "#         for i in range(self.num_relations):\n",
    "            \n",
    "#             adj_i = adj_mats[i]\n",
    "\n",
    "#             head_adj = tf.nn.embedding_lookup(adj_i,head_idx)\n",
    "#             tail_adj = tf.nn.embedding_lookup(adj_i,tail_idx)\n",
    "            \n",
    "#             h_head = tf.matmul(head_adj,embeddings)\n",
    "#             h_tail = tf.matmul(head_adj,embeddings)\n",
    "            \n",
    "#             head_output += tf.matmul(h_head,self.relation_kernel[i])\n",
    "#             tail_output += tf.matmul(h_tail,self.relation_kernel[i])\n",
    "\n",
    "#         return head_output,tail_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 583 5732  781 ... 1063 2747  816]], shape=(1, 4024), dtype=int64)\n",
      "tf.Tensor([[ 583 4636 4799 ... 2880 2843 5142]], shape=(1, 4024), dtype=int64)\n",
      "tf.Tensor([[5001 5368 3454 ... 1060  705  876]], shape=(1, 4024), dtype=int64)\n",
      "tf.Tensor([[1137 5368 3454 ... 1060  705  876]], shape=(1, 4024), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((\n",
    "        train2idx[:,:,0],\n",
    "        train2idx[:,:,1],\n",
    "        train2idx[:,:,2], \n",
    "        np.ones(train2idx.shape[1]).reshape(1,-1)\n",
    "    )\n",
    ").batch(1)\n",
    "\n",
    "for h,r,t,y in data:\n",
    "\n",
    "    neg_head, neg_tail = utils.get_negative_triples(head=h,rel=r,tail=t,num_entities=NUM_ENTITIES)\n",
    "    print(h)\n",
    "    print(neg_head)\n",
    "    print(t) \n",
    "    print(neg_tail)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The last dimension of the inputs to `Dense` should be defined. Found `None`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-dc2f3929379a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistMult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_relations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_RELATIONS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrel_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_tail\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain2idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#output = tf.keras.layers.Dense(1)(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m       raise ValueError('The last dimension of the inputs to `Dense` '\n\u001b[0m\u001b[1;32m   1169\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1170\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The last dimension of the inputs to `Dense` should be defined. Found `None`."
     ]
    }
   ],
   "source": [
    "all_entities = tf.keras.Input(shape=(NUM_ENTITIES,), name='all_entities',dtype=tf.int64)\n",
    "head_input = tf.keras.Input(shape=(None,), name='head_input',batch_size=1,dtype=tf.int64)\n",
    "rel_input = tf.keras.Input(shape=(None,), name='rel_input',batch_size=1,dtype=tf.int64)\n",
    "tail_input = tf.keras.Input(shape=(None,), name='tail_input',batch_size=1,dtype=tf.int64)\n",
    "\n",
    "adj_inputs = tf.keras.Input(\n",
    "        shape=(\n",
    "            NUM_RELATIONS,\n",
    "            NUM_ENTITIES,\n",
    "            NUM_ENTITIES\n",
    "        ),\n",
    "        dtype=tf.float32,\n",
    "        name='adj_inputs'\n",
    "    )\n",
    "\n",
    "entity_embeddings = Embedding(\n",
    "        input_dim=NUM_ENTITIES,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        name='entity_embeddings',\n",
    "        embeddings_initializer=tf.keras.initializers.RandomUniform(\n",
    "            minval=-1,\n",
    "            maxval=1,\n",
    "            seed=SEED\n",
    "        )\n",
    "    )\n",
    "\n",
    "all_e = entity_embeddings(all_entities)\n",
    "head_e = entity_embeddings(head_input)\n",
    "tail_e = entity_embeddings(tail_input)\n",
    "\n",
    "all_e = tf.keras.layers.Lambda(lambda x:x[0,:,:])(all_e)\n",
    "head_e = tf.keras.layers.Lambda(lambda x:x[0,:,:])(head_e)\n",
    "tail_e = tf.keras.layers.Lambda(lambda x:x[0,:,:])(tail_e)\n",
    "\n",
    "head_index = tf.keras.layers.Lambda(lambda x:x[0,:])(head_input)\n",
    "rel_index = tf.keras.layers.Lambda(lambda x:x[0,:])(rel_input)\n",
    "tail_index = tf.keras.layers.Lambda(lambda x:x[0,:])(tail_input)\n",
    "\n",
    "adj_mats_layer = tf.keras.layers.Lambda(lambda x:x[0,:,:])(adj_inputs)\n",
    "#embeddings,head_idx,head_e,tail_idx,tail_e,adj_mats\n",
    "\n",
    "new_head,new_tail = New_RGCN_Layer(NUM_RELATIONS,OUTPUT_DIM)([all_e,head_index,head_e,tail_index,tail_e,adj_mats_layer])\n",
    "#new_head = New_RGCN_Layer(NUM_RELATIONS,OUTPUT_DIM)([all_entities,])\n",
    "\n",
    "output = DistMult(num_relations=NUM_RELATIONS,name='output')([new_head,rel_index,new_tail])\n",
    "\n",
    "output = tf.keras.layers.Dense(train2idx.shape[1],activation='sigmoid')(output)\n",
    "\n",
    "#output = tf.keras.layers.Dense(1)(output)\n",
    "#output = tf.keras.layers.Reshape((1,))(output)\n",
    "# m = tf.keras.Model([head_input],[out])\n",
    "# m([train2idx[:,0:32,0]])\n",
    "m = tf.keras.Model([all_entities,head_input,rel_input,tail_input,adj_inputs],[output])\n",
    "\n",
    "m([np.arange(NUM_ENTITIES).reshape(1,-1),train2idx[:,:,0],train2idx[:,:,1],train2idx[:,:,2],adj_mats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x194b576f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x194b576f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x194b57e810>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    ")\n",
    "\n",
    "#m.summary()\n",
    "m.fit(x=[\n",
    "    all_indices,\n",
    "    train2idx[:,:,0],\n",
    "    train2idx[:,:,1],\n",
    "    train2idx[:,:,2],\n",
    "    adj_mats\n",
    "],\n",
    "    y=np.ones(train2idx.shape[1]).reshape(1,-1),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x194b628cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x194b628cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "preds = m.predict(\n",
    "    x=[\n",
    "        all_indices,\n",
    "        train2idx[:,:,0],\n",
    "        train2idx[:,:,1],\n",
    "        train2idx[:,:,2],\n",
    "        adj_mats\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 5983, 5983)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_mats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = tf.Variable(\n",
    "    initial_value=tf.random.uniform(\n",
    "        (adj_mats.shape), \n",
    "        minval=0, \n",
    "        maxval=1, \n",
    "        dtype=tf.dtypes.float32, \n",
    "        seed=SEED),\n",
    "    name='mask'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4024), dtype=float32, numpy=array([[1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m([all_indices,train2idx[:,:,0],train2idx[:,:,1],train2idx[:,:,2],masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 583,    2, 5001]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2idx[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
