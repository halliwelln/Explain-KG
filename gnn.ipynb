{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def load_data(path=\"/Users/nhalliwe/Desktop/keras-gcn-master/kegra/data/cora/\", dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset), dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])\n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset), dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    print('Dataset has {} nodes, {} edges, {} features.'.format(adj.shape[0], edges.shape[0], features.shape[1]))\n",
    "\n",
    "    return features.todense(), adj, labels\n",
    "\n",
    "\n",
    "def normalize_adj(adj, symmetric=True):\n",
    "    if symmetric:\n",
    "        d = sp.diags(np.power(np.array(adj.sum(1)), -0.5).flatten(), 0)\n",
    "        a_norm = adj.dot(d).transpose().dot(d).tocsr()\n",
    "    else:\n",
    "        d = sp.diags(np.power(np.array(adj.sum(1)), -1).flatten(), 0)\n",
    "        a_norm = d.dot(adj).tocsr()\n",
    "    return a_norm\n",
    "\n",
    "\n",
    "def preprocess_adj(adj, symmetric=True):\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    adj = normalize_adj(adj, symmetric)\n",
    "    return adj\n",
    "\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "\n",
    "def get_splits(y):\n",
    "    idx_train = range(140)\n",
    "    idx_val = range(200, 500)\n",
    "    idx_test = range(500, 1500)\n",
    "    y_train = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_val = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_test = np.zeros(y.shape, dtype=np.int32)\n",
    "    y_train[idx_train] = y[idx_train]\n",
    "    y_val[idx_val] = y[idx_val]\n",
    "    y_test[idx_test] = y[idx_test]\n",
    "    train_mask = sample_mask(idx_train, y.shape[0])\n",
    "    return y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask\n",
    "X, A, y = load_data(dataset='cora')\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('.','data','royalty.npz'))\n",
    "\n",
    "triples = data['triples']\n",
    "traces = data['traces']\n",
    "entities = data['entities'].tolist()\n",
    "num_entities = len(entities)\n",
    "relations = data['relations'].tolist()\n",
    "num_relations = len(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_triples = triples.shape[0]\n",
    "train_idx, test_idx = train_test_split(range(num_triples),random_state=SEED,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = np.zeros(num_triples,dtype=bool)\n",
    "train_mask[train_idx] = 1\n",
    "\n",
    "test_mask = np.zeros(num_triples,dtype=bool)\n",
    "test_mask[test_idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "self_loop = [[i,i] for i in range(num_entities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h,_,t in triples:\n",
    "    h_idx = entities.index(h)\n",
    "    t_idx = entities.index(t)\n",
    "    indices.append([h_idx,t_idx])\n",
    "\n",
    "indices += self_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.unique(indices,axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.ones(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_hat_sparse = tf.sparse.SparseTensor(indices,values,dense_shape=[num_entities,num_entities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = tf.sparse.reduce_sum(A_hat_sparse,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_hat = tf.sparse.SparseTensor(self_loop,diag,dense_shape=[num_entities,num_entities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.random.rand(num_entities,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9186,)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y = np.array([relations.index(i) for i in triples[:,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y[train_mask],num_classes=num_relations)\n",
    "y_test = tf.keras.utils.to_categorical(y[test_mask],num_classes=num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import karate_club_graph, to_numpy_matrix\n",
    "zkc = karate_club_graph()\n",
    "order = sorted(list(zkc.nodes()))\n",
    "A = to_numpy_matrix(zkc, nodelist=order)\n",
    "I = np.eye(zkc.number_of_nodes())\n",
    "A_hat = A + I\n",
    "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
    "#D_hat = np.matrix(np.diag(D_hat))**-1\n",
    "D_hat = np.linalg.inv(np.diag(D_hat))\n",
    "\n",
    "#degree_indices = [[i,i] for i in range(zkc.number_of_nodes())]\n",
    "#D_hat_sparse = tf.sparse.SparseTensor(degree_indices,values=D_hat,dense_shape=[34,34])\n",
    "D_indices = []\n",
    "D_values = []\n",
    "for i in range(len(D_hat)):\n",
    "    \n",
    "    for j in range(len(D_hat)):\n",
    "        \n",
    "        if D_hat[i,j] != 0:\n",
    "            \n",
    "            D_indices.append([i,j])\n",
    "            D_values.append(np.sqrt(D_hat[i,j]))\n",
    "\n",
    "D_hat_inv_sparse = tf.sparse.SparseTensor(D_indices,values=D_values,dense_shape=[34,34])      \n",
    "# W_1 = np.random.normal(\n",
    "#     loc=0, scale=1, size=(zkc.number_of_nodes(), 4))\n",
    "# W_2 = np.random.normal(\n",
    "#     loc=0, size=(W_1.shape[1], 2))\n",
    "\n",
    "# def gcn_layer(A_hat, D_hat, X, W):\n",
    "#     return D_hat**-1 * A_hat * X * W\n",
    "# H_1 = gcn_layer(A_hat, D_hat, I, W_1)\n",
    "# H_2 = gcn_layer(A_hat, D_hat, H_1, W_2)\n",
    "# output = H_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.sparse import csr_matrix\n",
    "\n",
    "# A_hat = csr_matrix(np.array(A_hat))\n",
    "# I = csr_matrix(np.array(I))\n",
    "# D_hat = csr_matrix(np.array(D_hat))\n",
    "X_indices = []\n",
    "X_values = []\n",
    "for i in range(len(I)):\n",
    "    \n",
    "    for j in range(len(I)):\n",
    "        \n",
    "        if I[i,j] != 0:\n",
    "            \n",
    "            X_indices.append([i,j])\n",
    "            X_values.append(I[i,j])\n",
    "            \n",
    "X_sparse = tf.sparse.SparseTensor(X_indices,values=X_values,dense_shape=[34,34])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_indices = []\n",
    "for i in range(len(A_hat)):\n",
    "    \n",
    "    for j in range(len(A_hat)):\n",
    "        \n",
    "        if A_hat[i,j] == 1.:\n",
    "            \n",
    "            adj_indices.append([i,j])\n",
    "            \n",
    "#indices = tf.cast(tf.convert_to_tensor(indices),dtype=tf.int64)\n",
    "#values = tf.cast(tf.convert_to_tensor(np.ones(len(indices))),dtype=tf.int64)\n",
    "A_hat_sparse = tf.sparse.SparseTensor(adj_indices,np.ones(len(adj_indices)), dense_shape=[34,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = tf.cast(tf.convert_to_tensor(indices),dtype=tf.int64)\n",
    "# values = tf.cast(tf.convert_to_tensor(np.ones(len(indices))),dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.matmul(np.randn(A_hat.shape))\n",
    "#tf.matmul(A_hat,A_hat,a_is_sparse=True,b_is_sparse=True)\n",
    "\n",
    "#tf.matmul(a_sparse,a_sparse,a_is_sparse=True,b_is_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.layers.Layer):\n",
    "    def __init__(self,units,**kwargs):\n",
    "        super(GCN,self).__init__(**kwargs)\n",
    "        self.units=units\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1][-1],self.units),\n",
    "            trainable=True,\n",
    "            name='kernel',\n",
    "            initializer=tf.keras.initializers.RandomNormal(seed=SEED)\n",
    "        )\n",
    "\n",
    "    def call(self,inputs):\n",
    "\n",
    "        D_hat_inv,A_hat,H = inputs\n",
    "        \n",
    "        #DHW = tf.matmul(D_hat_inv,tf.matmul(H,self.kernel))\n",
    "        #output = tf.matmul(D_hat_inv,tf.matmul(A_hat,DHW))\n",
    "\n",
    "        DHW = tf.keras.backend.dot(D_hat_inv,tf.keras.backend.dot(H,self.kernel))\n",
    "        output = tf.keras.backend.dot(D_hat_inv,tf.keras.backend.dot(A_hat,DHW))\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(GCN, self).get_config()\n",
    "        config = {'units': self.units}\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k hop subgraph -> Adjacency matrix of k neighbors? Features for k neighbors\n",
    "#define masks (2 vectors, 1 for each node, feature mask?)\n",
    "#feed masked data into model to compute predictions: subgraph preds vs masked subgraph preds\n",
    "\n",
    "#why return node and edge feature mask?\n",
    "\n",
    "#a = tf.keras.layers.ReLU()(GCN(4)([D_hat**-1,A_hat,I])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ef5f610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FEATURES = I.shape[0]\n",
    "feature_input = tf.keras.layers.Input(shape=(5,),sparse=False,name='feature_input')\n",
    "adjacency_input = tf.keras.layers.Input(shape=(NUM_FEATURES,),sparse=True,name='adjacency_input')\n",
    "degree_input = tf.keras.layers.Input(shape=(NUM_FEATURES,),sparse=True,name='degree_input')\n",
    "\n",
    "# feature_mask = tf.keras.layers.Masking(mask_value=-1,name='feature_mask')(feature_input)\n",
    "# adjacency_mask = tf.keras.layers.Masking(mask_value=-1,name='adjacency_mask')(adjacency_input)\n",
    "# degree_mask = tf.keras.layers.Masking(mask_value=-1,name='degree_mask')(degree_input)\n",
    "\n",
    "gcn_ = GCN(4,name='gcn')([degree_input,adjacency_input,feature_input])\n",
    "a2 = tf.keras.layers.Activation('sigmoid')(gcn_)\n",
    "model = tf.keras.Model(inputs=[degree_input,adjacency_input,feature_input], outputs=a2)\n",
    "\n",
    "model.compile(optimizer='sgd',loss='categorical_crossentropy')\n",
    "\n",
    "#model.fit(x=[D_hat,A_hat,I],y=tf.keras.utils.to_categorical(np.ones(34),4),batch_size=34)\n",
    "model.fit(x=[D_hat_inv_sparse,A_hat_sparse,X],y=tf.keras.utils.to_categorical(np.ones(34),4),\n",
    "          batch_size=34,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = np.array([\n",
    "        \n",
    "#             [0, 1, 2],\n",
    "#             [2, 3, 4],\n",
    "#             [4, 5, 6],\n",
    "#             [7, 7, 8],\n",
    "        \n",
    "#     ], dtype=K.floatx())\n",
    "# input_edge = np.array([\n",
    "        \n",
    "#             [1, 1, 1, 0],\n",
    "#             [1, 1, 0, 0],\n",
    "#             [1, 0, 1, 0],\n",
    "#             [0, 0, 0, 1],\n",
    "        \n",
    "#     ], dtype='int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros(A_hat.shape[0])\n",
    "mask[0] = 1\n",
    "mask[1] = 1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(27, 2), dtype=int64, numpy=\n",
       "array([[ 0,  0],\n",
       "       [ 0,  1],\n",
       "       [ 0,  2],\n",
       "       [ 0,  3],\n",
       "       [ 0,  4],\n",
       "       [ 0,  5],\n",
       "       [ 0,  6],\n",
       "       [ 0,  7],\n",
       "       [ 0,  8],\n",
       "       [ 0, 10],\n",
       "       [ 0, 11],\n",
       "       [ 0, 12],\n",
       "       [ 0, 13],\n",
       "       [ 0, 17],\n",
       "       [ 0, 19],\n",
       "       [ 0, 21],\n",
       "       [ 0, 31],\n",
       "       [ 1,  0],\n",
       "       [ 1,  1],\n",
       "       [ 1,  2],\n",
       "       [ 1,  3],\n",
       "       [ 1,  7],\n",
       "       [ 1, 13],\n",
       "       [ 1, 17],\n",
       "       [ 1, 19],\n",
       "       [ 1, 21],\n",
       "       [ 1, 30]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.boolean_mask(A_hat_sparse,mask)\n",
    "def boolean_mask_sparse_1d(sparse_tensor, mask, axis=0):  # mask is assumed to be 1D\n",
    "    mask = tf.convert_to_tensor(mask)\n",
    "    ind = sparse_tensor.indices[:, axis]\n",
    "    mask_sp = tf.gather(mask, ind)\n",
    "    new_size = tf.math.count_nonzero(mask)\n",
    "    new_shape = tf.concat([sparse_tensor.shape[:axis], [new_size],\n",
    "                           sparse_tensor.shape[axis + 1:]], axis=0)\n",
    "    new_shape = tf.dtypes.cast(new_shape, tf.int64)\n",
    "    mask_count = tf.cumsum(tf.dtypes.cast(mask, tf.int64), exclusive=True)\n",
    "    masked_idx = tf.boolean_mask(sparse_tensor.indices, mask_sp)\n",
    "    new_idx_axis = tf.gather(mask_count, masked_idx[:, axis])\n",
    "    new_idx = tf.concat([masked_idx[:, :axis],\n",
    "                         tf.expand_dims(new_idx_axis, 1),\n",
    "                         masked_idx[:, axis + 1:]], axis=1)\n",
    "    new_values = tf.boolean_mask(sparse_tensor.values, mask_sp)\n",
    "    return tf.SparseTensor(new_idx, new_values, new_shape)\n",
    "\n",
    "boolean_mask_sparse_1d(A_hat_sparse,mask).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sparse_matrix(sparse_matrix,mask):\n",
    "    \n",
    "    mask = tf.convert_to_tensor(mask)\n",
    "    ind = sparse_matrix.indices[:, 0]\n",
    "    new_size = tf.math.count_nonzero(mask)\n",
    "    mask_sp = tf.gather(mask, ind)\n",
    "\n",
    "    new_shape = tf.convert_to_tensor((tf.math.count_nonzero(mask),sparse_matrix.shape[0]))\n",
    "    new_idx = tf.boolean_mask(sparse_matrix.indices, mask_sp)\n",
    "\n",
    "    new_values = tf.boolean_mask(sparse_matrix.values, mask_sp)\n",
    "    \n",
    "    return tf.SparseTensor(new_idx, new_values, new_shape)\n",
    "\n",
    "#convert index data to mask!!!!!\n",
    "#create train test data, must be same size: train graph only has training data, test graph has all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 34), dtype=float64, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0.]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(mask_sparse_matrix(A_hat_sparse,mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
