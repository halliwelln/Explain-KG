{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GNNExplainer\n",
    "from torch.nn import Sequential, Linear\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12104d850>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, GNNExplainer\n",
    "\n",
    "dataset = 'Cora'\n",
    "#path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Planetoid')\n",
    "dataset = Planetoid('/Users/nhalliwe/Desktop/pytorch_geometric-master/data/Planetoid', dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    log_logits = model(x, edge_index)\n",
    "    loss = F.nll_loss(log_logits[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=200)\n",
    "node_idx = 10\n",
    "node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)\n",
    "ax, G = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=data.y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "npdata = np.load(os.path.join('.','data','royalty_spouse.npz'))\n",
    "\n",
    "train = npdata['X_train']\n",
    "test = npdata['X_test']\n",
    "\n",
    "train_exp = npdata['train_exp']\n",
    "test_exp = npdata['test_exp']\n",
    "\n",
    "full_train = np.concatenate((train,train_exp.reshape(-1,3)), axis=0)\n",
    "\n",
    "entities = npdata['entities'].tolist()\n",
    "relations = npdata['relations'].tolist()\n",
    "\n",
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "# train2idx = utils.array2idx(full_train,ent2idx,rel2idx)\n",
    "# test2idx = utils.array2idx(test,ent2idx,rel2idx)\n",
    "\n",
    "testexp2idx = utils.array2idx(test_exp,ent2idx,rel2idx)\n",
    "\n",
    "# #entity_embeddings = np.load(os.path.join('.','data','transE_embeddings.npz'))['entity_embeddings']\n",
    "# entity_embeddings = np.random.randn(NUM_ENTITIES,50)\n",
    "\n",
    "# train2idx_ = np.concatenate([train2idx[:,0].reshape(-1,1),train2idx[:,2].reshape(-1,1)], axis=1)\n",
    "# test2idx_ = np.concatenate([test2idx[:,0].reshape(-1,1),test2idx[:,2].reshape(-1,1)], axis=1)\n",
    "#testexp2idx\n",
    "test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.concatenate([train2idx[,test2idx], axis=0).shape\n",
    "\n",
    "all_data = np.concatenate([train2idx,test2idx], axis=0)\n",
    "all_labels = np.concatenate([train2idx[:,1],test2idx[:,1]], axis=0)\n",
    "\n",
    "\n",
    "train_mask = np.concatenate([np.ones(train2idx.shape[0], dtype=bool), np.zeros(test2idx.shape[0],dtype=bool)])\n",
    "test_mask = np.concatenate([np.zeros(train2idx.shape[0], dtype=bool), np.ones(test2idx.shape[0],dtype=bool)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "# for i,j in all_data:\n",
    "    \n",
    "#     X.append([entity_embeddings[i],entity_embeddings[j]])\n",
    "\n",
    "# X = np.array(X_embeddings)\n",
    "\n",
    "# y = torch.tensor(all_labels)\n",
    "\n",
    "# train_horizontal = np.stack([train2idx_[:,0],train2idx_[:,2]],axis=0)\n",
    "# test_horizontal = np.stack([test2idx_[:,0],test2idx_[:,2]],axis=0)\n",
    "\n",
    "# edge_index = torch.tensor(np.concatenate([train_horizontal, test_horizontal],axis=1), dtype=torch.long)\n",
    "# data = Data(x=X, y=y, edge_index=edge_index,num_classes=NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = GCNConv(50, 16)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = Net().to(device)\n",
    "# data = data.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# x, edge_index = data.x, data.edge_index\n",
    "\n",
    "# for epoch in range(1, 201):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     log_logits = model(x, edge_index)\n",
    "#     loss = F.nll_loss(log_logits[data.train_mask], data.y[data.train_mask])\n",
    "#     loss.backward()\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = torch.tensor([entity_embeddings[ent2idx[h]] for h,_,_ in test])\n",
    "# y_test = torch.tensor([(rel2idx[r]) for _,r,_ in test])\n",
    "# test_ents = np.array([(ent2idx[h],ent2idx[t]) for h,_,t in test]).T\n",
    "# test_ents_flipped = np.stack((test_ents[1,:], test_ents[0,:]))\n",
    "# test_edge_index = torch.tensor(np.concatenate((test_ents,test_ents_flipped), axis=1), dtype=torch.long)\n",
    "# test_data = Data(x_test=X_test,y_test=y_test,test_edge_index=test_edge_index,num_classes=num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lin = Sequential(Linear(10,10))\n",
    "        self.conv1 = GCNConv(data.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, data.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    log_logits = model(x, edge_index)\n",
    "    loss = F.nll_loss(log_logits, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "explainer = GNNExplainer(model, epochs=200)\n",
    "\n",
    "x_test,test_y, test_edge_index = test_data.x_test,test_data.y_test,test_data.test_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explanations(i,x,y,edge_index, explainer):\n",
    "\n",
    "    node_feat_mask, edge_mask = explainer.explain_node(i, x, edge_index)\n",
    "    \n",
    "    _, G = explainer.visualize_subgraph(i, edge_index, edge_mask, y=y)\n",
    "\n",
    "    temp = []\n",
    "    exp = list(G.edges)\n",
    "    for tup in exp:\n",
    "        sorted_tup = tuple(sorted(tup))\n",
    "        temp.append(sorted_tup)\n",
    "\n",
    "    return list(set(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat_mask, edge_mask = explainer.explain_node(0, x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.visualize_subgraph(2278, edge_index, edge_mask, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.zeros(shape=(num_entities,num_entities))\n",
    "\n",
    "# for h,r,t in d:\n",
    "    \n",
    "#     h_idx = entities.index(h)\n",
    "#     #r_idx = relations.index(r)\n",
    "#     t_idx = entities.index(t)\n",
    "    \n",
    "#     A[h_idx, t_idx] = 1\n",
    "    \n",
    "# A = torch.tensor(A, dtype=torch.float)\n",
    "#A = torch.randn(5,10)\n",
    "# X = torch.randn(2708,1433)\n",
    "# y = torch.randint(3, (2708,))\n",
    "\n",
    "# X = torch.randn(10,1433)\n",
    "# y = torch.randint(3, (10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.lin = Sequential(Linear(10,10))\n",
    "#         self.conv1 = GCNConv(data.num_features, 16)\n",
    "#         self.conv2 = GCNConv(16, data.num_classes)\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         return F.log_softmax(x, dim=1)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = Net().to(device)\n",
    "# data = data.to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# x, edge_index = data.x, data.edge_index\n",
    "\n",
    "# for epoch in range(1, 201):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     log_logits = model(x, edge_index)\n",
    "#     loss = F.nll_loss(log_logits, data.y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# explainer = GNNExplainer(model, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_idx = 3\n",
    "# node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)\n",
    "# ax, G = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=data.y)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanations = []\n",
    "\n",
    "# for i in range(2):\n",
    "    \n",
    "#     node_feat_mask, edge_mask = explainer.explain_node(i, x, edge_index)\n",
    "#     _, G = explainer.visualize_subgraph(i, edge_index, edge_mask, y=data.y)\n",
    "    \n",
    "#     explanations.append(list(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_explanations = []\n",
    "# for i in explanations:\n",
    "#     temp = []\n",
    "#     for tup in i:\n",
    "#         sorted_tup = tuple(sorted(tup))\n",
    "#         temp.append(sorted_tup)\n",
    "#     unique_explanations.append(list(set(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
